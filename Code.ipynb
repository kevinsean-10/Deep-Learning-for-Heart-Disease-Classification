{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "Bz_VSJSdRb1d"
      },
      "id": "Bz_VSJSdRb1d"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "id": "pi2qdiTZMxVm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de164304-4eec-4535-ee53-c28fd29de4e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "id": "pi2qdiTZMxVm"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataset = pd.read_excel('/content/gdrive/MyDrive/heart.xlsx')\n",
        "dataset = pd.DataFrame(dataset)\n",
        "dataset.head()\n",
        "mylist = dataset.columns\n",
        "print(mylist)\n",
        "\n",
        "# Mengambil dan mendefinisikan data\n",
        "Age = dataset['age']\n",
        "Sex = dataset['sex']\n",
        "ChestPain = dataset['cp'] # Type of Chest Pain\n",
        "RestBP = dataset['trestbps'] # Rest of Blood Pressure\n",
        "FBS = dataset['fbs']\n",
        "Cholesterol = dataset['chol'] # Cholesterol in mg/dl\n",
        "RestECG = dataset['restecg'] # Rest ECG result (values 0,1,2)\n",
        "MaxHR = dataset['thalach'] # Maximum Heart Rate\n",
        "ExAng = dataset['exang'] # Excercise Induces Angina\n",
        "OldPeak = dataset['oldpeak'] # ST depression induced by exercise relative to rest\n",
        "SlopeOP = dataset['slope'] # the slope of the peak exercise ST segment\n",
        "CA = dataset['ca']\n",
        "Thal = dataset['thal'] # 1 Normal, 2 Fixed defect, 3 Reversable defect\n",
        "Target = dataset['target'] # 0 No disease, 1 Disease"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxRtnvXANhEQ",
        "outputId": "774d96ba-104f-46f0-d6a5-22a2dbcbedb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
            "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "id": "QxRtnvXANhEQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifications with MLP"
      ],
      "metadata": {
        "id": "potqhnoxeb4x"
      },
      "id": "potqhnoxeb4x"
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax function\n",
        "def softmax(x):\n",
        "    exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "# Cross-entropy loss\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    m = y_pred.shape[0]\n",
        "    log_likelihood = -(y_true * np.log(y_pred))  # Adding a small constant to avoid log(0)\n",
        "    loss = np.sum(log_likelihood) / m\n",
        "    return loss\n",
        "\n",
        "# One-hot encoding\n",
        "def one_hot(y, num_classes):\n",
        "    return np.eye(num_classes)[y]\n",
        "\n",
        "# Accuracy calculation\n",
        "def accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)\n",
        "\n",
        "class SimpleMLP:\n",
        "    def __init__(self, layer_sizes):\n",
        "        self.layer_sizes = layer_sizes\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "\n",
        "        # Initialize weights and biases for each layer\n",
        "        for i in range(len(layer_sizes) - 1):\n",
        "            self.weights.append(np.random.randn(layer_sizes[i], layer_sizes[i + 1]) * 0.01)\n",
        "            self.biases.append(np.zeros((1, layer_sizes[i + 1])))\n",
        "\n",
        "    def feedforward(self, X):\n",
        "        activation = X\n",
        "        for i in range(len(self.weights)):\n",
        "            z = np.dot(activation, self.weights[i]) + self.biases[i]\n",
        "            activation = softmax(z)  # Using softmax for all layers\n",
        "        return activation\n",
        "\n",
        "    def backpropagation(self, X, y, learning_rate):\n",
        "        m = X.shape[0]\n",
        "        # Forward pass\n",
        "        activations = [X]\n",
        "        zs = []  # to store all z vectors layer by layer\n",
        "\n",
        "        for i in range(len(self.weights)):\n",
        "            z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
        "            activations.append(softmax(z))  # Using softmax for all layers\n",
        "            zs.append(z)\n",
        "\n",
        "        # Backward pass\n",
        "        delta = activations[-1] - one_hot(y, self.layer_sizes[-1])\n",
        "        for l in range(len(self.weights) - 1, -1, -1):\n",
        "            delta_w = np.dot(activations[l].T, delta) / m\n",
        "            delta_b = np.sum(delta, axis=0, keepdims=True) / m\n",
        "            self.weights[l] -= learning_rate * delta_w\n",
        "            self.biases[l] -= learning_rate * delta_b\n",
        "\n",
        "            if l > 0:\n",
        "                # Derivative of softmax\n",
        "                delta = np.dot(delta, self.weights[l].T) * activations[l] * (1 - activations[l])\n",
        "\n",
        "    def train(self, X, y, epochs, learning_rate):\n",
        "        for epoch in range(epochs):\n",
        "            output = self.feedforward(X)\n",
        "            self.backpropagation(X, y, learning_rate)\n",
        "            if epoch % 1000 == 0:\n",
        "                loss = cross_entropy_loss(one_hot(y, self.layer_sizes[-1]), output)\n",
        "                print(f\"Epoch {epoch}, Loss: {loss}\")"
      ],
      "metadata": {
        "id": "edZFvKGaWj01"
      },
      "id": "edZFvKGaWj01",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hasil Pertama"
      ],
      "metadata": {
        "id": "4sY3qpupPYHD"
      },
      "id": "4sY3qpupPYHD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the seed for reproducibility\n",
        "np.random.seed(25)\n",
        "\n",
        "#data preparation\n",
        "features = np.column_stack([Age,Sex,ChestPain,RestBP,FBS,Cholesterol,RestECG,MaxHR,ExAng,OldPeak,SlopeOP,CA,Thal])\n",
        "labels = Target\n",
        "#Split the dataset manually\n",
        "split_ratio = 0.7\n",
        "split_index = int(len(features) * split_ratio)\n",
        "X_train, X_test = features[:split_index], features[split_index:]\n",
        "y_train, y_test = labels[:split_index], labels[split_index:]\n",
        "\n",
        "# Training the model\n",
        "layer_sizes = [13, 5, 10, 2]  # 13 input features, two hidden layers with 5 neurons and 10 neurons, and 2 output neurons\n",
        "\n",
        "mlp = SimpleMLP(layer_sizes)\n",
        "mlp.train(X_train, y_train, epochs=50000, learning_rate=10**(-3))\n",
        "\n",
        "y_pred = np.argmax(mlp.feedforward(X_test), axis =1)\n",
        "accuracy_result = accuracy(y_test,y_pred)\n",
        "print(\"akurasi :\", accuracy_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Izlsxb2gCZ_d",
        "outputId": "b782738e-4c89-474e-e3fe-b9bbd8ae75fd"
      },
      "id": "Izlsxb2gCZ_d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6931820530655249\n",
            "Epoch 1000, Loss: 0.6926856852125758\n",
            "Epoch 2000, Loss: 0.692520472047502\n",
            "Epoch 3000, Loss: 0.6924654594865337\n",
            "Epoch 4000, Loss: 0.6924471348933887\n",
            "Epoch 5000, Loss: 0.6924410292607395\n",
            "Epoch 6000, Loss: 0.6924389943060145\n",
            "Epoch 7000, Loss: 0.6924383157379067\n",
            "Epoch 8000, Loss: 0.6924380892039038\n",
            "Epoch 9000, Loss: 0.6924380133507463\n",
            "Epoch 10000, Loss: 0.6924379877512585\n",
            "Epoch 11000, Loss: 0.6924379789352981\n",
            "Epoch 12000, Loss: 0.692437975746891\n",
            "Epoch 13000, Loss: 0.692437974466782\n",
            "Epoch 14000, Loss: 0.6924379738542478\n",
            "Epoch 15000, Loss: 0.692437973494645\n",
            "Epoch 16000, Loss: 0.6924379732486722\n",
            "Epoch 17000, Loss: 0.6924379730688122\n",
            "Epoch 18000, Loss: 0.6924379729381506\n",
            "Epoch 19000, Loss: 0.6924379728499834\n",
            "Epoch 20000, Loss: 0.6924379728010176\n",
            "Epoch 21000, Loss: 0.6924379727891046\n",
            "Epoch 22000, Loss: 0.6924379728124835\n",
            "Epoch 23000, Loss: 0.6924379728695298\n",
            "Epoch 24000, Loss: 0.69243797295867\n",
            "Epoch 25000, Loss: 0.6924379730783545\n",
            "Epoch 26000, Loss: 0.6924379732270479\n",
            "Epoch 27000, Loss: 0.6924379734032262\n",
            "Epoch 28000, Loss: 0.692437973605377\n",
            "Epoch 29000, Loss: 0.6924379738319987\n",
            "Epoch 30000, Loss: 0.6924379740816023\n",
            "Epoch 31000, Loss: 0.6924379743527118\n",
            "Epoch 32000, Loss: 0.6924379746438647\n",
            "Epoch 33000, Loss: 0.6924379749536133\n",
            "Epoch 34000, Loss: 0.6924379752805262\n",
            "Epoch 35000, Loss: 0.6924379756231894\n",
            "Epoch 36000, Loss: 0.6924379759802064\n",
            "Epoch 37000, Loss: 0.692437976350201\n",
            "Epoch 38000, Loss: 0.6924379767318172\n",
            "Epoch 39000, Loss: 0.6924379771237206\n",
            "Epoch 40000, Loss: 0.6924379775246005\n",
            "Epoch 41000, Loss: 0.6924379779331702\n",
            "Epoch 42000, Loss: 0.6924379783481678\n",
            "Epoch 43000, Loss: 0.6924379787683582\n",
            "Epoch 44000, Loss: 0.692437979192534\n",
            "Epoch 45000, Loss: 0.6924379796195156\n",
            "Epoch 46000, Loss: 0.6924379800481532\n",
            "Epoch 47000, Loss: 0.6924379804773271\n",
            "Epoch 48000, Loss: 0.6924379809059487\n",
            "Epoch 49000, Loss: 0.6924379813329606\n",
            "akurasi : 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hasil Kedua"
      ],
      "metadata": {
        "id": "f1Y0CJz4P6ST"
      },
      "id": "f1Y0CJz4P6ST"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the seed for reproducibility\n",
        "np.random.seed(25)\n",
        "\n",
        "#data preparation\n",
        "features = np.column_stack([Age,Sex,ChestPain,RestBP,FBS,Cholesterol,RestECG,MaxHR,ExAng,OldPeak,SlopeOP,CA,Thal])\n",
        "labels = Target\n",
        "#Split the dataset manually\n",
        "split_ratio = 0.7\n",
        "split_index = int(len(features) * split_ratio)\n",
        "X_train, X_test = features[:split_index], features[split_index:]\n",
        "y_train, y_test = labels[:split_index], labels[split_index:]\n",
        "\n",
        "# Training the model\n",
        "layer_sizes = [13, 5, 20, 2]  # 13 input features, two hidden layers with 5 neurons and 10 neurons, and 2 output neurons\n",
        "\n",
        "mlp = SimpleMLP(layer_sizes)\n",
        "mlp.train(X_train, y_train, epochs=50000, learning_rate=10**(-3))\n",
        "\n",
        "y_pred = np.argmax(mlp.feedforward(X_test), axis =1)\n",
        "accuracy_result = accuracy(y_test,y_pred)\n",
        "print(\"akurasi :\", accuracy_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGPjmlo0P7pF",
        "outputId": "e52b3095-1dd9-4a3f-aac3-825d5278a761"
      },
      "id": "IGPjmlo0P7pF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6930577145226965\n",
            "Epoch 1000, Loss: 0.6926544819561528\n",
            "Epoch 2000, Loss: 0.6925133616841718\n",
            "Epoch 3000, Loss: 0.6924639434111853\n",
            "Epoch 4000, Loss: 0.6924466199291797\n",
            "Epoch 5000, Loss: 0.6924405325086346\n",
            "Epoch 6000, Loss: 0.6924383789022235\n",
            "Epoch 7000, Loss: 0.692437601937706\n",
            "Epoch 8000, Loss: 0.6924373059127735\n",
            "Epoch 9000, Loss: 0.6924371770225793\n",
            "Epoch 10000, Loss: 0.6924371052956252\n",
            "Epoch 11000, Loss: 0.6924370521738525\n",
            "Epoch 12000, Loss: 0.6924370041274522\n",
            "Epoch 13000, Loss: 0.6924369564065826\n",
            "Epoch 14000, Loss: 0.6924369073504609\n",
            "Epoch 15000, Loss: 0.6924368563948864\n",
            "Epoch 16000, Loss: 0.6924368033752172\n",
            "Epoch 17000, Loss: 0.6924367482828343\n",
            "Epoch 18000, Loss: 0.6924366911800222\n",
            "Epoch 19000, Loss: 0.6924366321698131\n",
            "Epoch 20000, Loss: 0.6924365713845091\n",
            "Epoch 21000, Loss: 0.6924365089801588\n",
            "Epoch 22000, Loss: 0.6924364451325685\n",
            "Epoch 23000, Loss: 0.6924363800333719\n",
            "Epoch 24000, Loss: 0.6924363138857514\n",
            "Epoch 25000, Loss: 0.6924362468998094\n",
            "Epoch 26000, Loss: 0.6924361792877396\n",
            "Epoch 27000, Loss: 0.6924361112590062\n",
            "Epoch 28000, Loss: 0.6924360430157499\n",
            "Epoch 29000, Loss: 0.6924359747486183\n",
            "Epoch 30000, Loss: 0.6924359066331802\n",
            "Epoch 31000, Loss: 0.692435838827043\n",
            "Epoch 32000, Loss: 0.6924357714677339\n",
            "Epoch 33000, Loss: 0.6924357046713626\n",
            "Epoch 34000, Loss: 0.6924356385320353\n",
            "Epoch 35000, Loss: 0.6924355731219591\n",
            "Epoch 36000, Loss: 0.6924355084921436\n",
            "Epoch 37000, Loss: 0.6924354446735959\n",
            "Epoch 38000, Loss: 0.6924353816788961\n",
            "Epoch 39000, Loss: 0.6924353195040411\n",
            "Epoch 40000, Loss: 0.6924352581304501\n",
            "Epoch 41000, Loss: 0.6924351975270406\n",
            "Epoch 42000, Loss: 0.6924351376522945\n",
            "Epoch 43000, Loss: 0.6924350784562481\n",
            "Epoch 44000, Loss: 0.6924350198823611\n",
            "Epoch 45000, Loss: 0.6924349618692262\n",
            "Epoch 46000, Loss: 0.6924349043521008\n",
            "Epoch 47000, Loss: 0.6924348472642482\n",
            "Epoch 48000, Loss: 0.6924347905380895\n",
            "Epoch 49000, Loss: 0.6924347341061687\n",
            "akurasi : 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hasil Ketiga"
      ],
      "metadata": {
        "id": "hB6nsGJTFZol"
      },
      "id": "hB6nsGJTFZol"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the seed for reproducibility\n",
        "np.random.seed(25)\n",
        "\n",
        "#data preparation\n",
        "features = np.column_stack([Age,Sex,ChestPain,RestBP,FBS,Cholesterol,RestECG,MaxHR,ExAng,OldPeak,SlopeOP,CA,Thal])\n",
        "labels = Target\n",
        "#Split the dataset manually\n",
        "split_ratio = 0.7\n",
        "split_index = int(len(features) * split_ratio)\n",
        "X_train, X_test = features[:split_index], features[split_index:]\n",
        "y_train, y_test = labels[:split_index], labels[split_index:]\n",
        "\n",
        "# Training the model\n",
        "layer_sizes = [13, 5, 10,15, 2]  # 13 input features, three hidden layers with 5,10,15 neurons, and 2 output neurons\n",
        "\n",
        "mlp = SimpleMLP(layer_sizes)\n",
        "mlp.train(X_train, y_train, epochs=50000, learning_rate=10**(-3))\n",
        "\n",
        "y_pred = np.argmax(mlp.feedforward(X_test), axis =1)\n",
        "accuracy_result = accuracy(y_test,y_pred)\n",
        "print(\"akurasi :\", accuracy_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWI5eCmqEgjm",
        "outputId": "d0b4fb30-81ee-4cee-c381-2f019e1d1208"
      },
      "id": "GWI5eCmqEgjm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.693156854083655\n",
            "Epoch 1000, Loss: 0.6926854188326034\n",
            "Epoch 2000, Loss: 0.6925231829635058\n",
            "Epoch 3000, Loss: 0.6924673314294786\n",
            "Epoch 4000, Loss: 0.6924480977247858\n",
            "Epoch 5000, Loss: 0.6924414726962896\n",
            "Epoch 6000, Loss: 0.6924391903861942\n",
            "Epoch 7000, Loss: 0.6924384040653182\n",
            "Epoch 8000, Loss: 0.6924381331409263\n",
            "Epoch 9000, Loss: 0.6924380397917607\n",
            "Epoch 10000, Loss: 0.6924380076268938\n",
            "Epoch 11000, Loss: 0.6924379965438171\n",
            "Epoch 12000, Loss: 0.6924379927248238\n",
            "Epoch 13000, Loss: 0.6924379914088118\n",
            "Epoch 14000, Loss: 0.6924379909552547\n",
            "Epoch 15000, Loss: 0.6924379907988755\n",
            "Epoch 16000, Loss: 0.6924379907448955\n",
            "Epoch 17000, Loss: 0.6924379907261995\n",
            "Epoch 18000, Loss: 0.6924379907196614\n",
            "Epoch 19000, Loss: 0.6924379907173126\n",
            "Epoch 20000, Loss: 0.6924379907164073\n",
            "Epoch 21000, Loss: 0.6924379907159993\n",
            "Epoch 22000, Loss: 0.6924379907157627\n",
            "Epoch 23000, Loss: 0.6924379907155852\n",
            "Epoch 24000, Loss: 0.692437990715428\n",
            "Epoch 25000, Loss: 0.6924379907152777\n",
            "Epoch 26000, Loss: 0.6924379907151299\n",
            "Epoch 27000, Loss: 0.6924379907149827\n",
            "Epoch 28000, Loss: 0.6924379907148359\n",
            "Epoch 29000, Loss: 0.6924379907146891\n",
            "Epoch 30000, Loss: 0.6924379907145425\n",
            "Epoch 31000, Loss: 0.6924379907143957\n",
            "Epoch 32000, Loss: 0.6924379907142489\n",
            "Epoch 33000, Loss: 0.6924379907141023\n",
            "Epoch 34000, Loss: 0.6924379907139553\n",
            "Epoch 35000, Loss: 0.6924379907138085\n",
            "Epoch 36000, Loss: 0.6924379907136616\n",
            "Epoch 37000, Loss: 0.6924379907135146\n",
            "Epoch 38000, Loss: 0.6924379907133678\n",
            "Epoch 39000, Loss: 0.6924379907132208\n",
            "Epoch 40000, Loss: 0.6924379907130738\n",
            "Epoch 41000, Loss: 0.6924379907129268\n",
            "Epoch 42000, Loss: 0.6924379907127798\n",
            "Epoch 43000, Loss: 0.6924379907126327\n",
            "Epoch 44000, Loss: 0.6924379907124855\n",
            "Epoch 45000, Loss: 0.6924379907123384\n",
            "Epoch 46000, Loss: 0.6924379907121913\n",
            "Epoch 47000, Loss: 0.692437990712044\n",
            "Epoch 48000, Loss: 0.6924379907118967\n",
            "Epoch 49000, Loss: 0.6924379907117495\n",
            "akurasi : 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifications with FNN (with TensorFlow)"
      ],
      "metadata": {
        "id": "iAPI5HL5efLh"
      },
      "id": "iAPI5HL5efLh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hasil Pertama"
      ],
      "metadata": {
        "id": "m3VVcrxcGars"
      },
      "id": "m3VVcrxcGars"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "\n",
        "# Dataset\n",
        "X_train = np.column_stack([Age,Sex,ChestPain,RestBP,FBS,Cholesterol,RestECG,MaxHR,ExAng,OldPeak,SlopeOP,CA,Thal])\n",
        "y_train = Target\n",
        "\n",
        "# Building the Feedforward Neural Network model\n",
        "model = Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "model.add(Dense(units=128, activation='relu', input_shape=(13,)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Second hidden layer\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fitting the model to the training set\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4JRalWLeiDa",
        "outputId": "586d84da-f912-4a0f-e32e-478cc1e862d4"
      },
      "id": "C4JRalWLeiDa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "33/33 [==============================] - 2s 5ms/step - loss: 15.3599 - accuracy: 0.5229\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 9.1809 - accuracy: 0.5132\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 5.4697 - accuracy: 0.5493\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 3.3099 - accuracy: 0.5620\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 2.5375 - accuracy: 0.5288\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.5854 - accuracy: 0.5815\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.3075 - accuracy: 0.5571\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.1637 - accuracy: 0.5541\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9332 - accuracy: 0.5649\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8849 - accuracy: 0.5766\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8819 - accuracy: 0.5541\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8461 - accuracy: 0.5600\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7562 - accuracy: 0.5776\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7391 - accuracy: 0.5483\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.7784 - accuracy: 0.5649\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.7178 - accuracy: 0.5932\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7255 - accuracy: 0.5668\n",
            "Epoch 18/50\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.7195 - accuracy: 0.5932\n",
            "Epoch 19/50\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.7165 - accuracy: 0.5629\n",
            "Epoch 20/50\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.7095 - accuracy: 0.5551\n",
            "Epoch 21/50\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6903 - accuracy: 0.5727\n",
            "Epoch 22/50\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.7058 - accuracy: 0.5620\n",
            "Epoch 23/50\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.5766\n",
            "Epoch 24/50\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6785 - accuracy: 0.5883\n",
            "Epoch 25/50\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6731 - accuracy: 0.5815\n",
            "Epoch 26/50\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7141 - accuracy: 0.5629\n",
            "Epoch 27/50\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6802 - accuracy: 0.5785\n",
            "Epoch 28/50\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6694 - accuracy: 0.5980\n",
            "Epoch 29/50\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6678 - accuracy: 0.6195\n",
            "Epoch 30/50\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6732 - accuracy: 0.6059\n",
            "Epoch 31/50\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6703 - accuracy: 0.5824\n",
            "Epoch 32/50\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6643 - accuracy: 0.6205\n",
            "Epoch 33/50\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6675 - accuracy: 0.5961\n",
            "Epoch 34/50\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6796 - accuracy: 0.6127\n",
            "Epoch 35/50\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6635 - accuracy: 0.6098\n",
            "Epoch 36/50\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6641 - accuracy: 0.6039\n",
            "Epoch 37/50\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6539 - accuracy: 0.6166\n",
            "Epoch 38/50\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6549 - accuracy: 0.6283\n",
            "Epoch 39/50\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6755 - accuracy: 0.5951\n",
            "Epoch 40/50\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6414 - accuracy: 0.6341\n",
            "Epoch 41/50\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6727 - accuracy: 0.6010\n",
            "Epoch 42/50\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6523 - accuracy: 0.6195\n",
            "Epoch 43/50\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6341 - accuracy: 0.6507\n",
            "Epoch 44/50\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6331 - accuracy: 0.6429\n",
            "Epoch 45/50\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6332 - accuracy: 0.6605\n",
            "Epoch 46/50\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6342 - accuracy: 0.6420\n",
            "Epoch 47/50\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6456 - accuracy: 0.6498\n",
            "Epoch 48/50\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6446 - accuracy: 0.6244\n",
            "Epoch 49/50\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6303 - accuracy: 0.6517\n",
            "Epoch 50/50\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.6771\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 128)               1792      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10113 (39.50 KB)\n",
            "Trainable params: 10113 (39.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hasil Kedua"
      ],
      "metadata": {
        "id": "mz_ijgD-Gepv"
      },
      "id": "mz_ijgD-Gepv"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "\n",
        "# Dataset\n",
        "X_train = np.column_stack([Age,Sex,ChestPain,RestBP,FBS,Cholesterol,RestECG,MaxHR,ExAng,OldPeak,SlopeOP,CA,Thal])\n",
        "y_train = Target\n",
        "\n",
        "# Building the Feedforward Neural Network model\n",
        "model = Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "model.add(Dense(units=128, activation='relu', input_shape=(13,)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Second hidden layer\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fitting the model to the training set\n",
        "model.fit(X_train, y_train, epochs=500, batch_size=32)\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAQis3rNGdWC",
        "outputId": "7bff95ce-6c7a-4ec4-8f64-be08b5cffed2"
      },
      "id": "HAQis3rNGdWC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "33/33 [==============================] - 1s 3ms/step - loss: 20.1877 - accuracy: 0.5015\n",
            "Epoch 2/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 9.7400 - accuracy: 0.5512\n",
            "Epoch 3/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 5.8348 - accuracy: 0.5434\n",
            "Epoch 4/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 3.3154 - accuracy: 0.5776\n",
            "Epoch 5/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 2.6863 - accuracy: 0.5688\n",
            "Epoch 6/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 2.0211 - accuracy: 0.5551\n",
            "Epoch 7/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.5896 - accuracy: 0.5493\n",
            "Epoch 8/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.2128 - accuracy: 0.5580\n",
            "Epoch 9/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1797 - accuracy: 0.5746\n",
            "Epoch 10/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.9552 - accuracy: 0.5727\n",
            "Epoch 11/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.9520 - accuracy: 0.5610\n",
            "Epoch 12/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8603 - accuracy: 0.5551\n",
            "Epoch 13/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8255 - accuracy: 0.5288\n",
            "Epoch 14/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7509 - accuracy: 0.5688\n",
            "Epoch 15/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7556 - accuracy: 0.5473\n",
            "Epoch 16/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8172 - accuracy: 0.5317\n",
            "Epoch 17/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7305 - accuracy: 0.5444\n",
            "Epoch 18/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7867 - accuracy: 0.5122\n",
            "Epoch 19/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7173 - accuracy: 0.5541\n",
            "Epoch 20/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7436 - accuracy: 0.5327\n",
            "Epoch 21/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7240 - accuracy: 0.5288\n",
            "Epoch 22/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7073 - accuracy: 0.5434\n",
            "Epoch 23/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6965 - accuracy: 0.5307\n",
            "Epoch 24/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5463\n",
            "Epoch 25/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6999 - accuracy: 0.5659\n",
            "Epoch 26/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7054 - accuracy: 0.5600\n",
            "Epoch 27/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7244 - accuracy: 0.5454\n",
            "Epoch 28/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.5844\n",
            "Epoch 29/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7096 - accuracy: 0.5541\n",
            "Epoch 30/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.5610\n",
            "Epoch 31/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7046 - accuracy: 0.5454\n",
            "Epoch 32/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.5912\n",
            "Epoch 33/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.5980\n",
            "Epoch 34/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.5990\n",
            "Epoch 35/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.5844\n",
            "Epoch 36/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5805\n",
            "Epoch 37/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.5912\n",
            "Epoch 38/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.6234\n",
            "Epoch 39/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.6234\n",
            "Epoch 40/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.6176\n",
            "Epoch 41/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.6098\n",
            "Epoch 42/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.6068\n",
            "Epoch 43/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.5980\n",
            "Epoch 44/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6582 - accuracy: 0.6117\n",
            "Epoch 45/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6463 - accuracy: 0.6302\n",
            "Epoch 46/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6548 - accuracy: 0.6117\n",
            "Epoch 47/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.6546\n",
            "Epoch 48/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.6224\n",
            "Epoch 49/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6573 - accuracy: 0.6273\n",
            "Epoch 50/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6506 - accuracy: 0.6410\n",
            "Epoch 51/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.6234\n",
            "Epoch 52/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.6224\n",
            "Epoch 53/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.6195\n",
            "Epoch 54/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6156 - accuracy: 0.6449\n",
            "Epoch 55/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6691 - accuracy: 0.6293\n",
            "Epoch 56/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.6537\n",
            "Epoch 57/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.6468\n",
            "Epoch 58/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.6634\n",
            "Epoch 59/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.6361\n",
            "Epoch 60/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6046 - accuracy: 0.6732\n",
            "Epoch 61/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6117 - accuracy: 0.6615\n",
            "Epoch 62/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.6410\n",
            "Epoch 63/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.6546\n",
            "Epoch 64/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.6341\n",
            "Epoch 65/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6287 - accuracy: 0.6400\n",
            "Epoch 66/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6260 - accuracy: 0.6400\n",
            "Epoch 67/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6248 - accuracy: 0.6566\n",
            "Epoch 68/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.6380\n",
            "Epoch 69/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6318 - accuracy: 0.6439\n",
            "Epoch 70/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6138 - accuracy: 0.6459\n",
            "Epoch 71/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6054 - accuracy: 0.6751\n",
            "Epoch 72/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6162 - accuracy: 0.6546\n",
            "Epoch 73/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6175 - accuracy: 0.6927\n",
            "Epoch 74/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6149 - accuracy: 0.6663\n",
            "Epoch 75/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6153 - accuracy: 0.6566\n",
            "Epoch 76/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.6878\n",
            "Epoch 77/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5882 - accuracy: 0.6820\n",
            "Epoch 78/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5964 - accuracy: 0.6868\n",
            "Epoch 79/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5902 - accuracy: 0.6878\n",
            "Epoch 80/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5867 - accuracy: 0.6995\n",
            "Epoch 81/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6146 - accuracy: 0.6615\n",
            "Epoch 82/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.6829\n",
            "Epoch 83/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.6771\n",
            "Epoch 84/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7151\n",
            "Epoch 85/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.6907\n",
            "Epoch 86/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.6790\n",
            "Epoch 87/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7083\n",
            "Epoch 88/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.7015\n",
            "Epoch 89/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.7229\n",
            "Epoch 90/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.7161\n",
            "Epoch 91/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.7073\n",
            "Epoch 92/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7161\n",
            "Epoch 93/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7044\n",
            "Epoch 94/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7015\n",
            "Epoch 95/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7141\n",
            "Epoch 96/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.7024\n",
            "Epoch 97/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7054\n",
            "Epoch 98/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.7132\n",
            "Epoch 99/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7220\n",
            "Epoch 100/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7180\n",
            "Epoch 101/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7093\n",
            "Epoch 102/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7405\n",
            "Epoch 103/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7356\n",
            "Epoch 104/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7522\n",
            "Epoch 105/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7259\n",
            "Epoch 106/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7259\n",
            "Epoch 107/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.7415\n",
            "Epoch 108/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7551\n",
            "Epoch 109/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7288\n",
            "Epoch 110/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7444\n",
            "Epoch 111/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7571\n",
            "Epoch 112/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7366\n",
            "Epoch 113/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7454\n",
            "Epoch 114/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7473\n",
            "Epoch 115/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7551\n",
            "Epoch 116/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7580\n",
            "Epoch 117/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7698\n",
            "Epoch 118/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7307\n",
            "Epoch 119/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7298\n",
            "Epoch 120/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7463\n",
            "Epoch 121/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7590\n",
            "Epoch 122/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7541\n",
            "Epoch 123/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.7590\n",
            "Epoch 124/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7785\n",
            "Epoch 125/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7727\n",
            "Epoch 126/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7688\n",
            "Epoch 127/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7688\n",
            "Epoch 128/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7590\n",
            "Epoch 129/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7639\n",
            "Epoch 130/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7649\n",
            "Epoch 131/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7805\n",
            "Epoch 132/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7844\n",
            "Epoch 133/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7873\n",
            "Epoch 134/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7990\n",
            "Epoch 135/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7571\n",
            "Epoch 136/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7961\n",
            "Epoch 137/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7873\n",
            "Epoch 138/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7629\n",
            "Epoch 139/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7551\n",
            "Epoch 140/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7659\n",
            "Epoch 141/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7590\n",
            "Epoch 142/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7746\n",
            "Epoch 143/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7824\n",
            "Epoch 144/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7844\n",
            "Epoch 145/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.7727\n",
            "Epoch 146/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7249\n",
            "Epoch 147/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7873\n",
            "Epoch 148/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7698\n",
            "Epoch 149/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7834\n",
            "Epoch 150/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7873\n",
            "Epoch 151/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7717\n",
            "Epoch 152/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7707\n",
            "Epoch 153/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7815\n",
            "Epoch 154/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7776\n",
            "Epoch 155/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7912\n",
            "Epoch 156/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7873\n",
            "Epoch 157/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7863\n",
            "Epoch 158/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7737\n",
            "Epoch 159/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7912\n",
            "Epoch 160/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7873\n",
            "Epoch 161/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7834\n",
            "Epoch 162/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7893\n",
            "Epoch 163/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7717\n",
            "Epoch 164/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7785\n",
            "Epoch 165/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7941\n",
            "Epoch 166/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7737\n",
            "Epoch 167/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7756\n",
            "Epoch 168/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.8029\n",
            "Epoch 169/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7971\n",
            "Epoch 170/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7629\n",
            "Epoch 171/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7902\n",
            "Epoch 172/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7990\n",
            "Epoch 173/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7990\n",
            "Epoch 174/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7961\n",
            "Epoch 175/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8039\n",
            "Epoch 176/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8156\n",
            "Epoch 177/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7961\n",
            "Epoch 178/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8049\n",
            "Epoch 179/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8029\n",
            "Epoch 180/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7932\n",
            "Epoch 181/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8078\n",
            "Epoch 182/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8029\n",
            "Epoch 183/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8283\n",
            "Epoch 184/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.8010\n",
            "Epoch 185/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8185\n",
            "Epoch 186/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8078\n",
            "Epoch 187/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.8176\n",
            "Epoch 188/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8215\n",
            "Epoch 189/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8107\n",
            "Epoch 190/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8195\n",
            "Epoch 191/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7932\n",
            "Epoch 192/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8137\n",
            "Epoch 193/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8244\n",
            "Epoch 194/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8176\n",
            "Epoch 195/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.8117\n",
            "Epoch 196/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.8146\n",
            "Epoch 197/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.8166\n",
            "Epoch 198/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8156\n",
            "Epoch 199/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8263\n",
            "Epoch 200/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8234\n",
            "Epoch 201/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.8098\n",
            "Epoch 202/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8146\n",
            "Epoch 203/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8166\n",
            "Epoch 204/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8137\n",
            "Epoch 205/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.8029\n",
            "Epoch 206/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.7961\n",
            "Epoch 207/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8020\n",
            "Epoch 208/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.8068\n",
            "Epoch 209/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8205\n",
            "Epoch 210/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8088\n",
            "Epoch 211/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8156\n",
            "Epoch 212/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8312\n",
            "Epoch 213/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8215\n",
            "Epoch 214/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8078\n",
            "Epoch 215/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.8000\n",
            "Epoch 216/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8127\n",
            "Epoch 217/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7941\n",
            "Epoch 218/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7854\n",
            "Epoch 219/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7610\n",
            "Epoch 220/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7502\n",
            "Epoch 221/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.8059\n",
            "Epoch 222/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7932\n",
            "Epoch 223/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7844\n",
            "Epoch 224/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8244\n",
            "Epoch 225/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8098\n",
            "Epoch 226/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8166\n",
            "Epoch 227/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8010\n",
            "Epoch 228/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8127\n",
            "Epoch 229/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7902\n",
            "Epoch 230/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8020\n",
            "Epoch 231/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.8000\n",
            "Epoch 232/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8000\n",
            "Epoch 233/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8078\n",
            "Epoch 234/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8244\n",
            "Epoch 235/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3911 - accuracy: 0.8234\n",
            "Epoch 236/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8283\n",
            "Epoch 237/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8205\n",
            "Epoch 238/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3993 - accuracy: 0.8312\n",
            "Epoch 239/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8322\n",
            "Epoch 240/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8049\n",
            "Epoch 241/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8215\n",
            "Epoch 242/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8263\n",
            "Epoch 243/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.8224\n",
            "Epoch 244/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8351\n",
            "Epoch 245/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8283\n",
            "Epoch 246/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8137\n",
            "Epoch 247/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.8000\n",
            "Epoch 248/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8195\n",
            "Epoch 249/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8166\n",
            "Epoch 250/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8195\n",
            "Epoch 251/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8117\n",
            "Epoch 252/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8195\n",
            "Epoch 253/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8195\n",
            "Epoch 254/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8215\n",
            "Epoch 255/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8263\n",
            "Epoch 256/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8156\n",
            "Epoch 257/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8137\n",
            "Epoch 258/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8234\n",
            "Epoch 259/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8273\n",
            "Epoch 260/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.8078\n",
            "Epoch 261/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8302\n",
            "Epoch 262/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8263\n",
            "Epoch 263/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8322\n",
            "Epoch 264/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8420\n",
            "Epoch 265/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8351\n",
            "Epoch 266/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8244\n",
            "Epoch 267/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 0.8166\n",
            "Epoch 268/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8312\n",
            "Epoch 269/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8332\n",
            "Epoch 270/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8244\n",
            "Epoch 271/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3693 - accuracy: 0.8390\n",
            "Epoch 272/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8312\n",
            "Epoch 273/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3970 - accuracy: 0.8224\n",
            "Epoch 274/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8312\n",
            "Epoch 275/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8332\n",
            "Epoch 276/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.8283\n",
            "Epoch 277/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3909 - accuracy: 0.8312\n",
            "Epoch 278/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.8215\n",
            "Epoch 279/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.8351\n",
            "Epoch 280/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8420\n",
            "Epoch 281/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8312\n",
            "Epoch 282/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8302\n",
            "Epoch 283/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8400\n",
            "Epoch 284/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.8449\n",
            "Epoch 285/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8254\n",
            "Epoch 286/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8351\n",
            "Epoch 287/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8156\n",
            "Epoch 288/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8176\n",
            "Epoch 289/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8205\n",
            "Epoch 290/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8107\n",
            "Epoch 291/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8156\n",
            "Epoch 292/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8205\n",
            "Epoch 293/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.8176\n",
            "Epoch 294/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7298\n",
            "Epoch 295/500\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7941\n",
            "Epoch 296/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.8127\n",
            "Epoch 297/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8195\n",
            "Epoch 298/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8224\n",
            "Epoch 299/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.8312\n",
            "Epoch 300/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3882 - accuracy: 0.8293\n",
            "Epoch 301/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8195\n",
            "Epoch 302/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8302\n",
            "Epoch 303/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8341\n",
            "Epoch 304/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3993 - accuracy: 0.8273\n",
            "Epoch 305/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8390\n",
            "Epoch 306/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3805 - accuracy: 0.8302\n",
            "Epoch 307/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8322\n",
            "Epoch 308/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8273\n",
            "Epoch 309/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8312\n",
            "Epoch 310/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8371\n",
            "Epoch 311/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8380\n",
            "Epoch 312/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8302\n",
            "Epoch 313/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7873\n",
            "Epoch 314/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8127\n",
            "Epoch 315/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.8098\n",
            "Epoch 316/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8244\n",
            "Epoch 317/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8244\n",
            "Epoch 318/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8351\n",
            "Epoch 319/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8322\n",
            "Epoch 320/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8332\n",
            "Epoch 321/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8263\n",
            "Epoch 322/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8312\n",
            "Epoch 323/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8244\n",
            "Epoch 324/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3940 - accuracy: 0.8185\n",
            "Epoch 325/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.8146\n",
            "Epoch 326/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8059\n",
            "Epoch 327/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7951\n",
            "Epoch 328/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7688\n",
            "Epoch 329/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8215\n",
            "Epoch 330/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8254\n",
            "Epoch 331/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3798 - accuracy: 0.8234\n",
            "Epoch 332/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8302\n",
            "Epoch 333/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8254\n",
            "Epoch 334/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8273\n",
            "Epoch 335/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8098\n",
            "Epoch 336/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.8088\n",
            "Epoch 337/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.8234\n",
            "Epoch 338/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8244\n",
            "Epoch 339/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.8254\n",
            "Epoch 340/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8312\n",
            "Epoch 341/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3839 - accuracy: 0.8322\n",
            "Epoch 342/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8234\n",
            "Epoch 343/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8156\n",
            "Epoch 344/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8263\n",
            "Epoch 345/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3784 - accuracy: 0.8302\n",
            "Epoch 346/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7922\n",
            "Epoch 347/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8341\n",
            "Epoch 348/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8283\n",
            "Epoch 349/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.8332\n",
            "Epoch 350/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8244\n",
            "Epoch 351/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8322\n",
            "Epoch 352/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.8166\n",
            "Epoch 353/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8332\n",
            "Epoch 354/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8351\n",
            "Epoch 355/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3851 - accuracy: 0.8390\n",
            "Epoch 356/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3949 - accuracy: 0.8254\n",
            "Epoch 357/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8215\n",
            "Epoch 358/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8263\n",
            "Epoch 359/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.8488\n",
            "Epoch 360/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8234\n",
            "Epoch 361/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8341\n",
            "Epoch 362/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8410\n",
            "Epoch 363/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8517\n",
            "Epoch 364/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8361\n",
            "Epoch 365/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.8088\n",
            "Epoch 366/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8439\n",
            "Epoch 367/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8390\n",
            "Epoch 368/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8449\n",
            "Epoch 369/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3810 - accuracy: 0.8390\n",
            "Epoch 370/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3844 - accuracy: 0.8302\n",
            "Epoch 371/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8332\n",
            "Epoch 372/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8468\n",
            "Epoch 373/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8117\n",
            "Epoch 374/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8234\n",
            "Epoch 375/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.8390\n",
            "Epoch 376/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3723 - accuracy: 0.8420\n",
            "Epoch 377/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3837 - accuracy: 0.8439\n",
            "Epoch 378/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8293\n",
            "Epoch 379/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8322\n",
            "Epoch 380/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3948 - accuracy: 0.8234\n",
            "Epoch 381/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8429\n",
            "Epoch 382/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3620 - accuracy: 0.8517\n",
            "Epoch 383/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8273\n",
            "Epoch 384/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8371\n",
            "Epoch 385/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8351\n",
            "Epoch 386/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8420\n",
            "Epoch 387/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8439\n",
            "Epoch 388/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8312\n",
            "Epoch 389/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.8332\n",
            "Epoch 390/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8176\n",
            "Epoch 391/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8351\n",
            "Epoch 392/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8410\n",
            "Epoch 393/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.8439\n",
            "Epoch 394/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8449\n",
            "Epoch 395/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3719 - accuracy: 0.8400\n",
            "Epoch 396/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3844 - accuracy: 0.8390\n",
            "Epoch 397/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3948 - accuracy: 0.8244\n",
            "Epoch 398/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8341\n",
            "Epoch 399/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8380\n",
            "Epoch 400/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8380\n",
            "Epoch 401/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3722 - accuracy: 0.8449\n",
            "Epoch 402/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.8420\n",
            "Epoch 403/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8215\n",
            "Epoch 404/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8117\n",
            "Epoch 405/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8146\n",
            "Epoch 406/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3953 - accuracy: 0.8293\n",
            "Epoch 407/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8390\n",
            "Epoch 408/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8468\n",
            "Epoch 409/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8273\n",
            "Epoch 410/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8390\n",
            "Epoch 411/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8244\n",
            "Epoch 412/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 0.8410\n",
            "Epoch 413/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8439\n",
            "Epoch 414/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8400\n",
            "Epoch 415/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8468\n",
            "Epoch 416/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8400\n",
            "Epoch 417/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3881 - accuracy: 0.8273\n",
            "Epoch 418/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.8351\n",
            "Epoch 419/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8244\n",
            "Epoch 420/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8283\n",
            "Epoch 421/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8429\n",
            "Epoch 422/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8420\n",
            "Epoch 423/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8429\n",
            "Epoch 424/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8293\n",
            "Epoch 425/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.8322\n",
            "Epoch 426/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8332\n",
            "Epoch 427/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8468\n",
            "Epoch 428/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8224\n",
            "Epoch 429/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8234\n",
            "Epoch 430/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8215\n",
            "Epoch 431/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.8088\n",
            "Epoch 432/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8293\n",
            "Epoch 433/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.8078\n",
            "Epoch 434/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3948 - accuracy: 0.8244\n",
            "Epoch 435/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8059\n",
            "Epoch 436/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8059\n",
            "Epoch 437/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8224\n",
            "Epoch 438/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8273\n",
            "Epoch 439/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8254\n",
            "Epoch 440/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8341\n",
            "Epoch 441/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3865 - accuracy: 0.8390\n",
            "Epoch 442/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.8566\n",
            "Epoch 443/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3710 - accuracy: 0.8400\n",
            "Epoch 444/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8322\n",
            "Epoch 445/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8380\n",
            "Epoch 446/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8478\n",
            "Epoch 447/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.8312\n",
            "Epoch 448/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3769 - accuracy: 0.8302\n",
            "Epoch 449/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8215\n",
            "Epoch 450/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8176\n",
            "Epoch 451/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8107\n",
            "Epoch 452/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8215\n",
            "Epoch 453/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.8205\n",
            "Epoch 454/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8117\n",
            "Epoch 455/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8205\n",
            "Epoch 456/500\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8283\n",
            "Epoch 457/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8146\n",
            "Epoch 458/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8234\n",
            "Epoch 459/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8302\n",
            "Epoch 460/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8410\n",
            "Epoch 461/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8322\n",
            "Epoch 462/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3933 - accuracy: 0.8312\n",
            "Epoch 463/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8283\n",
            "Epoch 464/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.8293\n",
            "Epoch 465/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8156\n",
            "Epoch 466/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.8098\n",
            "Epoch 467/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8185\n",
            "Epoch 468/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3829 - accuracy: 0.8322\n",
            "Epoch 469/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8420\n",
            "Epoch 470/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8117\n",
            "Epoch 471/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3850 - accuracy: 0.8302\n",
            "Epoch 472/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8410\n",
            "Epoch 473/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8234\n",
            "Epoch 474/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8117\n",
            "Epoch 475/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8293\n",
            "Epoch 476/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8263\n",
            "Epoch 477/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8254\n",
            "Epoch 478/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8224\n",
            "Epoch 479/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8332\n",
            "Epoch 480/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.8146\n",
            "Epoch 481/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8312\n",
            "Epoch 482/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.8390\n",
            "Epoch 483/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6113 - accuracy: 0.7015\n",
            "Epoch 484/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5124 - accuracy: 0.7346\n",
            "Epoch 485/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7590\n",
            "Epoch 486/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7717\n",
            "Epoch 487/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.8137\n",
            "Epoch 488/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7912\n",
            "Epoch 489/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.8166\n",
            "Epoch 490/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.8176\n",
            "Epoch 491/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.8234\n",
            "Epoch 492/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8273\n",
            "Epoch 493/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7161\n",
            "Epoch 494/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7980\n",
            "Epoch 495/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8059\n",
            "Epoch 496/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8273\n",
            "Epoch 497/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.8322\n",
            "Epoch 498/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8420\n",
            "Epoch 499/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8234\n",
            "Epoch 500/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8302\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 128)               1792      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10113 (39.50 KB)\n",
            "Trainable params: 10113 (39.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hasil Ketiga"
      ],
      "metadata": {
        "id": "AoYllxsjHDA-"
      },
      "id": "AoYllxsjHDA-"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "\n",
        "# Dataset\n",
        "X_train = np.column_stack([Age,Sex,ChestPain,RestBP,FBS,Cholesterol,RestECG,MaxHR,ExAng,OldPeak,SlopeOP,CA,Thal])\n",
        "y_train = Target\n",
        "\n",
        "# Building the Feedforward Neural Network model\n",
        "model = Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "model.add(Dense(units=256, activation='relu', input_shape=(13,)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Second hidden layer\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fitting the model to the training set\n",
        "model.fit(X_train, y_train, epochs=500, batch_size=32)\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5HIauNhHEjb",
        "outputId": "f3d66744-b159-47a7-b634-d52aef599dd3"
      },
      "id": "J5HIauNhHEjb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "33/33 [==============================] - 2s 5ms/step - loss: 12.1402 - accuracy: 0.4985\n",
            "Epoch 2/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 5.7517 - accuracy: 0.5161\n",
            "Epoch 3/500\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 3.1122 - accuracy: 0.5493\n",
            "Epoch 4/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 2.0767 - accuracy: 0.5580\n",
            "Epoch 5/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.2397 - accuracy: 0.5815\n",
            "Epoch 6/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9963 - accuracy: 0.5698\n",
            "Epoch 7/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8804 - accuracy: 0.5590\n",
            "Epoch 8/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7983 - accuracy: 0.5600\n",
            "Epoch 9/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7830 - accuracy: 0.5756\n",
            "Epoch 10/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7026 - accuracy: 0.5824\n",
            "Epoch 11/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7400 - accuracy: 0.5854\n",
            "Epoch 12/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7184 - accuracy: 0.5620\n",
            "Epoch 13/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7000 - accuracy: 0.6010\n",
            "Epoch 14/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7169 - accuracy: 0.5951\n",
            "Epoch 15/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6728 - accuracy: 0.6176\n",
            "Epoch 16/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6784 - accuracy: 0.6000\n",
            "Epoch 17/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6787 - accuracy: 0.5990\n",
            "Epoch 18/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.6107\n",
            "Epoch 19/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6631 - accuracy: 0.6146\n",
            "Epoch 20/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6627 - accuracy: 0.6244\n",
            "Epoch 21/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.5893\n",
            "Epoch 22/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6441 - accuracy: 0.6224\n",
            "Epoch 23/500\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6514 - accuracy: 0.6293\n",
            "Epoch 24/500\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6283\n",
            "Epoch 25/500\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.6538 - accuracy: 0.6371\n",
            "Epoch 26/500\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.6463 - accuracy: 0.6615\n",
            "Epoch 27/500\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6606 - accuracy: 0.6420\n",
            "Epoch 28/500\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6531 - accuracy: 0.6029\n",
            "Epoch 29/500\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.6308 - accuracy: 0.6459\n",
            "Epoch 30/500\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.6498 - accuracy: 0.6439\n",
            "Epoch 31/500\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6448 - accuracy: 0.6507\n",
            "Epoch 32/500\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.6413 - accuracy: 0.6390\n",
            "Epoch 33/500\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6168 - accuracy: 0.6644\n",
            "Epoch 34/500\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6348 - accuracy: 0.6137\n",
            "Epoch 35/500\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.6303 - accuracy: 0.6663\n",
            "Epoch 36/500\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.6251 - accuracy: 0.6595\n",
            "Epoch 37/500\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6202 - accuracy: 0.6556\n",
            "Epoch 38/500\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.6112 - accuracy: 0.6732\n",
            "Epoch 39/500\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6178 - accuracy: 0.6507\n",
            "Epoch 40/500\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.5920 - accuracy: 0.6868\n",
            "Epoch 41/500\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6215 - accuracy: 0.6761\n",
            "Epoch 42/500\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.6210 - accuracy: 0.6615\n",
            "Epoch 43/500\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.5970 - accuracy: 0.6820\n",
            "Epoch 44/500\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6160 - accuracy: 0.6810\n",
            "Epoch 45/500\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.6017 - accuracy: 0.6732\n",
            "Epoch 46/500\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.5959 - accuracy: 0.6868\n",
            "Epoch 47/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.6810\n",
            "Epoch 48/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5995 - accuracy: 0.6780\n",
            "Epoch 49/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7073\n",
            "Epoch 50/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.6820\n",
            "Epoch 51/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.6927\n",
            "Epoch 52/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.6907\n",
            "Epoch 53/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.6995\n",
            "Epoch 54/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.7151\n",
            "Epoch 55/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.7063\n",
            "Epoch 56/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7239\n",
            "Epoch 57/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5676 - accuracy: 0.7151\n",
            "Epoch 58/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.7132\n",
            "Epoch 59/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7122\n",
            "Epoch 60/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.7210\n",
            "Epoch 61/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5472 - accuracy: 0.7171\n",
            "Epoch 62/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.7210\n",
            "Epoch 63/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7307\n",
            "Epoch 64/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5492 - accuracy: 0.7044\n",
            "Epoch 65/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7093\n",
            "Epoch 66/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7268\n",
            "Epoch 67/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7151\n",
            "Epoch 68/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7093\n",
            "Epoch 69/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7278\n",
            "Epoch 70/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7366\n",
            "Epoch 71/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7512\n",
            "Epoch 72/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7366\n",
            "Epoch 73/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7346\n",
            "Epoch 74/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7610\n",
            "Epoch 75/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7473\n",
            "Epoch 76/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7415\n",
            "Epoch 77/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7512\n",
            "Epoch 78/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.7766\n",
            "Epoch 79/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7844\n",
            "Epoch 80/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7727\n",
            "Epoch 81/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7317\n",
            "Epoch 82/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7590\n",
            "Epoch 83/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7444\n",
            "Epoch 84/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7600\n",
            "Epoch 85/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7795\n",
            "Epoch 86/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7873\n",
            "Epoch 87/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7795\n",
            "Epoch 88/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7971\n",
            "Epoch 89/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.7571\n",
            "Epoch 90/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7629\n",
            "Epoch 91/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7698\n",
            "Epoch 92/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7639\n",
            "Epoch 93/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7776\n",
            "Epoch 94/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7971\n",
            "Epoch 95/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7941\n",
            "Epoch 96/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7971\n",
            "Epoch 97/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7834\n",
            "Epoch 98/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.8049\n",
            "Epoch 99/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.8039\n",
            "Epoch 100/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7932\n",
            "Epoch 101/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.8020\n",
            "Epoch 102/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.8020\n",
            "Epoch 103/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7912\n",
            "Epoch 104/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7922\n",
            "Epoch 105/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.8107\n",
            "Epoch 106/500\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.4575 - accuracy: 0.7941\n",
            "Epoch 107/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.8010\n",
            "Epoch 108/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.8068\n",
            "Epoch 109/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.8107\n",
            "Epoch 110/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.8059\n",
            "Epoch 111/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7883\n",
            "Epoch 112/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.8049\n",
            "Epoch 113/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.8000\n",
            "Epoch 114/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8185\n",
            "Epoch 115/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8068\n",
            "Epoch 116/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8176\n",
            "Epoch 117/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.8156\n",
            "Epoch 118/500\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.4225 - accuracy: 0.8156\n",
            "Epoch 119/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7746\n",
            "Epoch 120/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7912\n",
            "Epoch 121/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8068\n",
            "Epoch 122/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.8000\n",
            "Epoch 123/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8020\n",
            "Epoch 124/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.8039\n",
            "Epoch 125/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.8185\n",
            "Epoch 126/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.8039\n",
            "Epoch 127/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8293\n",
            "Epoch 128/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8039\n",
            "Epoch 129/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.8117\n",
            "Epoch 130/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8234\n",
            "Epoch 131/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8273\n",
            "Epoch 132/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8049\n",
            "Epoch 133/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8205\n",
            "Epoch 134/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8205\n",
            "Epoch 135/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8137\n",
            "Epoch 136/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8088\n",
            "Epoch 137/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4541 - accuracy: 0.8049\n",
            "Epoch 138/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8263\n",
            "Epoch 139/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8332\n",
            "Epoch 140/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3905 - accuracy: 0.8341\n",
            "Epoch 141/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8293\n",
            "Epoch 142/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8107\n",
            "Epoch 143/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8254\n",
            "Epoch 144/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8273\n",
            "Epoch 145/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8205\n",
            "Epoch 146/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8078\n",
            "Epoch 147/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.8020\n",
            "Epoch 148/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8049\n",
            "Epoch 149/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5093 - accuracy: 0.7551\n",
            "Epoch 150/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7893\n",
            "Epoch 151/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4789 - accuracy: 0.7698\n",
            "Epoch 152/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7941\n",
            "Epoch 153/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8185\n",
            "Epoch 154/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.7922\n",
            "Epoch 155/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8068\n",
            "Epoch 156/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8156\n",
            "Epoch 157/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8215\n",
            "Epoch 158/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8361\n",
            "Epoch 159/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.8166\n",
            "Epoch 160/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.8146\n",
            "Epoch 161/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8244\n",
            "Epoch 162/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7854\n",
            "Epoch 163/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.8059\n",
            "Epoch 164/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.8078\n",
            "Epoch 165/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8244\n",
            "Epoch 166/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8107\n",
            "Epoch 167/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8049\n",
            "Epoch 168/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8078\n",
            "Epoch 169/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.8254\n",
            "Epoch 170/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8244\n",
            "Epoch 171/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8244\n",
            "Epoch 172/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3906 - accuracy: 0.8263\n",
            "Epoch 173/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3785 - accuracy: 0.8371\n",
            "Epoch 174/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8263\n",
            "Epoch 175/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8137\n",
            "Epoch 176/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8098\n",
            "Epoch 177/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8293\n",
            "Epoch 178/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.8341\n",
            "Epoch 179/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3872 - accuracy: 0.8254\n",
            "Epoch 180/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8185\n",
            "Epoch 181/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8117\n",
            "Epoch 182/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8059\n",
            "Epoch 183/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.8185\n",
            "Epoch 184/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8234\n",
            "Epoch 185/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8185\n",
            "Epoch 186/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8049\n",
            "Epoch 187/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8332\n",
            "Epoch 188/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8176\n",
            "Epoch 189/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8215\n",
            "Epoch 190/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3954 - accuracy: 0.8263\n",
            "Epoch 191/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7844\n",
            "Epoch 192/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.8088\n",
            "Epoch 193/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.8205\n",
            "Epoch 194/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8146\n",
            "Epoch 195/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8146\n",
            "Epoch 196/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8439\n",
            "Epoch 197/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.8244\n",
            "Epoch 198/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8176\n",
            "Epoch 199/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8224\n",
            "Epoch 200/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8234\n",
            "Epoch 201/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8273\n",
            "Epoch 202/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.8263\n",
            "Epoch 203/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8195\n",
            "Epoch 204/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8312\n",
            "Epoch 205/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.8195\n",
            "Epoch 206/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8117\n",
            "Epoch 207/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3690 - accuracy: 0.8322\n",
            "Epoch 208/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8176\n",
            "Epoch 209/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8068\n",
            "Epoch 210/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8205\n",
            "Epoch 211/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8166\n",
            "Epoch 212/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8049\n",
            "Epoch 213/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7990\n",
            "Epoch 214/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8000\n",
            "Epoch 215/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.8068\n",
            "Epoch 216/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8039\n",
            "Epoch 217/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8137\n",
            "Epoch 218/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8176\n",
            "Epoch 219/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7922\n",
            "Epoch 220/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8039\n",
            "Epoch 221/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8176\n",
            "Epoch 222/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3910 - accuracy: 0.8283\n",
            "Epoch 223/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.8176\n",
            "Epoch 224/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8107\n",
            "Epoch 225/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8254\n",
            "Epoch 226/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.8117\n",
            "Epoch 227/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8371\n",
            "Epoch 228/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.8380\n",
            "Epoch 229/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8224\n",
            "Epoch 230/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8263\n",
            "Epoch 231/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8234\n",
            "Epoch 232/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8283\n",
            "Epoch 233/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8195\n",
            "Epoch 234/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3853 - accuracy: 0.8322\n",
            "Epoch 235/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3723 - accuracy: 0.8283\n",
            "Epoch 236/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3905 - accuracy: 0.8351\n",
            "Epoch 237/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8273\n",
            "Epoch 238/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8410\n",
            "Epoch 239/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3970 - accuracy: 0.8215\n",
            "Epoch 240/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3824 - accuracy: 0.8273\n",
            "Epoch 241/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8176\n",
            "Epoch 242/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8185\n",
            "Epoch 243/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8146\n",
            "Epoch 244/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8215\n",
            "Epoch 245/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.8215\n",
            "Epoch 246/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8010\n",
            "Epoch 247/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8059\n",
            "Epoch 248/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8156\n",
            "Epoch 249/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8088\n",
            "Epoch 250/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8146\n",
            "Epoch 251/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8098\n",
            "Epoch 252/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3884 - accuracy: 0.8283\n",
            "Epoch 253/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7590\n",
            "Epoch 254/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7971\n",
            "Epoch 255/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.8049\n",
            "Epoch 256/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.8156\n",
            "Epoch 257/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7961\n",
            "Epoch 258/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8039\n",
            "Epoch 259/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8156\n",
            "Epoch 260/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8185\n",
            "Epoch 261/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8137\n",
            "Epoch 262/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8059\n",
            "Epoch 263/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.8185\n",
            "Epoch 264/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8078\n",
            "Epoch 265/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8224\n",
            "Epoch 266/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8078\n",
            "Epoch 267/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8322\n",
            "Epoch 268/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8010\n",
            "Epoch 269/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8224\n",
            "Epoch 270/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8176\n",
            "Epoch 271/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3834 - accuracy: 0.8254\n",
            "Epoch 272/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8224\n",
            "Epoch 273/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.8332\n",
            "Epoch 274/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8205\n",
            "Epoch 275/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8098\n",
            "Epoch 276/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8429\n",
            "Epoch 277/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8137\n",
            "Epoch 278/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7902\n",
            "Epoch 279/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8332\n",
            "Epoch 280/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8176\n",
            "Epoch 281/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8195\n",
            "Epoch 282/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8215\n",
            "Epoch 283/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.8263\n",
            "Epoch 284/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8205\n",
            "Epoch 285/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8098\n",
            "Epoch 286/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.8029\n",
            "Epoch 287/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8098\n",
            "Epoch 288/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8117\n",
            "Epoch 289/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8098\n",
            "Epoch 290/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.8351\n",
            "Epoch 291/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8146\n",
            "Epoch 292/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8224\n",
            "Epoch 293/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3568 - accuracy: 0.8322\n",
            "Epoch 294/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8293\n",
            "Epoch 295/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3806 - accuracy: 0.8273\n",
            "Epoch 296/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3749 - accuracy: 0.8351\n",
            "Epoch 297/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8322\n",
            "Epoch 298/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.8273\n",
            "Epoch 299/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8283\n",
            "Epoch 300/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3838 - accuracy: 0.8205\n",
            "Epoch 301/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3794 - accuracy: 0.8302\n",
            "Epoch 302/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8263\n",
            "Epoch 303/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8322\n",
            "Epoch 304/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7502\n",
            "Epoch 305/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7971\n",
            "Epoch 306/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8332\n",
            "Epoch 307/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8205\n",
            "Epoch 308/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8195\n",
            "Epoch 309/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8429\n",
            "Epoch 310/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8371\n",
            "Epoch 311/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8332\n",
            "Epoch 312/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8293\n",
            "Epoch 313/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8254\n",
            "Epoch 314/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8098\n",
            "Epoch 315/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8039\n",
            "Epoch 316/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8205\n",
            "Epoch 317/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8244\n",
            "Epoch 318/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8293\n",
            "Epoch 319/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8254\n",
            "Epoch 320/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8224\n",
            "Epoch 321/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7912\n",
            "Epoch 322/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8302\n",
            "Epoch 323/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8107\n",
            "Epoch 324/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8273\n",
            "Epoch 325/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8332\n",
            "Epoch 326/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7678\n",
            "Epoch 327/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8273\n",
            "Epoch 328/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3927 - accuracy: 0.8302\n",
            "Epoch 329/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.8078\n",
            "Epoch 330/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8302\n",
            "Epoch 331/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8322\n",
            "Epoch 332/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.8234\n",
            "Epoch 333/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3938 - accuracy: 0.8322\n",
            "Epoch 334/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8312\n",
            "Epoch 335/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8449\n",
            "Epoch 336/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3737 - accuracy: 0.8459\n",
            "Epoch 337/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8322\n",
            "Epoch 338/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8351\n",
            "Epoch 339/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8380\n",
            "Epoch 340/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8361\n",
            "Epoch 341/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8468\n",
            "Epoch 342/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8371\n",
            "Epoch 343/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8351\n",
            "Epoch 344/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8488\n",
            "Epoch 345/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3911 - accuracy: 0.8293\n",
            "Epoch 346/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 0.8332\n",
            "Epoch 347/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.8302\n",
            "Epoch 348/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3848 - accuracy: 0.8332\n",
            "Epoch 349/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8302\n",
            "Epoch 350/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3842 - accuracy: 0.8341\n",
            "Epoch 351/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.8371\n",
            "Epoch 352/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3911 - accuracy: 0.8361\n",
            "Epoch 353/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8156\n",
            "Epoch 354/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3882 - accuracy: 0.8312\n",
            "Epoch 355/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8341\n",
            "Epoch 356/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8380\n",
            "Epoch 357/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3779 - accuracy: 0.8332\n",
            "Epoch 358/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8332\n",
            "Epoch 359/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3804 - accuracy: 0.8449\n",
            "Epoch 360/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8293\n",
            "Epoch 361/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8283\n",
            "Epoch 362/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8205\n",
            "Epoch 363/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8380\n",
            "Epoch 364/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3691 - accuracy: 0.8390\n",
            "Epoch 365/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8400\n",
            "Epoch 366/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8410\n",
            "Epoch 367/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8390\n",
            "Epoch 368/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8332\n",
            "Epoch 369/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8371\n",
            "Epoch 370/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8283\n",
            "Epoch 371/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8283\n",
            "Epoch 372/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8224\n",
            "Epoch 373/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8244\n",
            "Epoch 374/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8420\n",
            "Epoch 375/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.8322\n",
            "Epoch 376/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3894 - accuracy: 0.8439\n",
            "Epoch 377/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8176\n",
            "Epoch 378/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8283\n",
            "Epoch 379/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7922\n",
            "Epoch 380/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8332\n",
            "Epoch 381/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8312\n",
            "Epoch 382/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8156\n",
            "Epoch 383/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3763 - accuracy: 0.8439\n",
            "Epoch 384/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8107\n",
            "Epoch 385/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.8380\n",
            "Epoch 386/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3767 - accuracy: 0.8322\n",
            "Epoch 387/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8410\n",
            "Epoch 388/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8420\n",
            "Epoch 389/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8293\n",
            "Epoch 390/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.8341\n",
            "Epoch 391/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3712 - accuracy: 0.8459\n",
            "Epoch 392/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8341\n",
            "Epoch 393/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8293\n",
            "Epoch 394/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3597 - accuracy: 0.8478\n",
            "Epoch 395/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3896 - accuracy: 0.8302\n",
            "Epoch 396/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8312\n",
            "Epoch 397/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8361\n",
            "Epoch 398/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.8322\n",
            "Epoch 399/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8322\n",
            "Epoch 400/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8517\n",
            "Epoch 401/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8429\n",
            "Epoch 402/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3781 - accuracy: 0.8380\n",
            "Epoch 403/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8439\n",
            "Epoch 404/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8380\n",
            "Epoch 405/500\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8537\n",
            "Epoch 406/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3742 - accuracy: 0.8420\n",
            "Epoch 407/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.8322\n",
            "Epoch 408/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8410\n",
            "Epoch 409/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.8380\n",
            "Epoch 410/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.8420\n",
            "Epoch 411/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3652 - accuracy: 0.8410\n",
            "Epoch 412/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8400\n",
            "Epoch 413/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3686 - accuracy: 0.8537\n",
            "Epoch 414/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.8371\n",
            "Epoch 415/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.8166\n",
            "Epoch 416/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8254\n",
            "Epoch 417/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8459\n",
            "Epoch 418/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8205\n",
            "Epoch 419/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8078\n",
            "Epoch 420/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8224\n",
            "Epoch 421/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8371\n",
            "Epoch 422/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8341\n",
            "Epoch 423/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8205\n",
            "Epoch 424/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8273\n",
            "Epoch 425/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8302\n",
            "Epoch 426/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3761 - accuracy: 0.8390\n",
            "Epoch 427/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3804 - accuracy: 0.8371\n",
            "Epoch 428/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.8244\n",
            "Epoch 429/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8185\n",
            "Epoch 430/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8400\n",
            "Epoch 431/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 0.8283\n",
            "Epoch 432/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3884 - accuracy: 0.8312\n",
            "Epoch 433/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8312\n",
            "Epoch 434/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3873 - accuracy: 0.8380\n",
            "Epoch 435/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.8380\n",
            "Epoch 436/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3765 - accuracy: 0.8380\n",
            "Epoch 437/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.8380\n",
            "Epoch 438/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8420\n",
            "Epoch 439/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8361\n",
            "Epoch 440/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3830 - accuracy: 0.8390\n",
            "Epoch 441/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8468\n",
            "Epoch 442/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3679 - accuracy: 0.8420\n",
            "Epoch 443/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.8332\n",
            "Epoch 444/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8410\n",
            "Epoch 445/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3652 - accuracy: 0.8468\n",
            "Epoch 446/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3623 - accuracy: 0.8488\n",
            "Epoch 447/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3718 - accuracy: 0.8390\n",
            "Epoch 448/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8234\n",
            "Epoch 449/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3744 - accuracy: 0.8351\n",
            "Epoch 450/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.8400\n",
            "Epoch 451/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8459\n",
            "Epoch 452/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8400\n",
            "Epoch 453/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3651 - accuracy: 0.8429\n",
            "Epoch 454/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8273\n",
            "Epoch 455/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3692 - accuracy: 0.8459\n",
            "Epoch 456/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8351\n",
            "Epoch 457/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8312\n",
            "Epoch 458/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8176\n",
            "Epoch 459/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8078\n",
            "Epoch 460/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3749 - accuracy: 0.8332\n",
            "Epoch 461/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.8244\n",
            "Epoch 462/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8400\n",
            "Epoch 463/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8351\n",
            "Epoch 464/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8293\n",
            "Epoch 465/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8400\n",
            "Epoch 466/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3905 - accuracy: 0.8302\n",
            "Epoch 467/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8449\n",
            "Epoch 468/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8322\n",
            "Epoch 469/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.8215\n",
            "Epoch 470/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7600\n",
            "Epoch 471/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8371\n",
            "Epoch 472/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.8273\n",
            "Epoch 473/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8488\n",
            "Epoch 474/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.8420\n",
            "Epoch 475/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8322\n",
            "Epoch 476/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3698 - accuracy: 0.8400\n",
            "Epoch 477/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3779 - accuracy: 0.8439\n",
            "Epoch 478/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8390\n",
            "Epoch 479/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8234\n",
            "Epoch 480/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8380\n",
            "Epoch 481/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8215\n",
            "Epoch 482/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8078\n",
            "Epoch 483/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.8254\n",
            "Epoch 484/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8215\n",
            "Epoch 485/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8449\n",
            "Epoch 486/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3744 - accuracy: 0.8468\n",
            "Epoch 487/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8156\n",
            "Epoch 488/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.8361\n",
            "Epoch 489/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8322\n",
            "Epoch 490/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3797 - accuracy: 0.8361\n",
            "Epoch 491/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8283\n",
            "Epoch 492/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8410\n",
            "Epoch 493/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8195\n",
            "Epoch 494/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8263\n",
            "Epoch 495/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8322\n",
            "Epoch 496/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3749 - accuracy: 0.8322\n",
            "Epoch 497/500\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8371\n",
            "Epoch 498/500\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8156\n",
            "Epoch 499/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8322\n",
            "Epoch 500/500\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3814 - accuracy: 0.8361\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 256)               3584      \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 36609 (143.00 KB)\n",
            "Trainable params: 36609 (143.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifications with CNN (with PCA)"
      ],
      "metadata": {
        "id": "gxuFxat_Ug2c"
      },
      "id": "gxuFxat_Ug2c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Data with PCA\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming 'data' is your multivariable dataset\n",
        "# Step 1: Standardize the data\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(dataset.iloc[:,0:13])\n",
        "\n",
        "# Step 2: Initialize PCA and fit to the scaled data\n",
        "pca = PCA(n_components=9)  # Set the number of components to 2\n",
        "pca.fit(scaled_data)\n",
        "\n",
        "# Step 3: Project data onto principal components\n",
        "reduced_data = pca.transform(scaled_data)\n",
        "data_CNN = pd.concat([pd.DataFrame(reduced_data), Target], axis=1)"
      ],
      "metadata": {
        "id": "ecmxxW5MUoEk"
      },
      "id": "ecmxxW5MUoEk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_CNN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "9_Ekz7L0ZPQ1",
        "outputId": "dc7823a8-6a40-4ec2-c5ff-249d445c6227"
      },
      "id": "9_Ekz7L0ZPQ1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "0    -0.522556 -1.112803  0.956816 -1.149198 -0.559252 -1.505052  0.071292   \n",
              "1     2.590381 -0.533162  1.467315  1.536614  1.345335  1.524630  1.469460   \n",
              "2     3.042352 -1.327521 -0.424765  1.567204  0.283814 -0.738182  0.378211   \n",
              "3    -0.492522 -0.276720  0.801442 -0.984277 -0.487587 -1.438634  0.385833   \n",
              "4     2.187464  1.951477 -0.385539  0.295793 -2.386144 -0.563839  1.022689   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1020 -0.762321 -0.512273  0.046672 -0.308011 -0.415454  0.083938  0.957084   \n",
              "1021  2.374273 -0.940859  0.182370 -0.628459  0.822406  0.373266 -0.493855   \n",
              "1022  1.245073 -1.457356 -0.473873 -0.645240 -0.271197  1.786723 -0.623980   \n",
              "1023 -1.620053  0.124443 -1.327956 -1.196804 -0.224913  1.263473 -0.498017   \n",
              "1024  0.934169 -1.778549 -0.005882  0.353372 -0.743381 -1.034172 -0.484996   \n",
              "\n",
              "             7         8  target  \n",
              "0     0.049732  0.872570       0  \n",
              "1     0.594801 -0.127561       0  \n",
              "2    -1.397097 -0.836844       0  \n",
              "3    -1.566671  0.085219       0  \n",
              "4     1.682067  0.451377       0  \n",
              "...        ...       ...     ...  \n",
              "1020 -1.517729 -0.519319       1  \n",
              "1021  0.086828 -0.050143       0  \n",
              "1022  0.614532 -0.084198       0  \n",
              "1023  0.265437  0.345972       1  \n",
              "1024 -0.130881 -0.428642       0  \n",
              "\n",
              "[1025 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18cf04bf-5dcd-41f8-9340-779d02b8cafd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.522556</td>\n",
              "      <td>-1.112803</td>\n",
              "      <td>0.956816</td>\n",
              "      <td>-1.149198</td>\n",
              "      <td>-0.559252</td>\n",
              "      <td>-1.505052</td>\n",
              "      <td>0.071292</td>\n",
              "      <td>0.049732</td>\n",
              "      <td>0.872570</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.590381</td>\n",
              "      <td>-0.533162</td>\n",
              "      <td>1.467315</td>\n",
              "      <td>1.536614</td>\n",
              "      <td>1.345335</td>\n",
              "      <td>1.524630</td>\n",
              "      <td>1.469460</td>\n",
              "      <td>0.594801</td>\n",
              "      <td>-0.127561</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.042352</td>\n",
              "      <td>-1.327521</td>\n",
              "      <td>-0.424765</td>\n",
              "      <td>1.567204</td>\n",
              "      <td>0.283814</td>\n",
              "      <td>-0.738182</td>\n",
              "      <td>0.378211</td>\n",
              "      <td>-1.397097</td>\n",
              "      <td>-0.836844</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.492522</td>\n",
              "      <td>-0.276720</td>\n",
              "      <td>0.801442</td>\n",
              "      <td>-0.984277</td>\n",
              "      <td>-0.487587</td>\n",
              "      <td>-1.438634</td>\n",
              "      <td>0.385833</td>\n",
              "      <td>-1.566671</td>\n",
              "      <td>0.085219</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.187464</td>\n",
              "      <td>1.951477</td>\n",
              "      <td>-0.385539</td>\n",
              "      <td>0.295793</td>\n",
              "      <td>-2.386144</td>\n",
              "      <td>-0.563839</td>\n",
              "      <td>1.022689</td>\n",
              "      <td>1.682067</td>\n",
              "      <td>0.451377</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1020</th>\n",
              "      <td>-0.762321</td>\n",
              "      <td>-0.512273</td>\n",
              "      <td>0.046672</td>\n",
              "      <td>-0.308011</td>\n",
              "      <td>-0.415454</td>\n",
              "      <td>0.083938</td>\n",
              "      <td>0.957084</td>\n",
              "      <td>-1.517729</td>\n",
              "      <td>-0.519319</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021</th>\n",
              "      <td>2.374273</td>\n",
              "      <td>-0.940859</td>\n",
              "      <td>0.182370</td>\n",
              "      <td>-0.628459</td>\n",
              "      <td>0.822406</td>\n",
              "      <td>0.373266</td>\n",
              "      <td>-0.493855</td>\n",
              "      <td>0.086828</td>\n",
              "      <td>-0.050143</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1022</th>\n",
              "      <td>1.245073</td>\n",
              "      <td>-1.457356</td>\n",
              "      <td>-0.473873</td>\n",
              "      <td>-0.645240</td>\n",
              "      <td>-0.271197</td>\n",
              "      <td>1.786723</td>\n",
              "      <td>-0.623980</td>\n",
              "      <td>0.614532</td>\n",
              "      <td>-0.084198</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023</th>\n",
              "      <td>-1.620053</td>\n",
              "      <td>0.124443</td>\n",
              "      <td>-1.327956</td>\n",
              "      <td>-1.196804</td>\n",
              "      <td>-0.224913</td>\n",
              "      <td>1.263473</td>\n",
              "      <td>-0.498017</td>\n",
              "      <td>0.265437</td>\n",
              "      <td>0.345972</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1024</th>\n",
              "      <td>0.934169</td>\n",
              "      <td>-1.778549</td>\n",
              "      <td>-0.005882</td>\n",
              "      <td>0.353372</td>\n",
              "      <td>-0.743381</td>\n",
              "      <td>-1.034172</td>\n",
              "      <td>-0.484996</td>\n",
              "      <td>-0.130881</td>\n",
              "      <td>-0.428642</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1025 rows  10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18cf04bf-5dcd-41f8-9340-779d02b8cafd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-18cf04bf-5dcd-41f8-9340-779d02b8cafd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-18cf04bf-5dcd-41f8-9340-779d02b8cafd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1bcb32b3-edbf-4a96-93e3-00c285964973\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1bcb32b3-edbf-4a96-93e3-00c285964973')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1bcb32b3-edbf-4a96-93e3-00c285964973 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_CNN",
              "summary": "{\n  \"name\": \"data_CNN\",\n  \"rows\": 1025,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6675735655841608,\n        \"min\": -3.4586086144922765,\n        \"max\": 4.583909283982099,\n        \"num_unique_values\": 303,\n        \"samples\": [\n          -2.3412864512887848,\n          0.9891126170587019,\n          2.2170888922443646\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2481484459916556,\n        \"min\": -3.134033738567055,\n        \"max\": 4.187313106983563,\n        \"num_unique_values\": 302,\n        \"samples\": [\n          -0.3270354838032014,\n          0.6662475461635857,\n          2.300571114702865\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0964318413251997,\n        \"min\": -2.8268767006099806,\n        \"max\": 2.960454320384006,\n        \"num_unique_values\": 303,\n        \"samples\": [\n          0.8504045502477612,\n          -1.4325132645389362,\n          0.19479014644924497\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0818349908467542,\n        \"min\": -2.6450166697944266,\n        \"max\": 3.6307719782206527,\n        \"num_unique_values\": 303,\n        \"samples\": [\n          -0.4399360983310711,\n          0.5086463392547097,\n          1.4283478756552392\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000730040622325,\n        \"min\": -2.6863904051600342,\n        \"max\": 3.340093478854618,\n        \"num_unique_values\": 303,\n        \"samples\": [\n          0.748211334391176,\n          -0.4353576891618498,\n          -1.139565346465647\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.986556404364596,\n        \"min\": -2.4676130350641263,\n        \"max\": 2.716672467305502,\n        \"num_unique_values\": 302,\n        \"samples\": [\n          0.9845284758829571,\n          -1.7133317268480053,\n          1.8970993140488566\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9366365123381872,\n        \"min\": -2.131441524101399,\n        \"max\": 3.15573404612295,\n        \"num_unique_values\": 303,\n        \"samples\": [\n          -0.4227807698474417,\n          -0.5626434372239433,\n          1.7191383441141512\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8767753946333379,\n        \"min\": -2.191538212811809,\n        \"max\": 3.080578524097178,\n        \"num_unique_values\": 303,\n        \"samples\": [\n          -0.5025644239614342,\n          0.23570822492979754,\n          -0.20976623606883452\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8524361560139502,\n        \"min\": -2.144796640918775,\n        \"max\": 3.1688733149258894,\n        \"num_unique_values\": 302,\n        \"samples\": [\n          0.7342023990011279,\n          -1.3217077578435554,\n          2.153026141899078\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data_CNN.iloc[:, 0:9].values, data_CNN['target'].values, train_size=0.8,\n",
        "                                                    test_size=0.2, random_state=2, shuffle=True, stratify=data_CNN['target'].values)\n",
        "\n",
        "if 0.7*x_train.shape[0] < 2500:\n",
        "    train_split = 0.8\n",
        "else:\n",
        "    train_split = 0.7\n",
        "# train_split = 0.7\n",
        "print('train_split =',train_split)\n",
        "x_train, x_cv, y_train, y_cv = train_test_split(x_train, y_train, train_size=train_split,\n",
        "                                                random_state=2, shuffle=True, stratify=y_train)\n",
        "mm_scaler = MinMaxScaler(feature_range=(0, 1)) # or StandardScaler?\n",
        "x_train = mm_scaler.fit_transform(x_train)\n",
        "x_cv = mm_scaler.transform(x_cv)\n",
        "x_test = mm_scaler.transform(x_test)\n",
        "\n",
        "x_main = x_train.copy()\n",
        "print(\"Shape of x, y train/cv/test {} {} {} {} {} {}\".format(x_train.shape, y_train.shape, x_cv.shape, y_cv.shape, x_test.shape, y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO6Ub5V4ZvM0",
        "outputId": "89457256-5501-49ba-a09a-e50147d4fb5d"
      },
      "id": "DO6Ub5V4ZvM0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_split = 0.8\n",
            "Shape of x, y train/cv/test (656, 9) (656,) (164, 9) (164,) (205, 9) (205,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "def get_sample_weights(y):\n",
        "    \"\"\"\n",
        "    calculate the sample weights based on class weights. Used for models with\n",
        "    imbalanced data and one hot encoding prediction.\n",
        "\n",
        "    params:\n",
        "        y: class labels as integers\n",
        "    \"\"\"\n",
        "\n",
        "    y = y.astype(int)  # compute_class_weight needs int labels\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
        "\n",
        "    print(\"real class weights are {}\".format(class_weights), np.unique(y))\n",
        "    print(\"value_counts\", np.unique(y, return_counts=True))\n",
        "    sample_weights = y.copy().astype(float)\n",
        "    for i in np.unique(y):\n",
        "        sample_weights[sample_weights == i] = class_weights[i]  # if i == 2 else 0.8 * class_weights[i]\n",
        "        # sample_weights = np.where(sample_weights == i, class_weights[int(i)], y_)\n",
        "\n",
        "    return sample_weights\n",
        "\n",
        "def reshape_as_image(x, img_width, img_height):\n",
        "    x_temp = np.zeros((len(x), img_height, img_width))\n",
        "    for i in range(x.shape[0]):\n",
        "        # print(type(x), type(x_temp), x.shape)\n",
        "        x_temp[i] = np.reshape(x[i], (img_height, img_width))\n",
        "\n",
        "    return x_temp\n",
        "\n",
        "def f1_weighted(y_true, y_pred):\n",
        "    y_true_class = tf.math.argmax(y_true, axis=1, output_type=tf.dtypes.int32)\n",
        "    y_pred_class = tf.math.argmax(y_pred, axis=1, output_type=tf.dtypes.int32)\n",
        "    conf_mat = tf.math.confusion_matrix(y_true_class, y_pred_class)  # can use conf_mat[0, :], tf.slice()\n",
        "    # precision = TP/TP+FP, recall = TP/TP+FN\n",
        "    rows, cols = conf_mat.get_shape()\n",
        "    size = y_true_class.get_shape()[0]\n",
        "    precision = tf.constant([0, 0, 0])  # change this to use rows/cols as size\n",
        "    recall = tf.constant([0, 0, 0])\n",
        "    class_counts = tf.constant([0, 0, 0])\n",
        "\n",
        "    def get_precision(i, conf_mat):\n",
        "        print(\"prec check\", conf_mat, conf_mat[i, i], tf.reduce_sum(conf_mat[:, i]))\n",
        "        precision[i].assign(conf_mat[i, i] / tf.reduce_sum(conf_mat[:, i]))\n",
        "        recall[i].assign(conf_mat[i, i] / tf.reduce_sum(conf_mat[i, :]))\n",
        "        tf.add(i, 1)\n",
        "        return i, conf_mat, precision, recall\n",
        "\n",
        "    def tf_count(i):\n",
        "        elements_equal_to_value = tf.equal(y_true_class, i)\n",
        "        as_ints = tf.cast(elements_equal_to_value, tf.int32)\n",
        "        count = tf.reduce_sum(as_ints)\n",
        "        class_counts[i].assign(count)\n",
        "        tf.add(i, 1)\n",
        "        return count\n",
        "\n",
        "    def condition(i, conf_mat):\n",
        "        return tf.less(i, 3)\n",
        "\n",
        "    i = tf.constant(3)\n",
        "    i, conf_mat = tf.while_loop(condition, get_precision, [i, conf_mat])\n",
        "\n",
        "    i = tf.constant(3)\n",
        "    c = lambda i: tf.less(i, 3)\n",
        "    b = tf_count(i)\n",
        "    tf.while_loop(c, b, [i])\n",
        "\n",
        "    weights = tf.math.divide(class_counts, size)\n",
        "    numerators = tf.math.multiply(tf.math.multiply(precision, recall), tf.constant(2))\n",
        "    denominators = tf.math.add(precision, recall)\n",
        "    f1s = tf.math.divide(numerators, denominators)\n",
        "    weighted_f1 = tf.reduce_sum(f.math.multiply(f1s, weights))\n",
        "    return weighted_f1\n",
        "\n",
        "def f1_metric(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    this calculates precision & recall\n",
        "    \"\"\"\n",
        "\n",
        "    def recall(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))  # mistake: y_pred of 0.3 is also considered 1\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    # y_true_class = tf.math.argmax(y_true, axis=1, output_type=tf.dtypes.int32)\n",
        "    # y_pred_class = tf.math.argmax(y_pred, axis=1, output_type=tf.dtypes.int32)\n",
        "    # conf_mat = tf.math.confusion_matrix(y_true_class, y_pred_class)\n",
        "    # tf.Print(conf_mat, [conf_mat], \"confusion_matrix\")\n",
        "\n",
        "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
        "\n",
        "get_custom_objects().update({\"f1_metric\": f1_metric, \"f1_weighted\": f1_weighted})"
      ],
      "metadata": {
        "id": "S-Mw65CyarPV"
      },
      "id": "S-Mw65CyarPV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_weights = get_sample_weights(y_train)\n",
        "print(\"Test sample_weights\")\n",
        "rand_idx = np.random.randint(0, 650, 30)\n",
        "print(y_train[rand_idx])\n",
        "print(sample_weights[rand_idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE0NSV6nooGK",
        "outputId": "3d65e491-1574-4519-bc8a-3c0f7b9706b1"
      },
      "id": "fE0NSV6nooGK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "real class weights are [1.02821317 0.97329377] [0 1]\n",
            "value_counts (array([0, 1]), array([319, 337]))\n",
            "Test sample_weights\n",
            "[0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0]\n",
            "[1.02821317 0.97329377 0.97329377 0.97329377 0.97329377 1.02821317\n",
            " 1.02821317 0.97329377 0.97329377 0.97329377 0.97329377 0.97329377\n",
            " 1.02821317 1.02821317 0.97329377 1.02821317 0.97329377 0.97329377\n",
            " 0.97329377 0.97329377 0.97329377 0.97329377 0.97329377 1.02821317\n",
            " 0.97329377 1.02821317 1.02821317 0.97329377 0.97329377 1.02821317]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_enc = OneHotEncoder(sparse_output=False, categories='auto')  # , categories='auto'\n",
        "y_train = one_hot_enc.fit_transform(y_train.reshape(-1, 1))\n",
        "print(\"y_train\",y_train.shape)\n",
        "y_cv = one_hot_enc.transform(y_cv.reshape(-1, 1))\n",
        "y_test = one_hot_enc.transform(y_test.reshape(-1, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MK6OpNGaOn4",
        "outputId": "c8c3d8ae-4975-4c38-a9f6-d9a8bc8a71c5"
      },
      "id": "-MK6OpNGaOn4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train (656, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim = int(np.sqrt(9))\n",
        "x_train = reshape_as_image(x_train, dim, dim)\n",
        "x_cv = reshape_as_image(x_cv, dim, dim)\n",
        "x_test = reshape_as_image(x_test, dim, dim)\n",
        "# adding a 1-dim for channels (3)\n",
        "x_train = np.stack((x_train,) * 3, axis=-1)\n",
        "x_test = np.stack((x_test,) * 3, axis=-1)\n",
        "x_cv = np.stack((x_cv,) * 3, axis=-1)\n",
        "print(\"final shape of x, y train/test {} {} {} {}\".format(x_train.shape, y_train.shape, x_test.shape, y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKzPd-QOavws",
        "outputId": "1cb61d91-34d2-4534-dc7f-682dd3f0be74"
      },
      "id": "fKzPd-QOavws",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final shape of x, y train/test (656, 3, 3, 3) (656, 2) (205, 3, 3, 3) (205, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "columns = rows = 5\n",
        "for i in range(1, columns*rows +1):\n",
        "    index = np.random.randint(len(x_train))\n",
        "    img = x_train[index]\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title('image_'+str(index)+'_class_'+str(np.argmax(y_train[index])), fontsize=10)\n",
        "    plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
        "    plt.imshow(img)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "hJlumDlVbbeO",
        "outputId": "0c772aae-a792-4af2-91ea-b78bf04a4cd0"
      },
      "id": "hJlumDlVbbeO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 25 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, LeakyReLU\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, Callback\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
        "from tensorflow.keras.initializers import RandomUniform, RandomNormal\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "params = {'batch_size': 80, 'conv2d_layers': {'conv2d_do_1': 0.22, 'conv2d_filters_1': 20, 'conv2d_kernel_size_1': 2, 'conv2d_mp_1': 2,\n",
        "                                              'conv2d_strides_1': 1, 'kernel_regularizer_1': 0.0, 'conv2d_do_2': 0.05,\n",
        "                                              'conv2d_filters_2': 40, 'conv2d_kernel_size_2': 2, 'conv2d_mp_2': 2, 'conv2d_strides_2': 2,\n",
        "                                              'kernel_regularizer_2': 0.0, 'layers': 'two'},\n",
        "          'dense_layers': {'dense_do_1': 0.22, 'dense_nodes_1': 100, 'kernel_regularizer_1': 0.0, 'layers': 'one'},\n",
        "          'epochs': 300, 'lr': 0.001, 'optimizer': 'adam'}"
      ],
      "metadata": {
        "id": "tmKFF7bFoAkR"
      },
      "id": "tmKFF7bFoAkR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import *\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.metrics import AUC\n",
        "\n",
        "def f1_custom(y_true, y_pred):\n",
        "    y_t = np.argmax(y_true, axis=1)\n",
        "    y_p = np.argmax(y_pred, axis=1)\n",
        "    f1_score(y_t, y_p, labels=None, average='weighted', sample_weight=None, zero_division='warn')\n",
        "\n",
        "def create_model_cnn(params):\n",
        "    model = Sequential()\n",
        "\n",
        "    print(\"Training with params {}\".format(params))\n",
        "    # (batch_size, timesteps, data_dim)\n",
        "    # x_train, y_train = get_data_cnn(df, df.head(1).iloc[0][\"timestamp\"])[0:2]\n",
        "    conv2d_layer1 = Conv2D(params[\"conv2d_layers\"][\"conv2d_filters_1\"],\n",
        "                           params[\"conv2d_layers\"][\"conv2d_kernel_size_1\"],\n",
        "                           strides=params[\"conv2d_layers\"][\"conv2d_strides_1\"],\n",
        "                           kernel_regularizer=regularizers.l2(params[\"conv2d_layers\"][\"kernel_regularizer_1\"]),\n",
        "                           padding='valid',activation=\"relu\", use_bias=True,\n",
        "                           kernel_initializer='glorot_uniform',\n",
        "                           input_shape=(x_train[0].shape[0],\n",
        "                                        x_train[0].shape[1], x_train[0].shape[2]))\n",
        "    model.add(conv2d_layer1)\n",
        "    if params[\"conv2d_layers\"]['conv2d_mp_1'] == 1:\n",
        "        model.add(MaxPool2D(pool_size=2))\n",
        "    model.add(Dropout(params['conv2d_layers']['conv2d_do_1']))\n",
        "    if params[\"conv2d_layers\"]['layers'] == 'two':\n",
        "        conv2d_layer2 = Conv2D(params[\"conv2d_layers\"][\"conv2d_filters_2\"],\n",
        "                               params[\"conv2d_layers\"][\"conv2d_kernel_size_2\"],\n",
        "                               strides=params[\"conv2d_layers\"][\"conv2d_strides_2\"],\n",
        "                               kernel_regularizer=regularizers.l2(params[\"conv2d_layers\"][\"kernel_regularizer_2\"]),\n",
        "                               padding='valid',activation=\"relu\", use_bias=True,\n",
        "                               kernel_initializer='glorot_uniform')\n",
        "        model.add(conv2d_layer2)\n",
        "        if params[\"conv2d_layers\"]['conv2d_mp_2'] == 1:\n",
        "            model.add(MaxPool2D(pool_size=2))\n",
        "        model.add(Dropout(params['conv2d_layers']['conv2d_do_2']))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(params['dense_layers'][\"dense_nodes_1\"], activation='relu'))\n",
        "    model.add(Dropout(params['dense_layers']['dense_do_1']))\n",
        "\n",
        "    if params['dense_layers'][\"layers\"] == 'two':\n",
        "        model.add(Dense(params['dense_layers'][\"dense_nodes_2\"], activation='relu',\n",
        "                        kernel_regularizer=params['dense_layers'][\"kernel_regularizer_1\"]))\n",
        "        model.add(Dropout(params['dense_layers']['dense_do_2']))\n",
        "\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    if params[\"optimizer\"] == 'rmsprop':\n",
        "        optimizer = optimizers.RMSprop(lr=params[\"lr\"])\n",
        "    elif params[\"optimizer\"] == 'sgd':\n",
        "        optimizer = optimizers.SGD(lr=params[\"lr\"], decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    elif params[\"optimizer\"] == 'adam':\n",
        "        optimizer = optimizers.Adam(learning_rate=params[\"lr\"], beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', f1_metric])\n",
        "    # from keras.utils.vis_utils import plot_model use this too for diagram with plot\n",
        "    # model.summary(print_fn=lambda x: print(x + '\\n'))\n",
        "    return model\n",
        "\n",
        "def check_baseline(pred, y_test):\n",
        "    print(\"size of test set\", len(y_test))\n",
        "    e = np.equal(pred, y_test)\n",
        "    print(\"TP class counts\", np.unique(y_test[e], return_counts=True))\n",
        "    print(\"True class counts\", np.unique(y_test, return_counts=True))\n",
        "    print(\"Pred class counts\", np.unique(pred, return_counts=True))\n",
        "    holds = np.unique(y_test, return_counts=True)[1][2]  # number 'hold' predictions\n",
        "    print(\"baseline acc:\", (holds/len(y_test)*100))"
      ],
      "metadata": {
        "id": "VpOJX6GyoEfn"
      },
      "id": "VpOJX6GyoEfn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG\n",
        "from tensorflow.keras.utils import model_to_dot, plot_model\n",
        "\n",
        "model = create_model_cnn(params)\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False)\n",
        "\n",
        "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q5Fm79B0oNMv",
        "outputId": "e0da2d11-525b-4fc3-ce48-1b42e38e584a"
      },
      "id": "Q5Fm79B0oNMv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with params {'batch_size': 80, 'conv2d_layers': {'conv2d_do_1': 0.22, 'conv2d_filters_1': 20, 'conv2d_kernel_size_1': 2, 'conv2d_mp_1': 2, 'conv2d_strides_1': 1, 'kernel_regularizer_1': 0.0, 'conv2d_do_2': 0.05, 'conv2d_filters_2': 40, 'conv2d_kernel_size_2': 2, 'conv2d_mp_2': 2, 'conv2d_strides_2': 2, 'kernel_regularizer_2': 0.0, 'layers': 'two'}, 'dense_layers': {'dense_do_1': 0.22, 'dense_nodes_1': 100, 'kernel_regularizer_1': 0.0, 'layers': 'one'}, 'epochs': 300, 'lr': 0.001, 'optimizer': 'adam'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "best_model_path = os.path.join('.', 'best_model_keras')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n",
        "                   patience=100, min_delta=0.0001)\n",
        "# csv_logger = CSVLogger(os.path.join(OUTPUT_PATH, 'log_training_batch.log'), append=True)\n",
        "rlp = ReduceLROnPlateau(monitor='val_loss', factor=0.02, patience=20, verbose=1, mode='min',\n",
        "                        min_delta=0.001, cooldown=1, min_lr=0.0001)\n",
        "mcp = ModelCheckpoint(best_model_path, monitor='val_f1_metric', verbose=1,\n",
        "                      save_best_only=True, save_weights_only=False, mode='max', period=1)  # val_f1_metric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhR5ke7_oFUi",
        "outputId": "d64ec386-fb9b-4cd4-9873-e7a514e49916"
      },
      "id": "BhR5ke7_oFUi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = model.fit(x_train, y_train, epochs=params['epochs'], verbose=1,\n",
        "                            batch_size=80, shuffle=True,\n",
        "                            # validation_split=0.3,\n",
        "                            validation_data=(x_cv, y_cv),\n",
        "                            callbacks=[mcp, rlp, es]\n",
        "                            , sample_weight=sample_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ok-G2vYoHxx",
        "outputId": "c4c09db3-9bf0-4d10-ec86-bd0d75f5d160"
      },
      "id": "6ok-G2vYoHxx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "1/9 [==>...........................] - ETA: 11s - loss: 0.6904 - accuracy: 0.5875 - f1_metric: 0.5875\n",
            "Epoch 1: val_f1_metric improved from -inf to 0.60417, saving model to ./best_model_keras\n",
            "9/9 [==============================] - 4s 310ms/step - loss: 0.6918 - accuracy: 0.5396 - f1_metric: 0.5583 - val_loss: 0.6790 - val_accuracy: 0.6524 - val_f1_metric: 0.6042 - lr: 0.0010\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6773 - accuracy: 0.6143 - f1_metric: 0.6208\n",
            "Epoch 2: val_f1_metric improved from 0.60417 to 0.71250, saving model to ./best_model_keras\n",
            "9/9 [==============================] - 2s 227ms/step - loss: 0.6773 - accuracy: 0.6143 - f1_metric: 0.6208 - val_loss: 0.6607 - val_accuracy: 0.8110 - val_f1_metric: 0.7125 - lr: 0.0010\n",
            "Epoch 3/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.6694 - accuracy: 0.6500 - f1_metric: 0.6500\n",
            "Epoch 3: val_f1_metric improved from 0.71250 to 0.80000, saving model to ./best_model_keras\n",
            "9/9 [==============================] - 1s 181ms/step - loss: 0.6600 - accuracy: 0.6738 - f1_metric: 0.6861 - val_loss: 0.6359 - val_accuracy: 0.8232 - val_f1_metric: 0.8000 - lr: 0.0010\n",
            "Epoch 4/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.6393 - accuracy: 0.7500 - f1_metric: 0.7500\n",
            "Epoch 4: val_f1_metric did not improve from 0.80000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6393 - accuracy: 0.7104 - f1_metric: 0.7083 - val_loss: 0.5969 - val_accuracy: 0.8415 - val_f1_metric: 0.7333 - lr: 0.0010\n",
            "Epoch 5/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.6089 - accuracy: 0.8000 - f1_metric: 0.8000\n",
            "Epoch 5: val_f1_metric did not improve from 0.80000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5973 - accuracy: 0.7637 - f1_metric: 0.7403 - val_loss: 0.5428 - val_accuracy: 0.8476 - val_f1_metric: 0.7375 - lr: 0.0010\n",
            "Epoch 6/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.6014 - accuracy: 0.7125 - f1_metric: 0.7125\n",
            "Epoch 6: val_f1_metric did not improve from 0.80000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5555 - accuracy: 0.7607 - f1_metric: 0.7708 - val_loss: 0.4786 - val_accuracy: 0.8598 - val_f1_metric: 0.7458 - lr: 0.0010\n",
            "Epoch 7/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4978 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 7: val_f1_metric improved from 0.80000 to 0.82500, saving model to ./best_model_keras\n",
            "9/9 [==============================] - 2s 232ms/step - loss: 0.5165 - accuracy: 0.7820 - f1_metric: 0.7736 - val_loss: 0.4215 - val_accuracy: 0.8598 - val_f1_metric: 0.8250 - lr: 0.0010\n",
            "Epoch 8/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.5146 - accuracy: 0.7500 - f1_metric: 0.7500\n",
            "Epoch 8: val_f1_metric did not improve from 0.82500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.4623 - accuracy: 0.8079 - f1_metric: 0.8139 - val_loss: 0.3693 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 9/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4447 - accuracy: 0.8250 - f1_metric: 0.8250\n",
            "Epoch 9: val_f1_metric improved from 0.82500 to 0.84583, saving model to ./best_model_keras\n",
            "9/9 [==============================] - 1s 155ms/step - loss: 0.4285 - accuracy: 0.8186 - f1_metric: 0.8236 - val_loss: 0.3412 - val_accuracy: 0.8902 - val_f1_metric: 0.8458 - lr: 0.0010\n",
            "Epoch 10/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4562 - accuracy: 0.8500 - f1_metric: 0.8500\n",
            "Epoch 10: val_f1_metric improved from 0.84583 to 0.85000, saving model to ./best_model_keras\n",
            "9/9 [==============================] - 1s 151ms/step - loss: 0.4364 - accuracy: 0.8110 - f1_metric: 0.7944 - val_loss: 0.3276 - val_accuracy: 0.8963 - val_f1_metric: 0.8500 - lr: 0.0010\n",
            "Epoch 11/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4198 - accuracy: 0.8375 - f1_metric: 0.8375\n",
            "Epoch 11: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3982 - accuracy: 0.8354 - f1_metric: 0.8278 - val_loss: 0.3325 - val_accuracy: 0.8780 - val_f1_metric: 0.8375 - lr: 0.0010\n",
            "Epoch 12/300\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.4089 - accuracy: 0.8141 - f1_metric: 0.8141\n",
            "Epoch 12: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.4124 - accuracy: 0.8125 - f1_metric: 0.8069 - val_loss: 0.3283 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 13/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4434 - accuracy: 0.8000 - f1_metric: 0.8000\n",
            "Epoch 13: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.4019 - accuracy: 0.8323 - f1_metric: 0.8306 - val_loss: 0.3300 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 14/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3591 - accuracy: 0.8375 - f1_metric: 0.8375\n",
            "Epoch 14: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4021 - accuracy: 0.8247 - f1_metric: 0.8292 - val_loss: 0.3286 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 15/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3994 - accuracy: 0.8625 - f1_metric: 0.8625\n",
            "Epoch 15: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4166 - accuracy: 0.8354 - f1_metric: 0.8278 - val_loss: 0.3251 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 16/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3928 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 16: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.4087 - accuracy: 0.8323 - f1_metric: 0.8306 - val_loss: 0.3335 - val_accuracy: 0.8780 - val_f1_metric: 0.7583 - lr: 0.0010\n",
            "Epoch 17/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3641 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 17: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3848 - accuracy: 0.8338 - f1_metric: 0.8375 - val_loss: 0.3248 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 18/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4017 - accuracy: 0.8375 - f1_metric: 0.8375\n",
            "Epoch 18: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3815 - accuracy: 0.8491 - f1_metric: 0.8514 - val_loss: 0.3213 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 19/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3533 - accuracy: 0.8500 - f1_metric: 0.8500\n",
            "Epoch 19: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3843 - accuracy: 0.8369 - f1_metric: 0.8292 - val_loss: 0.3214 - val_accuracy: 0.8720 - val_f1_metric: 0.7542 - lr: 0.0010\n",
            "Epoch 20/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4233 - accuracy: 0.8000 - f1_metric: 0.8000\n",
            "Epoch 20: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3916 - accuracy: 0.8323 - f1_metric: 0.8083 - val_loss: 0.3206 - val_accuracy: 0.8780 - val_f1_metric: 0.7583 - lr: 0.0010\n",
            "Epoch 21/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4078 - accuracy: 0.8625 - f1_metric: 0.8625\n",
            "Epoch 21: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3862 - accuracy: 0.8415 - f1_metric: 0.8333 - val_loss: 0.3255 - val_accuracy: 0.8780 - val_f1_metric: 0.7583 - lr: 0.0010\n",
            "Epoch 22/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3699 - accuracy: 0.8625 - f1_metric: 0.8625\n",
            "Epoch 22: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.3879 - accuracy: 0.8445 - f1_metric: 0.8472 - val_loss: 0.3237 - val_accuracy: 0.8720 - val_f1_metric: 0.7542 - lr: 0.0010\n",
            "Epoch 23/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3223 - accuracy: 0.8625 - f1_metric: 0.8625\n",
            "Epoch 23: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3785 - accuracy: 0.8354 - f1_metric: 0.8389 - val_loss: 0.3142 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 24/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3591 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 24: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3803 - accuracy: 0.8293 - f1_metric: 0.8056 - val_loss: 0.3129 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 25/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3917 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 25: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3825 - accuracy: 0.8460 - f1_metric: 0.8486 - val_loss: 0.3121 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 26/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3599 - accuracy: 0.8000 - f1_metric: 0.8000\n",
            "Epoch 26: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3798 - accuracy: 0.8308 - f1_metric: 0.8403 - val_loss: 0.3123 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 27/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4335 - accuracy: 0.8000 - f1_metric: 0.8000\n",
            "Epoch 27: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3535 - accuracy: 0.8537 - f1_metric: 0.8611 - val_loss: 0.3153 - val_accuracy: 0.8780 - val_f1_metric: 0.7583 - lr: 0.0010\n",
            "Epoch 28/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3842 - accuracy: 0.8500 - f1_metric: 0.8500\n",
            "Epoch 28: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3770 - accuracy: 0.8415 - f1_metric: 0.8333 - val_loss: 0.3120 - val_accuracy: 0.8780 - val_f1_metric: 0.7583 - lr: 0.0010\n",
            "Epoch 29/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3615 - accuracy: 0.8250 - f1_metric: 0.8250\n",
            "Epoch 29: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3546 - accuracy: 0.8476 - f1_metric: 0.8556 - val_loss: 0.3088 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 30/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2799 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 30: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3726 - accuracy: 0.8415 - f1_metric: 0.8389 - val_loss: 0.3043 - val_accuracy: 0.8780 - val_f1_metric: 0.7583 - lr: 0.0010\n",
            "Epoch 31/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3045 - accuracy: 0.8375 - f1_metric: 0.8375\n",
            "Epoch 31: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3565 - accuracy: 0.8476 - f1_metric: 0.8444 - val_loss: 0.3016 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 32/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3605 - accuracy: 0.8500 - f1_metric: 0.8500\n",
            "Epoch 32: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3648 - accuracy: 0.8521 - f1_metric: 0.8431 - val_loss: 0.2978 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 33/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4219 - accuracy: 0.8250 - f1_metric: 0.8250\n",
            "Epoch 33: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3736 - accuracy: 0.8491 - f1_metric: 0.8403 - val_loss: 0.3011 - val_accuracy: 0.8780 - val_f1_metric: 0.7583 - lr: 0.0010\n",
            "Epoch 34/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3184 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 34: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3641 - accuracy: 0.8476 - f1_metric: 0.8444 - val_loss: 0.3105 - val_accuracy: 0.8780 - val_f1_metric: 0.7583 - lr: 0.0010\n",
            "Epoch 35/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4184 - accuracy: 0.8375 - f1_metric: 0.8375\n",
            "Epoch 35: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3597 - accuracy: 0.8521 - f1_metric: 0.8486 - val_loss: 0.3039 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 36/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3057 - accuracy: 0.8625 - f1_metric: 0.8625\n",
            "Epoch 36: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3541 - accuracy: 0.8476 - f1_metric: 0.8444 - val_loss: 0.2948 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 37/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3387 - accuracy: 0.8250 - f1_metric: 0.8250\n",
            "Epoch 37: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3372 - accuracy: 0.8598 - f1_metric: 0.8667 - val_loss: 0.2928 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 38/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4695 - accuracy: 0.7875 - f1_metric: 0.7875\n",
            "Epoch 38: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3506 - accuracy: 0.8460 - f1_metric: 0.8542 - val_loss: 0.2915 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 39/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2799 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 39: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3441 - accuracy: 0.8643 - f1_metric: 0.8708 - val_loss: 0.2912 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 40/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4739 - accuracy: 0.7375 - f1_metric: 0.7375\n",
            "Epoch 40: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3502 - accuracy: 0.8537 - f1_metric: 0.8556 - val_loss: 0.2898 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 41/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3596 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 41: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3363 - accuracy: 0.8582 - f1_metric: 0.8542 - val_loss: 0.2807 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 42/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3239 - accuracy: 0.8500 - f1_metric: 0.8500\n",
            "Epoch 42: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3588 - accuracy: 0.8460 - f1_metric: 0.8542 - val_loss: 0.2762 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3463 - accuracy: 0.8537 - f1_metric: 0.8556\n",
            "Epoch 43: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.3463 - accuracy: 0.8537 - f1_metric: 0.8556 - val_loss: 0.2883 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 44/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4258 - accuracy: 0.8250 - f1_metric: 0.8250\n",
            "Epoch 44: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3509 - accuracy: 0.8506 - f1_metric: 0.8528 - val_loss: 0.2817 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 45/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3917 - accuracy: 0.8250 - f1_metric: 0.8250\n",
            "Epoch 45: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3426 - accuracy: 0.8628 - f1_metric: 0.8750 - val_loss: 0.2845 - val_accuracy: 0.8963 - val_f1_metric: 0.7708 - lr: 0.0010\n",
            "Epoch 46/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4344 - accuracy: 0.7750 - f1_metric: 0.7750\n",
            "Epoch 46: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3451 - accuracy: 0.8628 - f1_metric: 0.8694 - val_loss: 0.2841 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 47/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3182 - accuracy: 0.8500 - f1_metric: 0.8500\n",
            "Epoch 47: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3376 - accuracy: 0.8460 - f1_metric: 0.8375 - val_loss: 0.2853 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 48/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3466 - accuracy: 0.8375 - f1_metric: 0.8375\n",
            "Epoch 48: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3564 - accuracy: 0.8598 - f1_metric: 0.8500 - val_loss: 0.2828 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 49/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3991 - accuracy: 0.8500 - f1_metric: 0.8500\n",
            "Epoch 49: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3290 - accuracy: 0.8735 - f1_metric: 0.8681 - val_loss: 0.2826 - val_accuracy: 0.9024 - val_f1_metric: 0.7750 - lr: 0.0010\n",
            "Epoch 50/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2449 - accuracy: 0.9000 - f1_metric: 0.9000\n",
            "Epoch 50: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3486 - accuracy: 0.8476 - f1_metric: 0.8500 - val_loss: 0.2823 - val_accuracy: 0.8780 - val_f1_metric: 0.7583 - lr: 0.0010\n",
            "Epoch 51/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4218 - accuracy: 0.8000 - f1_metric: 0.8000\n",
            "Epoch 51: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3496 - accuracy: 0.8567 - f1_metric: 0.8639 - val_loss: 0.2810 - val_accuracy: 0.8963 - val_f1_metric: 0.7708 - lr: 0.0010\n",
            "Epoch 52/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3626 - accuracy: 0.8500 - f1_metric: 0.8500\n",
            "Epoch 52: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3234 - accuracy: 0.8689 - f1_metric: 0.8750 - val_loss: 0.2686 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 53/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3545 - accuracy: 0.8250 - f1_metric: 0.8250\n",
            "Epoch 53: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3268 - accuracy: 0.8659 - f1_metric: 0.8556 - val_loss: 0.2711 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 54/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3619 - accuracy: 0.8500 - f1_metric: 0.8500\n",
            "Epoch 54: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.3473 - accuracy: 0.8537 - f1_metric: 0.8611 - val_loss: 0.2800 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 55/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4589 - accuracy: 0.8250 - f1_metric: 0.8250\n",
            "Epoch 55: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.3404 - accuracy: 0.8628 - f1_metric: 0.8750 - val_loss: 0.2748 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3204 - accuracy: 0.8720 - f1_metric: 0.8778\n",
            "Epoch 56: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.3204 - accuracy: 0.8720 - f1_metric: 0.8778 - val_loss: 0.2714 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3349 - accuracy: 0.8537 - f1_metric: 0.8500\n",
            "Epoch 57: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.3349 - accuracy: 0.8537 - f1_metric: 0.8500 - val_loss: 0.2727 - val_accuracy: 0.8963 - val_f1_metric: 0.7708 - lr: 0.0010\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3212 - accuracy: 0.8659 - f1_metric: 0.8611\n",
            "Epoch 58: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.3212 - accuracy: 0.8659 - f1_metric: 0.8611 - val_loss: 0.2652 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 59/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4584 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 59: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.3227 - accuracy: 0.8689 - f1_metric: 0.8750 - val_loss: 0.2671 - val_accuracy: 0.9085 - val_f1_metric: 0.7792 - lr: 0.0010\n",
            "Epoch 60/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2815 - accuracy: 0.8500 - f1_metric: 0.8500\n",
            "Epoch 60: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.3049 - accuracy: 0.8841 - f1_metric: 0.8778 - val_loss: 0.2600 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 61/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3507 - accuracy: 0.8500 - f1_metric: 0.8500\n",
            "Epoch 61: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.3131 - accuracy: 0.8659 - f1_metric: 0.8778 - val_loss: 0.2658 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 62/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2842 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 62: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3154 - accuracy: 0.8765 - f1_metric: 0.8764 - val_loss: 0.2692 - val_accuracy: 0.8963 - val_f1_metric: 0.7708 - lr: 0.0010\n",
            "Epoch 63/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3287 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 63: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3098 - accuracy: 0.8689 - f1_metric: 0.8639 - val_loss: 0.2561 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 64/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3487 - accuracy: 0.8625 - f1_metric: 0.8625\n",
            "Epoch 64: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.3246 - accuracy: 0.8628 - f1_metric: 0.8639 - val_loss: 0.2569 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 65/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2736 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 65: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.3264 - accuracy: 0.8674 - f1_metric: 0.8625 - val_loss: 0.2514 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 66/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3209 - accuracy: 0.8500 - f1_metric: 0.8500\n",
            "Epoch 66: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3242 - accuracy: 0.8643 - f1_metric: 0.8653 - val_loss: 0.2511 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 67/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3083 - accuracy: 0.8625 - f1_metric: 0.8625\n",
            "Epoch 67: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.3160 - accuracy: 0.8704 - f1_metric: 0.8764 - val_loss: 0.2629 - val_accuracy: 0.8963 - val_f1_metric: 0.7708 - lr: 0.0010\n",
            "Epoch 68/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3617 - accuracy: 0.8250 - f1_metric: 0.8250\n",
            "Epoch 68: val_f1_metric did not improve from 0.85000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.3140 - accuracy: 0.8552 - f1_metric: 0.8458 - val_loss: 0.2470 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 69/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2130 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 69: val_f1_metric improved from 0.85000 to 0.85417, saving model to ./best_model_keras\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 0.3007 - accuracy: 0.8750 - f1_metric: 0.8750 - val_loss: 0.2500 - val_accuracy: 0.9024 - val_f1_metric: 0.8542 - lr: 0.0010\n",
            "Epoch 70/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3271 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 70: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.3094 - accuracy: 0.8674 - f1_metric: 0.8736 - val_loss: 0.2439 - val_accuracy: 0.8841 - val_f1_metric: 0.7625 - lr: 0.0010\n",
            "Epoch 71/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3639 - accuracy: 0.8625 - f1_metric: 0.8625\n",
            "Epoch 71: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.3298 - accuracy: 0.8567 - f1_metric: 0.8583 - val_loss: 0.2472 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 72/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3353 - accuracy: 0.8500 - f1_metric: 0.8500\n",
            "Epoch 72: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3066 - accuracy: 0.8750 - f1_metric: 0.8694 - val_loss: 0.2420 - val_accuracy: 0.9085 - val_f1_metric: 0.7792 - lr: 0.0010\n",
            "Epoch 73/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2822 - accuracy: 0.8875 - f1_metric: 0.8875\n",
            "Epoch 73: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2892 - accuracy: 0.8765 - f1_metric: 0.8875 - val_loss: 0.2336 - val_accuracy: 0.8902 - val_f1_metric: 0.7667 - lr: 0.0010\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3193 - accuracy: 0.8765 - f1_metric: 0.8875\n",
            "Epoch 74: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 0.3193 - accuracy: 0.8765 - f1_metric: 0.8875 - val_loss: 0.2413 - val_accuracy: 0.8963 - val_f1_metric: 0.7708 - lr: 0.0010\n",
            "Epoch 75/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2605 - accuracy: 0.8625 - f1_metric: 0.8625\n",
            "Epoch 75: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2877 - accuracy: 0.8811 - f1_metric: 0.8750 - val_loss: 0.2412 - val_accuracy: 0.8963 - val_f1_metric: 0.7708 - lr: 0.0010\n",
            "Epoch 76/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2145 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 76: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.3010 - accuracy: 0.8643 - f1_metric: 0.8542 - val_loss: 0.2398 - val_accuracy: 0.8963 - val_f1_metric: 0.8500 - lr: 0.0010\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.3054 - accuracy: 0.8720 - f1_metric: 0.8778\n",
            "Epoch 77: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.3054 - accuracy: 0.8720 - f1_metric: 0.8778 - val_loss: 0.2372 - val_accuracy: 0.8841 - val_f1_metric: 0.8417 - lr: 0.0010\n",
            "Epoch 78/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2667 - accuracy: 0.8875 - f1_metric: 0.8875\n",
            "Epoch 78: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2654 - accuracy: 0.8979 - f1_metric: 0.9014 - val_loss: 0.2432 - val_accuracy: 0.8963 - val_f1_metric: 0.8500 - lr: 0.0010\n",
            "Epoch 79/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2411 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 79: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2844 - accuracy: 0.8826 - f1_metric: 0.8875 - val_loss: 0.2326 - val_accuracy: 0.9024 - val_f1_metric: 0.8542 - lr: 0.0010\n",
            "Epoch 80/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2186 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 80: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2904 - accuracy: 0.8811 - f1_metric: 0.8583 - val_loss: 0.2323 - val_accuracy: 0.9024 - val_f1_metric: 0.8542 - lr: 0.0010\n",
            "Epoch 81/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2555 - accuracy: 0.8875 - f1_metric: 0.8875\n",
            "Epoch 81: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2910 - accuracy: 0.8826 - f1_metric: 0.8875 - val_loss: 0.2378 - val_accuracy: 0.9024 - val_f1_metric: 0.8542 - lr: 0.0010\n",
            "Epoch 82/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2912 - accuracy: 0.8875 - f1_metric: 0.8875\n",
            "Epoch 82: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2939 - accuracy: 0.8780 - f1_metric: 0.8778 - val_loss: 0.2239 - val_accuracy: 0.9024 - val_f1_metric: 0.8542 - lr: 0.0010\n",
            "Epoch 83/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3381 - accuracy: 0.8250 - f1_metric: 0.8250\n",
            "Epoch 83: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2924 - accuracy: 0.8857 - f1_metric: 0.8847 - val_loss: 0.2260 - val_accuracy: 0.9024 - val_f1_metric: 0.8542 - lr: 0.0010\n",
            "Epoch 84/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2620 - accuracy: 0.9000 - f1_metric: 0.9000\n",
            "Epoch 84: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2874 - accuracy: 0.8811 - f1_metric: 0.8750 - val_loss: 0.2255 - val_accuracy: 0.9024 - val_f1_metric: 0.7750 - lr: 0.0010\n",
            "Epoch 85/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2948 - accuracy: 0.8500 - f1_metric: 0.8500\n",
            "Epoch 85: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2774 - accuracy: 0.8811 - f1_metric: 0.8806 - val_loss: 0.2198 - val_accuracy: 0.9024 - val_f1_metric: 0.8542 - lr: 0.0010\n",
            "Epoch 86/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3180 - accuracy: 0.8500 - f1_metric: 0.8500\n",
            "Epoch 86: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2817 - accuracy: 0.8841 - f1_metric: 0.8889 - val_loss: 0.2219 - val_accuracy: 0.8963 - val_f1_metric: 0.8500 - lr: 0.0010\n",
            "Epoch 87/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2021 - accuracy: 0.8875 - f1_metric: 0.8875\n",
            "Epoch 87: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2891 - accuracy: 0.8750 - f1_metric: 0.8861 - val_loss: 0.2249 - val_accuracy: 0.9024 - val_f1_metric: 0.8542 - lr: 0.0010\n",
            "Epoch 88/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1923 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 88: val_f1_metric did not improve from 0.85417\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2599 - accuracy: 0.8902 - f1_metric: 0.8944 - val_loss: 0.2181 - val_accuracy: 0.8963 - val_f1_metric: 0.8500 - lr: 0.0010\n",
            "Epoch 89/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3435 - accuracy: 0.8375 - f1_metric: 0.8375\n",
            "Epoch 89: val_f1_metric improved from 0.85417 to 0.85833, saving model to ./best_model_keras\n",
            "9/9 [==============================] - 1s 152ms/step - loss: 0.2737 - accuracy: 0.8872 - f1_metric: 0.8917 - val_loss: 0.2079 - val_accuracy: 0.9085 - val_f1_metric: 0.8583 - lr: 0.0010\n",
            "Epoch 90/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2435 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 90: val_f1_metric did not improve from 0.85833\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2759 - accuracy: 0.8765 - f1_metric: 0.8653 - val_loss: 0.2084 - val_accuracy: 0.9085 - val_f1_metric: 0.8583 - lr: 0.0010\n",
            "Epoch 91/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3121 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 91: val_f1_metric did not improve from 0.85833\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2809 - accuracy: 0.8902 - f1_metric: 0.9000 - val_loss: 0.2070 - val_accuracy: 0.9085 - val_f1_metric: 0.8583 - lr: 0.0010\n",
            "Epoch 92/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3021 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 92: val_f1_metric did not improve from 0.85833\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2816 - accuracy: 0.8857 - f1_metric: 0.8903 - val_loss: 0.2051 - val_accuracy: 0.9085 - val_f1_metric: 0.8583 - lr: 0.0010\n",
            "Epoch 93/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2240 - accuracy: 0.9000 - f1_metric: 0.9000\n",
            "Epoch 93: val_f1_metric did not improve from 0.85833\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2665 - accuracy: 0.8963 - f1_metric: 0.9000 - val_loss: 0.2205 - val_accuracy: 0.9085 - val_f1_metric: 0.8583 - lr: 0.0010\n",
            "Epoch 94/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2375 - accuracy: 0.8875 - f1_metric: 0.8875\n",
            "Epoch 94: val_f1_metric did not improve from 0.85833\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2701 - accuracy: 0.8918 - f1_metric: 0.8847 - val_loss: 0.2220 - val_accuracy: 0.8963 - val_f1_metric: 0.8500 - lr: 0.0010\n",
            "Epoch 95/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3328 - accuracy: 0.8375 - f1_metric: 0.8375\n",
            "Epoch 95: val_f1_metric did not improve from 0.85833\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2798 - accuracy: 0.8841 - f1_metric: 0.8778 - val_loss: 0.2120 - val_accuracy: 0.9085 - val_f1_metric: 0.8583 - lr: 0.0010\n",
            "Epoch 96/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3067 - accuracy: 0.8625 - f1_metric: 0.8625\n",
            "Epoch 96: val_f1_metric did not improve from 0.85833\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2681 - accuracy: 0.8857 - f1_metric: 0.8903 - val_loss: 0.2097 - val_accuracy: 0.9085 - val_f1_metric: 0.8583 - lr: 0.0010\n",
            "Epoch 97/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.4126 - accuracy: 0.8500 - f1_metric: 0.8500\n",
            "Epoch 97: val_f1_metric did not improve from 0.85833\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2790 - accuracy: 0.8918 - f1_metric: 0.8958 - val_loss: 0.2079 - val_accuracy: 0.9024 - val_f1_metric: 0.8542 - lr: 0.0010\n",
            "Epoch 98/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3349 - accuracy: 0.8375 - f1_metric: 0.8375\n",
            "Epoch 98: val_f1_metric did not improve from 0.85833\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2587 - accuracy: 0.9040 - f1_metric: 0.9125 - val_loss: 0.2047 - val_accuracy: 0.9024 - val_f1_metric: 0.8542 - lr: 0.0010\n",
            "Epoch 99/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2573 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 99: val_f1_metric did not improve from 0.85833\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2540 - accuracy: 0.8979 - f1_metric: 0.9069 - val_loss: 0.1980 - val_accuracy: 0.9024 - val_f1_metric: 0.8542 - lr: 0.0010\n",
            "Epoch 100/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1799 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 100: val_f1_metric improved from 0.85833 to 0.87917, saving model to ./best_model_keras\n",
            "9/9 [==============================] - 1s 184ms/step - loss: 0.2498 - accuracy: 0.8933 - f1_metric: 0.8806 - val_loss: 0.1924 - val_accuracy: 0.9390 - val_f1_metric: 0.8792 - lr: 0.0010\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2700 - accuracy: 0.9024 - f1_metric: 0.9000\n",
            "Epoch 101: val_f1_metric did not improve from 0.87917\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2700 - accuracy: 0.9024 - f1_metric: 0.9000 - val_loss: 0.1815 - val_accuracy: 0.9390 - val_f1_metric: 0.8792 - lr: 0.0010\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2631 - accuracy: 0.8994 - f1_metric: 0.9028\n",
            "Epoch 102: val_f1_metric improved from 0.87917 to 0.88333, saving model to ./best_model_keras\n",
            "9/9 [==============================] - 2s 242ms/step - loss: 0.2631 - accuracy: 0.8994 - f1_metric: 0.9028 - val_loss: 0.1957 - val_accuracy: 0.9451 - val_f1_metric: 0.8833 - lr: 0.0010\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2690 - accuracy: 0.8963 - f1_metric: 0.8889\n",
            "Epoch 103: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.2690 - accuracy: 0.8963 - f1_metric: 0.8889 - val_loss: 0.1942 - val_accuracy: 0.9207 - val_f1_metric: 0.8667 - lr: 0.0010\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2589 - accuracy: 0.9055 - f1_metric: 0.9083\n",
            "Epoch 104: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2589 - accuracy: 0.9055 - f1_metric: 0.9083 - val_loss: 0.1973 - val_accuracy: 0.9329 - val_f1_metric: 0.8750 - lr: 0.0010\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2545 - accuracy: 0.8979 - f1_metric: 0.8958\n",
            "Epoch 105: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.2545 - accuracy: 0.8979 - f1_metric: 0.8958 - val_loss: 0.1932 - val_accuracy: 0.9207 - val_f1_metric: 0.8667 - lr: 0.0010\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2569 - accuracy: 0.8933 - f1_metric: 0.8917\n",
            "Epoch 106: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.2569 - accuracy: 0.8933 - f1_metric: 0.8917 - val_loss: 0.1959 - val_accuracy: 0.9329 - val_f1_metric: 0.8750 - lr: 0.0010\n",
            "Epoch 107/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2325 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 107: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2428 - accuracy: 0.9055 - f1_metric: 0.9028 - val_loss: 0.1922 - val_accuracy: 0.9085 - val_f1_metric: 0.8583 - lr: 0.0010\n",
            "Epoch 108/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1295 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 108: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2480 - accuracy: 0.9116 - f1_metric: 0.9083 - val_loss: 0.1989 - val_accuracy: 0.9146 - val_f1_metric: 0.8625 - lr: 0.0010\n",
            "Epoch 109/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1979 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 109: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.2535 - accuracy: 0.8963 - f1_metric: 0.9000 - val_loss: 0.1973 - val_accuracy: 0.9146 - val_f1_metric: 0.8625 - lr: 0.0010\n",
            "Epoch 110/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3254 - accuracy: 0.8500 - f1_metric: 0.8500\n",
            "Epoch 110: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2452 - accuracy: 0.9040 - f1_metric: 0.9125 - val_loss: 0.1958 - val_accuracy: 0.9268 - val_f1_metric: 0.8708 - lr: 0.0010\n",
            "Epoch 111/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1951 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 111: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2410 - accuracy: 0.9009 - f1_metric: 0.8875 - val_loss: 0.1898 - val_accuracy: 0.9390 - val_f1_metric: 0.8792 - lr: 0.0010\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2390 - accuracy: 0.8979 - f1_metric: 0.8903\n",
            "Epoch 112: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.2390 - accuracy: 0.8979 - f1_metric: 0.8903 - val_loss: 0.1805 - val_accuracy: 0.9146 - val_f1_metric: 0.8625 - lr: 0.0010\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2470 - accuracy: 0.8918 - f1_metric: 0.8847\n",
            "Epoch 113: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2470 - accuracy: 0.8918 - f1_metric: 0.8847 - val_loss: 0.1794 - val_accuracy: 0.9207 - val_f1_metric: 0.8667 - lr: 0.0010\n",
            "Epoch 114/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2031 - accuracy: 0.9000 - f1_metric: 0.9000\n",
            "Epoch 114: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2325 - accuracy: 0.9131 - f1_metric: 0.8986 - val_loss: 0.1741 - val_accuracy: 0.9268 - val_f1_metric: 0.8708 - lr: 0.0010\n",
            "Epoch 115/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1396 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 115: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2172 - accuracy: 0.9101 - f1_metric: 0.9014 - val_loss: 0.1755 - val_accuracy: 0.9390 - val_f1_metric: 0.8792 - lr: 0.0010\n",
            "Epoch 116/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2386 - accuracy: 0.9000 - f1_metric: 0.9000\n",
            "Epoch 116: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2349 - accuracy: 0.9055 - f1_metric: 0.9083 - val_loss: 0.1774 - val_accuracy: 0.9268 - val_f1_metric: 0.7917 - lr: 0.0010\n",
            "Epoch 117/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2349 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 117: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2245 - accuracy: 0.9101 - f1_metric: 0.9125 - val_loss: 0.1815 - val_accuracy: 0.9329 - val_f1_metric: 0.8750 - lr: 0.0010\n",
            "Epoch 118/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1644 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 118: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2342 - accuracy: 0.8994 - f1_metric: 0.8917 - val_loss: 0.1738 - val_accuracy: 0.9268 - val_f1_metric: 0.8708 - lr: 0.0010\n",
            "Epoch 119/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2274 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 119: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2221 - accuracy: 0.9116 - f1_metric: 0.9083 - val_loss: 0.1635 - val_accuracy: 0.9329 - val_f1_metric: 0.8750 - lr: 0.0010\n",
            "Epoch 120/300\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.2217 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 120: val_f1_metric did not improve from 0.88333\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.2288 - accuracy: 0.9085 - f1_metric: 0.8944 - val_loss: 0.1550 - val_accuracy: 0.9329 - val_f1_metric: 0.8750 - lr: 0.0010\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2371 - accuracy: 0.9177 - f1_metric: 0.9194\n",
            "Epoch 121: val_f1_metric improved from 0.88333 to 0.88750, saving model to ./best_model_keras\n",
            "9/9 [==============================] - 1s 185ms/step - loss: 0.2371 - accuracy: 0.9177 - f1_metric: 0.9194 - val_loss: 0.1616 - val_accuracy: 0.9512 - val_f1_metric: 0.8875 - lr: 0.0010\n",
            "Epoch 122/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3016 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 122: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2216 - accuracy: 0.9131 - f1_metric: 0.9153 - val_loss: 0.1508 - val_accuracy: 0.9146 - val_f1_metric: 0.8625 - lr: 0.0010\n",
            "Epoch 123/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2660 - accuracy: 0.8875 - f1_metric: 0.8875\n",
            "Epoch 123: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2390 - accuracy: 0.9040 - f1_metric: 0.9014 - val_loss: 0.1654 - val_accuracy: 0.9512 - val_f1_metric: 0.8875 - lr: 0.0010\n",
            "Epoch 124/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1591 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 124: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2177 - accuracy: 0.9207 - f1_metric: 0.9278 - val_loss: 0.1553 - val_accuracy: 0.9390 - val_f1_metric: 0.8792 - lr: 0.0010\n",
            "Epoch 125/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1873 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 125: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2235 - accuracy: 0.9131 - f1_metric: 0.9208 - val_loss: 0.1599 - val_accuracy: 0.9390 - val_f1_metric: 0.8792 - lr: 0.0010\n",
            "Epoch 126/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2182 - accuracy: 0.9000 - f1_metric: 0.9000\n",
            "Epoch 126: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2081 - accuracy: 0.9253 - f1_metric: 0.9264 - val_loss: 0.1714 - val_accuracy: 0.9146 - val_f1_metric: 0.8625 - lr: 0.0010\n",
            "Epoch 127/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1224 - accuracy: 0.9750 - f1_metric: 0.9750\n",
            "Epoch 127: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2045 - accuracy: 0.9238 - f1_metric: 0.9250 - val_loss: 0.1635 - val_accuracy: 0.9085 - val_f1_metric: 0.8583 - lr: 0.0010\n",
            "Epoch 128/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2365 - accuracy: 0.8875 - f1_metric: 0.8875\n",
            "Epoch 128: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2186 - accuracy: 0.9131 - f1_metric: 0.9208 - val_loss: 0.1591 - val_accuracy: 0.9207 - val_f1_metric: 0.8667 - lr: 0.0010\n",
            "Epoch 129/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2187 - accuracy: 0.9000 - f1_metric: 0.9000\n",
            "Epoch 129: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2240 - accuracy: 0.9024 - f1_metric: 0.9056 - val_loss: 0.1575 - val_accuracy: 0.9390 - val_f1_metric: 0.8792 - lr: 0.0010\n",
            "Epoch 130/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1646 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 130: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2109 - accuracy: 0.9101 - f1_metric: 0.9181 - val_loss: 0.1567 - val_accuracy: 0.9329 - val_f1_metric: 0.8750 - lr: 0.0010\n",
            "Epoch 131/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2290 - accuracy: 0.9000 - f1_metric: 0.9000\n",
            "Epoch 131: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2242 - accuracy: 0.9162 - f1_metric: 0.9069 - val_loss: 0.1516 - val_accuracy: 0.9329 - val_f1_metric: 0.8750 - lr: 0.0010\n",
            "Epoch 132/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2388 - accuracy: 0.8875 - f1_metric: 0.8875\n",
            "Epoch 132: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2237 - accuracy: 0.9131 - f1_metric: 0.9097 - val_loss: 0.1577 - val_accuracy: 0.9390 - val_f1_metric: 0.8792 - lr: 0.0010\n",
            "Epoch 133/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2259 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 133: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2322 - accuracy: 0.9085 - f1_metric: 0.9111 - val_loss: 0.1457 - val_accuracy: 0.9451 - val_f1_metric: 0.8833 - lr: 0.0010\n",
            "Epoch 134/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2072 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 134: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2103 - accuracy: 0.9116 - f1_metric: 0.9083 - val_loss: 0.1403 - val_accuracy: 0.9512 - val_f1_metric: 0.8875 - lr: 0.0010\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.9192 - f1_metric: 0.9264\n",
            "Epoch 135: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2132 - accuracy: 0.9192 - f1_metric: 0.9264 - val_loss: 0.1508 - val_accuracy: 0.9451 - val_f1_metric: 0.8833 - lr: 0.0010\n",
            "Epoch 136/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1895 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 136: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2009 - accuracy: 0.9162 - f1_metric: 0.9181 - val_loss: 0.1472 - val_accuracy: 0.9512 - val_f1_metric: 0.8875 - lr: 0.0010\n",
            "Epoch 137/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2039 - accuracy: 0.9000 - f1_metric: 0.9000\n",
            "Epoch 137: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2024 - accuracy: 0.9268 - f1_metric: 0.9278 - val_loss: 0.1513 - val_accuracy: 0.9512 - val_f1_metric: 0.8875 - lr: 0.0010\n",
            "Epoch 138/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2056 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 138: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2111 - accuracy: 0.9192 - f1_metric: 0.9264 - val_loss: 0.1429 - val_accuracy: 0.9451 - val_f1_metric: 0.8833 - lr: 0.0010\n",
            "Epoch 139/300\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.2075 - accuracy: 0.9234 - f1_metric: 0.9234\n",
            "Epoch 139: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2077 - accuracy: 0.9238 - f1_metric: 0.9250 - val_loss: 0.1455 - val_accuracy: 0.9329 - val_f1_metric: 0.8750 - lr: 0.0010\n",
            "Epoch 140/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2683 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 140: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2078 - accuracy: 0.9116 - f1_metric: 0.9194 - val_loss: 0.1500 - val_accuracy: 0.9390 - val_f1_metric: 0.8792 - lr: 0.0010\n",
            "Epoch 141/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2570 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 141: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.1796 - accuracy: 0.9299 - f1_metric: 0.9306 - val_loss: 0.1467 - val_accuracy: 0.9390 - val_f1_metric: 0.8792 - lr: 0.0010\n",
            "Epoch 142/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2863 - accuracy: 0.8875 - f1_metric: 0.8875\n",
            "Epoch 142: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2050 - accuracy: 0.9177 - f1_metric: 0.9139 - val_loss: 0.1467 - val_accuracy: 0.9451 - val_f1_metric: 0.8833 - lr: 0.0010\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2000 - accuracy: 0.9177 - f1_metric: 0.9194\n",
            "Epoch 143: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.2000 - accuracy: 0.9177 - f1_metric: 0.9194 - val_loss: 0.1450 - val_accuracy: 0.9268 - val_f1_metric: 0.8708 - lr: 0.0010\n",
            "Epoch 144/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2431 - accuracy: 0.9000 - f1_metric: 0.9000\n",
            "Epoch 144: val_f1_metric did not improve from 0.88750\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1998 - accuracy: 0.9253 - f1_metric: 0.9264 - val_loss: 0.1447 - val_accuracy: 0.9451 - val_f1_metric: 0.8833 - lr: 0.0010\n",
            "Epoch 145/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1849 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 145: val_f1_metric improved from 0.88750 to 0.89167, saving model to ./best_model_keras\n",
            "9/9 [==============================] - 2s 285ms/step - loss: 0.2034 - accuracy: 0.9146 - f1_metric: 0.9111 - val_loss: 0.1500 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 0.0010\n",
            "Epoch 146/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1859 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 146: val_f1_metric did not improve from 0.89167\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1873 - accuracy: 0.9177 - f1_metric: 0.9083 - val_loss: 0.1409 - val_accuracy: 0.9512 - val_f1_metric: 0.8875 - lr: 0.0010\n",
            "Epoch 147/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1553 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 147: val_f1_metric did not improve from 0.89167\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2011 - accuracy: 0.9009 - f1_metric: 0.9042 - val_loss: 0.1557 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 0.0010\n",
            "Epoch 148/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1781 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 148: val_f1_metric did not improve from 0.89167\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2035 - accuracy: 0.9207 - f1_metric: 0.9222 - val_loss: 0.1369 - val_accuracy: 0.9512 - val_f1_metric: 0.8875 - lr: 0.0010\n",
            "Epoch 149/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1723 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 149: val_f1_metric did not improve from 0.89167\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2023 - accuracy: 0.9253 - f1_metric: 0.9319 - val_loss: 0.1376 - val_accuracy: 0.9451 - val_f1_metric: 0.8833 - lr: 0.0010\n",
            "Epoch 150/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1816 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 150: val_f1_metric improved from 0.89167 to 0.89583, saving model to ./best_model_keras\n",
            "9/9 [==============================] - 1s 164ms/step - loss: 0.2092 - accuracy: 0.9055 - f1_metric: 0.9028 - val_loss: 0.1406 - val_accuracy: 0.9634 - val_f1_metric: 0.8958 - lr: 0.0010\n",
            "Epoch 151/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1466 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 151: val_f1_metric did not improve from 0.89583\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1816 - accuracy: 0.9345 - f1_metric: 0.9403 - val_loss: 0.1381 - val_accuracy: 0.9512 - val_f1_metric: 0.8875 - lr: 0.0010\n",
            "Epoch 152/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1893 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 152: val_f1_metric did not improve from 0.89583\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1947 - accuracy: 0.9238 - f1_metric: 0.9194 - val_loss: 0.1423 - val_accuracy: 0.9451 - val_f1_metric: 0.8833 - lr: 0.0010\n",
            "Epoch 153/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1585 - accuracy: 0.9875 - f1_metric: 0.9875\n",
            "Epoch 153: val_f1_metric did not improve from 0.89583\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1950 - accuracy: 0.9268 - f1_metric: 0.9222 - val_loss: 0.1387 - val_accuracy: 0.9451 - val_f1_metric: 0.8833 - lr: 0.0010\n",
            "Epoch 154/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2259 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 154: val_f1_metric improved from 0.89583 to 0.90417, saving model to ./best_model_keras\n",
            "9/9 [==============================] - 1s 150ms/step - loss: 0.1869 - accuracy: 0.9375 - f1_metric: 0.9431 - val_loss: 0.1318 - val_accuracy: 0.9756 - val_f1_metric: 0.9042 - lr: 0.0010\n",
            "Epoch 155/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2751 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 155: val_f1_metric did not improve from 0.90417\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1831 - accuracy: 0.9253 - f1_metric: 0.9264 - val_loss: 0.1392 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 0.0010\n",
            "Epoch 156/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2392 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 156: val_f1_metric did not improve from 0.90417\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2007 - accuracy: 0.9253 - f1_metric: 0.9208 - val_loss: 0.1278 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 0.0010\n",
            "Epoch 157/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2001 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 157: val_f1_metric did not improve from 0.90417\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1600 - accuracy: 0.9436 - f1_metric: 0.9486 - val_loss: 0.1476 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 0.0010\n",
            "Epoch 158/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1370 - accuracy: 0.9750 - f1_metric: 0.9750\n",
            "Epoch 158: val_f1_metric did not improve from 0.90417\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1696 - accuracy: 0.9390 - f1_metric: 0.9389 - val_loss: 0.1365 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 0.0010\n",
            "Epoch 159/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2228 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 159: val_f1_metric did not improve from 0.90417\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1749 - accuracy: 0.9375 - f1_metric: 0.9319 - val_loss: 0.1329 - val_accuracy: 0.9512 - val_f1_metric: 0.8875 - lr: 0.0010\n",
            "Epoch 160/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2278 - accuracy: 0.8875 - f1_metric: 0.8875\n",
            "Epoch 160: val_f1_metric did not improve from 0.90417\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1936 - accuracy: 0.9253 - f1_metric: 0.9208 - val_loss: 0.1382 - val_accuracy: 0.9634 - val_f1_metric: 0.8958 - lr: 0.0010\n",
            "Epoch 161/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1800 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 161: val_f1_metric did not improve from 0.90417\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1803 - accuracy: 0.9436 - f1_metric: 0.9486 - val_loss: 0.1233 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 0.0010\n",
            "Epoch 162/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1655 - accuracy: 0.9000 - f1_metric: 0.9000\n",
            "Epoch 162: val_f1_metric did not improve from 0.90417\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1867 - accuracy: 0.9223 - f1_metric: 0.9236 - val_loss: 0.1267 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 0.0010\n",
            "Epoch 163/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1655 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 163: val_f1_metric did not improve from 0.90417\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1852 - accuracy: 0.9314 - f1_metric: 0.9208 - val_loss: 0.1382 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 0.0010\n",
            "Epoch 164/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1736 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 164: val_f1_metric improved from 0.90417 to 0.90833, saving model to ./best_model_keras\n",
            "9/9 [==============================] - 1s 147ms/step - loss: 0.1709 - accuracy: 0.9223 - f1_metric: 0.9236 - val_loss: 0.1175 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 0.0010\n",
            "Epoch 165/300\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1896 - accuracy: 0.9281 - f1_metric: 0.9281\n",
            "Epoch 165: val_f1_metric did not improve from 0.90833\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.1869 - accuracy: 0.9284 - f1_metric: 0.9292 - val_loss: 0.1277 - val_accuracy: 0.9512 - val_f1_metric: 0.8875 - lr: 0.0010\n",
            "Epoch 166/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1548 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 166: val_f1_metric did not improve from 0.90833\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1876 - accuracy: 0.9284 - f1_metric: 0.9292 - val_loss: 0.1352 - val_accuracy: 0.9512 - val_f1_metric: 0.8875 - lr: 0.0010\n",
            "Epoch 167/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1685 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 167: val_f1_metric did not improve from 0.90833\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1586 - accuracy: 0.9421 - f1_metric: 0.9472 - val_loss: 0.1451 - val_accuracy: 0.9268 - val_f1_metric: 0.8708 - lr: 0.0010\n",
            "Epoch 168/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1165 - accuracy: 0.9750 - f1_metric: 0.9750\n",
            "Epoch 168: val_f1_metric did not improve from 0.90833\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1798 - accuracy: 0.9329 - f1_metric: 0.9389 - val_loss: 0.1179 - val_accuracy: 0.9756 - val_f1_metric: 0.9042 - lr: 0.0010\n",
            "Epoch 169/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1411 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 169: val_f1_metric did not improve from 0.90833\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1692 - accuracy: 0.9375 - f1_metric: 0.9375 - val_loss: 0.1179 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 0.0010\n",
            "Epoch 170/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2355 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 170: val_f1_metric did not improve from 0.90833\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1749 - accuracy: 0.9405 - f1_metric: 0.9403 - val_loss: 0.1278 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 0.0010\n",
            "Epoch 171/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1049 - accuracy: 0.9750 - f1_metric: 0.9750\n",
            "Epoch 171: val_f1_metric did not improve from 0.90833\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1483 - accuracy: 0.9512 - f1_metric: 0.9500 - val_loss: 0.1376 - val_accuracy: 0.9329 - val_f1_metric: 0.8750 - lr: 0.0010\n",
            "Epoch 172/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1271 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 172: val_f1_metric did not improve from 0.90833\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1812 - accuracy: 0.9268 - f1_metric: 0.9333 - val_loss: 0.1240 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 0.0010\n",
            "Epoch 173/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2544 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 173: val_f1_metric did not improve from 0.90833\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1754 - accuracy: 0.9360 - f1_metric: 0.9417 - val_loss: 0.1146 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 0.0010\n",
            "Epoch 174/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1522 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 174: val_f1_metric did not improve from 0.90833\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1791 - accuracy: 0.9345 - f1_metric: 0.9347 - val_loss: 0.1170 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 0.0010\n",
            "Epoch 175/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1924 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 175: val_f1_metric did not improve from 0.90833\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1755 - accuracy: 0.9329 - f1_metric: 0.9389 - val_loss: 0.1208 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 0.0010\n",
            "Epoch 176/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2240 - accuracy: 0.9000 - f1_metric: 0.9000\n",
            "Epoch 176: val_f1_metric did not improve from 0.90833\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1832 - accuracy: 0.9299 - f1_metric: 0.9306 - val_loss: 0.1244 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 0.0010\n",
            "Epoch 177/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1056 - accuracy: 0.9750 - f1_metric: 0.9750\n",
            "Epoch 177: val_f1_metric did not improve from 0.90833\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1712 - accuracy: 0.9345 - f1_metric: 0.9292 - val_loss: 0.1233 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 0.0010\n",
            "Epoch 178/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1642 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 178: val_f1_metric did not improve from 0.90833\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1699 - accuracy: 0.9314 - f1_metric: 0.9208 - val_loss: 0.1127 - val_accuracy: 0.9634 - val_f1_metric: 0.8958 - lr: 0.0010\n",
            "Epoch 179/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1798 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 179: val_f1_metric did not improve from 0.90833\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1651 - accuracy: 0.9345 - f1_metric: 0.9347 - val_loss: 0.1090 - val_accuracy: 0.9634 - val_f1_metric: 0.8958 - lr: 0.0010\n",
            "Epoch 180/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1877 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 180: val_f1_metric did not improve from 0.90833\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1543 - accuracy: 0.9390 - f1_metric: 0.9389 - val_loss: 0.1090 - val_accuracy: 0.9634 - val_f1_metric: 0.8958 - lr: 0.0010\n",
            "Epoch 181/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1269 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 181: val_f1_metric did not improve from 0.90833\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1498 - accuracy: 0.9436 - f1_metric: 0.9486 - val_loss: 0.1028 - val_accuracy: 0.9756 - val_f1_metric: 0.9042 - lr: 0.0010\n",
            "Epoch 182/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2163 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 182: val_f1_metric improved from 0.90833 to 0.91250, saving model to ./best_model_keras\n",
            "9/9 [==============================] - 1s 145ms/step - loss: 0.1805 - accuracy: 0.9314 - f1_metric: 0.9319 - val_loss: 0.1106 - val_accuracy: 0.9878 - val_f1_metric: 0.9125 - lr: 0.0010\n",
            "Epoch 183/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1592 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 183: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1558 - accuracy: 0.9482 - f1_metric: 0.9472 - val_loss: 0.1283 - val_accuracy: 0.9329 - val_f1_metric: 0.8750 - lr: 0.0010\n",
            "Epoch 184/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1823 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 184: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1882 - accuracy: 0.9299 - f1_metric: 0.9306 - val_loss: 0.1198 - val_accuracy: 0.9756 - val_f1_metric: 0.9042 - lr: 0.0010\n",
            "Epoch 185/300\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1684 - accuracy: 0.9406 - f1_metric: 0.9406\n",
            "Epoch 185: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.1658 - accuracy: 0.9421 - f1_metric: 0.9472 - val_loss: 0.1150 - val_accuracy: 0.9756 - val_f1_metric: 0.9042 - lr: 0.0010\n",
            "Epoch 186/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1545 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 186: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1702 - accuracy: 0.9345 - f1_metric: 0.9347 - val_loss: 0.1344 - val_accuracy: 0.9634 - val_f1_metric: 0.8958 - lr: 0.0010\n",
            "Epoch 187/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1521 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 187: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1708 - accuracy: 0.9421 - f1_metric: 0.9361 - val_loss: 0.1116 - val_accuracy: 0.9756 - val_f1_metric: 0.9042 - lr: 0.0010\n",
            "Epoch 188/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1182 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 188: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1997 - accuracy: 0.9192 - f1_metric: 0.9264 - val_loss: 0.1256 - val_accuracy: 0.9634 - val_f1_metric: 0.8958 - lr: 0.0010\n",
            "Epoch 189/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1908 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 189: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1714 - accuracy: 0.9375 - f1_metric: 0.9375 - val_loss: 0.1238 - val_accuracy: 0.9573 - val_f1_metric: 0.8125 - lr: 0.0010\n",
            "Epoch 190/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2338 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 190: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1785 - accuracy: 0.9390 - f1_metric: 0.9389 - val_loss: 0.1235 - val_accuracy: 0.9512 - val_f1_metric: 0.8875 - lr: 0.0010\n",
            "Epoch 191/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2176 - accuracy: 0.9000 - f1_metric: 0.9000\n",
            "Epoch 191: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1612 - accuracy: 0.9314 - f1_metric: 0.9375 - val_loss: 0.1166 - val_accuracy: 0.9512 - val_f1_metric: 0.8875 - lr: 0.0010\n",
            "Epoch 192/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1664 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 192: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1755 - accuracy: 0.9405 - f1_metric: 0.9458 - val_loss: 0.1143 - val_accuracy: 0.9634 - val_f1_metric: 0.8958 - lr: 0.0010\n",
            "Epoch 193/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1213 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 193: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1676 - accuracy: 0.9390 - f1_metric: 0.9444 - val_loss: 0.1139 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 0.0010\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1737 - accuracy: 0.9375 - f1_metric: 0.9431\n",
            "Epoch 194: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.1737 - accuracy: 0.9375 - f1_metric: 0.9431 - val_loss: 0.1094 - val_accuracy: 0.9634 - val_f1_metric: 0.8958 - lr: 0.0010\n",
            "Epoch 195/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1715 - accuracy: 0.9411 - f1_metric: 0.9411\n",
            "Epoch 195: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.1692 - accuracy: 0.9421 - f1_metric: 0.9417 - val_loss: 0.1193 - val_accuracy: 0.9756 - val_f1_metric: 0.9042 - lr: 0.0010\n",
            "Epoch 196/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2161 - accuracy: 0.8875 - f1_metric: 0.8875\n",
            "Epoch 196: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.1845 - accuracy: 0.9238 - f1_metric: 0.9306 - val_loss: 0.1206 - val_accuracy: 0.9634 - val_f1_metric: 0.8958 - lr: 0.0010\n",
            "Epoch 197/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1049 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 197: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.1700 - accuracy: 0.9390 - f1_metric: 0.9389 - val_loss: 0.1275 - val_accuracy: 0.9390 - val_f1_metric: 0.8792 - lr: 0.0010\n",
            "Epoch 198/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1901 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 198: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1633 - accuracy: 0.9451 - f1_metric: 0.9444 - val_loss: 0.1282 - val_accuracy: 0.9451 - val_f1_metric: 0.8833 - lr: 0.0010\n",
            "Epoch 199/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1676 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 199: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1543 - accuracy: 0.9436 - f1_metric: 0.9486 - val_loss: 0.1370 - val_accuracy: 0.9329 - val_f1_metric: 0.8750 - lr: 0.0010\n",
            "Epoch 200/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1641 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 200: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1618 - accuracy: 0.9360 - f1_metric: 0.9417 - val_loss: 0.1244 - val_accuracy: 0.9329 - val_f1_metric: 0.8750 - lr: 0.0010\n",
            "Epoch 201/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0781 - accuracy: 0.9875 - f1_metric: 0.9875\n",
            "Epoch 201: val_f1_metric did not improve from 0.91250\n",
            "\n",
            "Epoch 201: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.1339 - accuracy: 0.9573 - f1_metric: 0.9611 - val_loss: 0.1148 - val_accuracy: 0.9512 - val_f1_metric: 0.8875 - lr: 0.0010\n",
            "Epoch 202/300\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1777 - accuracy: 0.9281 - f1_metric: 0.9281\n",
            "Epoch 202: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.1740 - accuracy: 0.9299 - f1_metric: 0.9361 - val_loss: 0.1125 - val_accuracy: 0.9512 - val_f1_metric: 0.8875 - lr: 1.0000e-04\n",
            "Epoch 203/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2093 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 203: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.1590 - accuracy: 0.9497 - f1_metric: 0.9486 - val_loss: 0.1106 - val_accuracy: 0.9512 - val_f1_metric: 0.8875 - lr: 1.0000e-04\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1410 - accuracy: 0.9421 - f1_metric: 0.9472\n",
            "Epoch 204: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1410 - accuracy: 0.9421 - f1_metric: 0.9472 - val_loss: 0.1098 - val_accuracy: 0.9512 - val_f1_metric: 0.8875 - lr: 1.0000e-04\n",
            "Epoch 205/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2005 - accuracy: 0.9000 - f1_metric: 0.9000\n",
            "Epoch 205: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.1419 - accuracy: 0.9436 - f1_metric: 0.9431 - val_loss: 0.1092 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 206/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1350 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 206: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1603 - accuracy: 0.9329 - f1_metric: 0.9333 - val_loss: 0.1096 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 207/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1232 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 207: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.1599 - accuracy: 0.9329 - f1_metric: 0.9389 - val_loss: 0.1095 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1424 - accuracy: 0.9405 - f1_metric: 0.9403\n",
            "Epoch 208: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1424 - accuracy: 0.9405 - f1_metric: 0.9403 - val_loss: 0.1101 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 209/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1515 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 209: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1714 - accuracy: 0.9253 - f1_metric: 0.9208 - val_loss: 0.1092 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 210/300\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1557 - accuracy: 0.9391 - f1_metric: 0.9391\n",
            "Epoch 210: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.1599 - accuracy: 0.9375 - f1_metric: 0.9319 - val_loss: 0.1086 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 211/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1283 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 211: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1379 - accuracy: 0.9527 - f1_metric: 0.9569 - val_loss: 0.1092 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 212/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1288 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 212: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.1239 - accuracy: 0.9512 - f1_metric: 0.9500 - val_loss: 0.1100 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 213/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2432 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 213: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.1424 - accuracy: 0.9543 - f1_metric: 0.9472 - val_loss: 0.1109 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1452 - accuracy: 0.9466 - f1_metric: 0.9403\n",
            "Epoch 214: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.1452 - accuracy: 0.9466 - f1_metric: 0.9403 - val_loss: 0.1111 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1536 - accuracy: 0.9466 - f1_metric: 0.9403\n",
            "Epoch 215: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.1536 - accuracy: 0.9466 - f1_metric: 0.9403 - val_loss: 0.1127 - val_accuracy: 0.9634 - val_f1_metric: 0.8958 - lr: 1.0000e-04\n",
            "Epoch 216/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.3238 - accuracy: 0.8875 - f1_metric: 0.8875\n",
            "Epoch 216: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1677 - accuracy: 0.9375 - f1_metric: 0.9431 - val_loss: 0.1132 - val_accuracy: 0.9634 - val_f1_metric: 0.8958 - lr: 1.0000e-04\n",
            "Epoch 217/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1176 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 217: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.1286 - accuracy: 0.9527 - f1_metric: 0.9514 - val_loss: 0.1125 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 218/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1977 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 218: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.1299 - accuracy: 0.9649 - f1_metric: 0.9625 - val_loss: 0.1106 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 219/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2090 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 219: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.1368 - accuracy: 0.9482 - f1_metric: 0.9306 - val_loss: 0.1099 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 220/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1352 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 220: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1448 - accuracy: 0.9512 - f1_metric: 0.9500 - val_loss: 0.1088 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1560 - accuracy: 0.9436 - f1_metric: 0.9486\n",
            "Epoch 221: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.1560 - accuracy: 0.9436 - f1_metric: 0.9486 - val_loss: 0.1082 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1252 - accuracy: 0.9512 - f1_metric: 0.9500\n",
            "Epoch 222: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.1252 - accuracy: 0.9512 - f1_metric: 0.9500 - val_loss: 0.1085 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 223/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1272 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 223: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1582 - accuracy: 0.9451 - f1_metric: 0.9333 - val_loss: 0.1109 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.9497 - f1_metric: 0.9486\n",
            "Epoch 224: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.1498 - accuracy: 0.9497 - f1_metric: 0.9486 - val_loss: 0.1107 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 225/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0947 - accuracy: 0.9750 - f1_metric: 0.9750\n",
            "Epoch 225: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1392 - accuracy: 0.9466 - f1_metric: 0.9458 - val_loss: 0.1103 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.9314 - f1_metric: 0.9375\n",
            "Epoch 226: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.1697 - accuracy: 0.9314 - f1_metric: 0.9375 - val_loss: 0.1106 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1381 - accuracy: 0.9345 - f1_metric: 0.9403\n",
            "Epoch 227: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.1381 - accuracy: 0.9345 - f1_metric: 0.9403 - val_loss: 0.1103 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 228/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1349 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 228: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.1491 - accuracy: 0.9497 - f1_metric: 0.9486 - val_loss: 0.1097 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 229/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0852 - accuracy: 0.9875 - f1_metric: 0.9875\n",
            "Epoch 229: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.1508 - accuracy: 0.9375 - f1_metric: 0.9319 - val_loss: 0.1098 - val_accuracy: 0.9634 - val_f1_metric: 0.8958 - lr: 1.0000e-04\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.9588 - f1_metric: 0.9625\n",
            "Epoch 230: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.1297 - accuracy: 0.9588 - f1_metric: 0.9625 - val_loss: 0.1100 - val_accuracy: 0.9634 - val_f1_metric: 0.8958 - lr: 1.0000e-04\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1675 - accuracy: 0.9405 - f1_metric: 0.9347\n",
            "Epoch 231: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.1675 - accuracy: 0.9405 - f1_metric: 0.9347 - val_loss: 0.1100 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 232/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1913 - accuracy: 0.9125 - f1_metric: 0.9125\n",
            "Epoch 232: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.1552 - accuracy: 0.9390 - f1_metric: 0.9389 - val_loss: 0.1100 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 233/300\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1383 - accuracy: 0.9516 - f1_metric: 0.9516\n",
            "Epoch 233: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.1395 - accuracy: 0.9497 - f1_metric: 0.9431 - val_loss: 0.1094 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 234/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1045 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 234: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.1518 - accuracy: 0.9466 - f1_metric: 0.9458 - val_loss: 0.1092 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 235/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1057 - accuracy: 0.9750 - f1_metric: 0.9750\n",
            "Epoch 235: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1421 - accuracy: 0.9527 - f1_metric: 0.9514 - val_loss: 0.1086 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 236/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1493 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 236: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1538 - accuracy: 0.9451 - f1_metric: 0.9444 - val_loss: 0.1079 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 237/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2359 - accuracy: 0.9000 - f1_metric: 0.9000\n",
            "Epoch 237: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.1560 - accuracy: 0.9512 - f1_metric: 0.9556 - val_loss: 0.1080 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 238/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1717 - accuracy: 0.9411 - f1_metric: 0.9411\n",
            "Epoch 238: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.1792 - accuracy: 0.9375 - f1_metric: 0.9319 - val_loss: 0.1091 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 239/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1479 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 239: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1308 - accuracy: 0.9588 - f1_metric: 0.9625 - val_loss: 0.1099 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 240/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1105 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 240: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1262 - accuracy: 0.9512 - f1_metric: 0.9556 - val_loss: 0.1098 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 241/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1166 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 241: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1494 - accuracy: 0.9482 - f1_metric: 0.9472 - val_loss: 0.1096 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 242/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1734 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 242: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1458 - accuracy: 0.9497 - f1_metric: 0.9375 - val_loss: 0.1099 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 243/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2116 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 243: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1435 - accuracy: 0.9482 - f1_metric: 0.9528 - val_loss: 0.1087 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 244/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1584 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 244: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1574 - accuracy: 0.9482 - f1_metric: 0.9417 - val_loss: 0.1078 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 245/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1677 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 245: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1442 - accuracy: 0.9497 - f1_metric: 0.9486 - val_loss: 0.1065 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 246/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1133 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 246: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1733 - accuracy: 0.9345 - f1_metric: 0.9403 - val_loss: 0.1056 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 247/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1041 - accuracy: 0.9750 - f1_metric: 0.9750\n",
            "Epoch 247: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1365 - accuracy: 0.9466 - f1_metric: 0.9458 - val_loss: 0.1052 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 248/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1319 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 248: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1439 - accuracy: 0.9543 - f1_metric: 0.9583 - val_loss: 0.1053 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 249/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1080 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 249: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1373 - accuracy: 0.9436 - f1_metric: 0.9431 - val_loss: 0.1055 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 250/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1525 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 250: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1423 - accuracy: 0.9466 - f1_metric: 0.9403 - val_loss: 0.1057 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 251/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1629 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 251: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1606 - accuracy: 0.9405 - f1_metric: 0.9458 - val_loss: 0.1055 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 252/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0967 - accuracy: 0.9750 - f1_metric: 0.9750\n",
            "Epoch 252: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1267 - accuracy: 0.9573 - f1_metric: 0.9500 - val_loss: 0.1054 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 253/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1524 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 253: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1445 - accuracy: 0.9527 - f1_metric: 0.9569 - val_loss: 0.1058 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 254/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2303 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 254: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1499 - accuracy: 0.9482 - f1_metric: 0.9472 - val_loss: 0.1058 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 255/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1402 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 255: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1320 - accuracy: 0.9527 - f1_metric: 0.9458 - val_loss: 0.1046 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 256/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1611 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 256: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1309 - accuracy: 0.9558 - f1_metric: 0.9597 - val_loss: 0.1041 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 257/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0973 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 257: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1162 - accuracy: 0.9619 - f1_metric: 0.9597 - val_loss: 0.1043 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 258/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1757 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 258: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1511 - accuracy: 0.9543 - f1_metric: 0.9528 - val_loss: 0.1051 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 259/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1199 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 259: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1475 - accuracy: 0.9497 - f1_metric: 0.9542 - val_loss: 0.1049 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 260/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1404 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 260: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1390 - accuracy: 0.9466 - f1_metric: 0.9514 - val_loss: 0.1052 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 261/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1390 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 261: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1309 - accuracy: 0.9482 - f1_metric: 0.9472 - val_loss: 0.1049 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 262/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1532 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 262: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1296 - accuracy: 0.9527 - f1_metric: 0.9458 - val_loss: 0.1042 - val_accuracy: 0.9573 - val_f1_metric: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 263/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1146 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 263: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1602 - accuracy: 0.9390 - f1_metric: 0.9333 - val_loss: 0.1036 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 264/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1341 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 264: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1363 - accuracy: 0.9512 - f1_metric: 0.9556 - val_loss: 0.1031 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 265/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1230 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 265: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1322 - accuracy: 0.9466 - f1_metric: 0.9458 - val_loss: 0.1024 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 266/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2516 - accuracy: 0.8875 - f1_metric: 0.8875\n",
            "Epoch 266: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1494 - accuracy: 0.9436 - f1_metric: 0.9486 - val_loss: 0.1013 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 267/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1285 - accuracy: 0.9750 - f1_metric: 0.9750\n",
            "Epoch 267: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1443 - accuracy: 0.9497 - f1_metric: 0.9542 - val_loss: 0.1015 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 268/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1432 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 268: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1551 - accuracy: 0.9421 - f1_metric: 0.9472 - val_loss: 0.1014 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 269/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1845 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 269: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.1535 - accuracy: 0.9482 - f1_metric: 0.9472 - val_loss: 0.1020 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 270/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1310 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 270: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1437 - accuracy: 0.9527 - f1_metric: 0.9514 - val_loss: 0.1023 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 271/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1480 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 271: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1381 - accuracy: 0.9497 - f1_metric: 0.9375 - val_loss: 0.1031 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 272/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1402 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 272: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.1630 - accuracy: 0.9451 - f1_metric: 0.9500 - val_loss: 0.1046 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 273/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2131 - accuracy: 0.9000 - f1_metric: 0.9000\n",
            "Epoch 273: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1550 - accuracy: 0.9421 - f1_metric: 0.9417 - val_loss: 0.1032 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 274/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1356 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 274: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1292 - accuracy: 0.9482 - f1_metric: 0.9528 - val_loss: 0.1025 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 275/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1400 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 275: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1392 - accuracy: 0.9512 - f1_metric: 0.9556 - val_loss: 0.1023 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 276/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0714 - accuracy: 0.9875 - f1_metric: 0.9875\n",
            "Epoch 276: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1466 - accuracy: 0.9497 - f1_metric: 0.9486 - val_loss: 0.1024 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 277/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1227 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 277: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1376 - accuracy: 0.9466 - f1_metric: 0.9458 - val_loss: 0.1025 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 278/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0635 - accuracy: 0.9750 - f1_metric: 0.9750\n",
            "Epoch 278: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1282 - accuracy: 0.9527 - f1_metric: 0.9514 - val_loss: 0.1027 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 279/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1656 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 279: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1521 - accuracy: 0.9405 - f1_metric: 0.9403 - val_loss: 0.1037 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 280/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1659 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 280: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1483 - accuracy: 0.9543 - f1_metric: 0.9583 - val_loss: 0.1048 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 281/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1506 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 281: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1363 - accuracy: 0.9527 - f1_metric: 0.9458 - val_loss: 0.1052 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 282/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1159 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 282: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1675 - accuracy: 0.9405 - f1_metric: 0.9403 - val_loss: 0.1044 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 283/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1385 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 283: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1493 - accuracy: 0.9482 - f1_metric: 0.9528 - val_loss: 0.1044 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 284/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1941 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 284: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1443 - accuracy: 0.9512 - f1_metric: 0.9556 - val_loss: 0.1033 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 285/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1069 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 285: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1374 - accuracy: 0.9466 - f1_metric: 0.9514 - val_loss: 0.1034 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 286/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2554 - accuracy: 0.8625 - f1_metric: 0.8625\n",
            "Epoch 286: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1633 - accuracy: 0.9314 - f1_metric: 0.9319 - val_loss: 0.1033 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 287/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1504 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 287: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1462 - accuracy: 0.9436 - f1_metric: 0.9431 - val_loss: 0.1028 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 288/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1276 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 288: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1632 - accuracy: 0.9421 - f1_metric: 0.9472 - val_loss: 0.1021 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 289/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0922 - accuracy: 0.9750 - f1_metric: 0.9750\n",
            "Epoch 289: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1400 - accuracy: 0.9573 - f1_metric: 0.9611 - val_loss: 0.1020 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 290/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1463 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 290: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1443 - accuracy: 0.9512 - f1_metric: 0.9556 - val_loss: 0.1020 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 291/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0871 - accuracy: 0.9750 - f1_metric: 0.9750\n",
            "Epoch 291: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1548 - accuracy: 0.9421 - f1_metric: 0.9361 - val_loss: 0.1021 - val_accuracy: 0.9695 - val_f1_metric: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 292/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1090 - accuracy: 0.9750 - f1_metric: 0.9750\n",
            "Epoch 292: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1350 - accuracy: 0.9543 - f1_metric: 0.9583 - val_loss: 0.1017 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 293/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1050 - accuracy: 0.9625 - f1_metric: 0.9625\n",
            "Epoch 293: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1546 - accuracy: 0.9436 - f1_metric: 0.9431 - val_loss: 0.1009 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 294/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1634 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 294: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1357 - accuracy: 0.9497 - f1_metric: 0.9486 - val_loss: 0.1013 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 295/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1385 - accuracy: 0.9500 - f1_metric: 0.9500\n",
            "Epoch 295: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.1620 - accuracy: 0.9390 - f1_metric: 0.9444 - val_loss: 0.1014 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 296/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.2314 - accuracy: 0.9250 - f1_metric: 0.9250\n",
            "Epoch 296: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1346 - accuracy: 0.9497 - f1_metric: 0.9542 - val_loss: 0.1014 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 297/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1711 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 297: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.1503 - accuracy: 0.9466 - f1_metric: 0.9514 - val_loss: 0.1011 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 298/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0689 - accuracy: 0.9750 - f1_metric: 0.9750\n",
            "Epoch 298: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1252 - accuracy: 0.9482 - f1_metric: 0.9472 - val_loss: 0.1008 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "Epoch 299/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1102 - accuracy: 0.9750 - f1_metric: 0.9750\n",
            "Epoch 299: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1359 - accuracy: 0.9512 - f1_metric: 0.9556 - val_loss: 0.1004 - val_accuracy: 0.9878 - val_f1_metric: 0.9125 - lr: 1.0000e-04\n",
            "Epoch 300/300\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1444 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 300: val_f1_metric did not improve from 0.91250\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1489 - accuracy: 0.9482 - f1_metric: 0.9472 - val_loss: 0.1009 - val_accuracy: 0.9817 - val_f1_metric: 0.9083 - lr: 1.0000e-04\n",
            "CPU times: user 55.1 s, sys: 1.39 s, total: 56.5 s\n",
            "Wall time: 1min 23s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"last\"\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['f1_metric'])\n",
        "plt.plot(history.history['val_f1_metric'])\n",
        "\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train_loss', 'val_loss', 'f1', 'val_f1'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "gWnX58sBayYP",
        "outputId": "2dcdb552-ad01-404b-e6fa-031b85f44a01"
      },
      "id": "gWnX58sBayYP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score, cohen_kappa_score\n",
        "import seaborn as sns\n",
        "\n",
        "model = load_model(best_model_path)\n",
        "test_res = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"keras evaluate=\", test_res)\n",
        "pred = model.predict(x_test)\n",
        "pred_classes = np.argmax(pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "#check_baseline(pred_classes, y_test_classes)\n",
        "conf_mat = confusion_matrix(y_test_classes, pred_classes)\n",
        "print(conf_mat)\n",
        "labels = [0,1,2]\n",
        "# ax = sns.heatmap(conf_mat, xticklabels=labels, yticklabels=labels, annot=True)\n",
        "# ax.xaxis.set_ticks_position('top')\n",
        "f1_weighted = f1_score(y_test_classes, pred_classes, labels=None,\n",
        "         average='weighted', sample_weight=None)\n",
        "print(\"F1 score (weighted)\", f1_weighted)\n",
        "print(\"F1 score (macro)\", f1_score(y_test_classes, pred_classes, labels=None,\n",
        "         average='macro', sample_weight=None))\n",
        "print(\"F1 score (micro)\", f1_score(y_test_classes, pred_classes, labels=None,\n",
        "         average='micro', sample_weight=None))  # weighted and micro preferred in case of imbalance\n",
        "# https://scikit-learn.org/stable/modules/model_evaluation.html#cohen-s-kappa --> supports multiclass; ref: https://stats.stackexchange.com/questions/82162/cohens-kappa-in-plain-english\n",
        "print(\"cohen's Kappa\", cohen_kappa_score(y_test_classes, pred_classes))\n",
        "\n",
        "prec = []\n",
        "for i, row in enumerate(conf_mat):\n",
        "    prec.append(np.round(row[i]/np.sum(row), 2))\n",
        "    print(\"precision of class {} = {}\".format(i, prec[i]))\n",
        "print(\"precision avg\", sum(prec)/len(prec))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivzU3c9xa3o1",
        "outputId": "ebaa8da1-ce39-46bf-88d2-b4d867b4e0d7"
      },
      "id": "ivzU3c9xa3o1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keras evaluate= [0.14939069747924805, 0.9512194991111755, 0.9488323926925659]\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "[[97  3]\n",
            " [ 7 98]]\n",
            "F1 score (weighted) 0.9512241553026609\n",
            "F1 score (macro) 0.9512183514182372\n",
            "F1 score (micro) 0.9512195121951219\n",
            "cohen's Kappa 0.9024738344433872\n",
            "precision of class 0 = 0.97\n",
            "precision of class 1 = 0.93\n",
            "precision avg 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifications with CNN"
      ],
      "metadata": {
        "id": "9GzYRzKA5q3w"
      },
      "id": "9GzYRzKA5q3w"
    },
    {
      "cell_type": "code",
      "source": [
        "df = dataset"
      ],
      "metadata": {
        "id": "PHnBVxWv6dRl"
      },
      "id": "PHnBVxWv6dRl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
        "from collections import Counter\n",
        "\n",
        "list_features = list(df.iloc[:, 0:13].columns)\n",
        "print('Total number of features', len(list_features))\n",
        "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:, 0:13].values, Target.values, train_size=0.8,\n",
        "                                                    test_size=0.2, random_state=2, shuffle=True, stratify=Target.values)\n",
        "\n",
        "# smote = RandomOverSampler(random_state=42, sampling_strategy='not majority')\n",
        "# x_train, y_train = smote.fit_resample(x_train, y_train)\n",
        "# print('Resampled dataset shape %s' % Counter(y_train))\n",
        "\n",
        "if 0.7*x_train.shape[0] < 2500:\n",
        "    train_split = 0.8\n",
        "else:\n",
        "    train_split = 0.7\n",
        "# train_split = 0.7\n",
        "print('train_split =',train_split)\n",
        "x_train, x_cv, y_train, y_cv = train_test_split(x_train, y_train, train_size=train_split,\n",
        "                                                random_state=2, shuffle=True, stratify=y_train)\n",
        "mm_scaler = MinMaxScaler(feature_range=(0, 1)) # or StandardScaler?\n",
        "x_train = mm_scaler.fit_transform(x_train)\n",
        "x_cv = mm_scaler.transform(x_cv)\n",
        "x_test = mm_scaler.transform(x_test)\n",
        "\n",
        "x_main = x_train.copy()\n",
        "print(\"Shape of x, y train/cv/test {} {} {} {} {} {}\".format(x_train.shape, y_train.shape, x_cv.shape, y_cv.shape, x_test.shape, y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi973z4R5xwF",
        "outputId": "5967500c-89b4-44e2-8ba7-1699f4699a54"
      },
      "id": "Fi973z4R5xwF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of features 13\n",
            "train_split = 0.8\n",
            "Shape of x, y train/cv/test (656, 13) (656,) (164, 13) (164,) (205, 13) (205,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = 9  # should be a perfect square\n",
        "selection_method = 'all'\n",
        "topk = 13 if selection_method == 'all' else num_features"
      ],
      "metadata": {
        "id": "-qVp9X2z6jkY"
      },
      "id": "-qVp9X2z6jkY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
        "\n",
        "if selection_method == 'anova' or selection_method == 'all':\n",
        "    select_k_best = SelectKBest(f_classif, k=topk)\n",
        "    if selection_method != 'all':\n",
        "        x_train = select_k_best.fit_transform(x_main, y_train)\n",
        "        x_cv = select_k_best.transform(x_cv)\n",
        "        x_test = select_k_best.transform(x_test)\n",
        "    else:\n",
        "        select_k_best.fit(x_main, y_train)\n",
        "\n",
        "    selected_features_anova = itemgetter(*select_k_best.get_support(indices=True))(list_features)\n",
        "    print(selected_features_anova)\n",
        "    print(select_k_best.get_support(indices=True))\n",
        "    print(\"****************************************\")\n",
        "\n",
        "if selection_method == 'mutual_info' or selection_method == 'all':\n",
        "    select_k_best = SelectKBest(mutual_info_classif, k=topk)\n",
        "    if selection_method != 'all':\n",
        "        x_train = select_k_best.fit_transform(x_main, y_train)\n",
        "        x_cv = select_k_best.transform(x_cv)\n",
        "        x_test = select_k_best.transform(x_test)\n",
        "    else:\n",
        "        select_k_best.fit(x_main, y_train)\n",
        "\n",
        "    selected_features_mic = itemgetter(*select_k_best.get_support(indices=True))(list_features)\n",
        "    print(len(selected_features_mic), selected_features_mic)\n",
        "    print(select_k_best.get_support(indices=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "nSxCpwo06o4X",
        "outputId": "68cd998b-0737-4c58-b7f3-0ceb379fa971"
      },
      "id": "nSxCpwo06o4X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal')\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
            "****************************************\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelectKBest(k=13, score_func=<function mutual_info_classif at 0x7c7aaaffde10>)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SelectKBest(k=13, score_func=&lt;function mutual_info_classif at 0x7c7aaaffde10&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest(k=13, score_func=&lt;function mutual_info_classif at 0x7c7aaaffde10&gt;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13 ('age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal')\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if selection_method == 'all':\n",
        "    common = list(set(selected_features_anova).intersection(selected_features_mic))\n",
        "    print(\"common selected featues\", len(common), common)\n",
        "    if len(common) < num_features:\n",
        "        raise Exception('number of common features found {} < {} required features. Increase \"topk variable\"'.format(len(common), num_features))\n",
        "    feat_idx = []\n",
        "    for c in common:\n",
        "        feat_idx.append(list_features.index(c))\n",
        "    feat_idx = sorted(feat_idx[0:num_features])\n",
        "    print(feat_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffEFNFkZ6qv0",
        "outputId": "470be501-f72b-4b27-aca0-445342fe115f"
      },
      "id": "ffEFNFkZ6qv0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common selected featues 13 ['fbs', 'ca', 'sex', 'age', 'trestbps', 'exang', 'oldpeak', 'thalach', 'slope', 'chol', 'restecg', 'thal', 'cp']\n",
            "[0, 1, 3, 5, 7, 8, 9, 10, 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if selection_method == 'all':\n",
        "    x_train = x_train[:, feat_idx]\n",
        "    x_cv = x_cv[:, feat_idx]\n",
        "    x_test = x_test[:, feat_idx]\n",
        "\n",
        "print(\"Shape of x, y train/cv/test {} {} {} {} {} {}\".format(x_train.shape,\n",
        "                                                             y_train.shape,\n",
        "                                                             x_cv.shape,\n",
        "                                                             y_cv.shape,\n",
        "                                                             x_test.shape,\n",
        "                                                             y_test.shape\n",
        "                                                             ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRiWrcdc6t9l",
        "outputId": "20d2edbe-a734-4533-c6af-6b351b96a736"
      },
      "id": "GRiWrcdc6t9l",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x, y train/cv/test (656, 9) (656,) (164, 9) (164,) (205, 9) (205,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_labels, _counts = np.unique(y_train, return_counts=True)\n",
        "print(\"percentage of class 0 = {}, class 1 = {}\".format(_counts[0]/len(y_train) * 100, _counts[1]/len(y_train) * 100,  ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROOgFXW260XF",
        "outputId": "7255d74b-0aee-4277-8af2-c2e3acb61b6f"
      },
      "id": "ROOgFXW260XF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "percentage of class 0 = 48.6280487804878, class 1 = 51.37195121951219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "def get_sample_weights(y):\n",
        "    \"\"\"\n",
        "    calculate the sample weights based on class weights. Used for models with\n",
        "    imbalanced data and one hot encoding prediction.\n",
        "\n",
        "    params:\n",
        "        y: class labels as integers\n",
        "    \"\"\"\n",
        "\n",
        "    y = y.astype(int)  # compute_class_weight needs int labels\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
        "\n",
        "    print(\"real class weights are {}\".format(class_weights), np.unique(y))\n",
        "    print(\"value_counts\", np.unique(y, return_counts=True))\n",
        "    sample_weights = y.copy().astype(float)\n",
        "    for i in np.unique(y):\n",
        "        sample_weights[sample_weights == i] = class_weights[i]  # if i == 2 else 0.8 * class_weights[i]\n",
        "        # sample_weights = np.where(sample_weights == i, class_weights[int(i)], y_)\n",
        "\n",
        "    return sample_weights\n",
        "\n",
        "def reshape_as_image(x, img_width, img_height):\n",
        "    x_temp = np.zeros((len(x), img_height, img_width))\n",
        "    for i in range(x.shape[0]):\n",
        "        # print(type(x), type(x_temp), x.shape)\n",
        "        x_temp[i] = np.reshape(x[i], (img_height, img_width))\n",
        "\n",
        "    return x_temp\n",
        "\n",
        "def f1_weighted(y_true, y_pred):\n",
        "    y_true_class = tf.math.argmax(y_true, axis=1, output_type=tf.dtypes.int32)\n",
        "    y_pred_class = tf.math.argmax(y_pred, axis=1, output_type=tf.dtypes.int32)\n",
        "    conf_mat = tf.math.confusion_matrix(y_true_class, y_pred_class)  # can use conf_mat[0, :], tf.slice()\n",
        "    # precision = TP/TP+FP, recall = TP/TP+FN\n",
        "    rows, cols = conf_mat.get_shape()\n",
        "    size = y_true_class.get_shape()[0]\n",
        "    precision = tf.constant([0, 0, 0])  # change this to use rows/cols as size\n",
        "    recall = tf.constant([0, 0, 0])\n",
        "    class_counts = tf.constant([0, 0, 0])\n",
        "\n",
        "    def get_precision(i, conf_mat):\n",
        "        print(\"prec check\", conf_mat, conf_mat[i, i], tf.reduce_sum(conf_mat[:, i]))\n",
        "        precision[i].assign(conf_mat[i, i] / tf.reduce_sum(conf_mat[:, i]))\n",
        "        recall[i].assign(conf_mat[i, i] / tf.reduce_sum(conf_mat[i, :]))\n",
        "        tf.add(i, 1)\n",
        "        return i, conf_mat, precision, recall\n",
        "\n",
        "    def tf_count(i):\n",
        "        elements_equal_to_value = tf.equal(y_true_class, i)\n",
        "        as_ints = tf.cast(elements_equal_to_value, tf.int32)\n",
        "        count = tf.reduce_sum(as_ints)\n",
        "        class_counts[i].assign(count)\n",
        "        tf.add(i, 1)\n",
        "        return count\n",
        "\n",
        "    def condition(i, conf_mat):\n",
        "        return tf.less(i, 3)\n",
        "\n",
        "    i = tf.constant(3)\n",
        "    i, conf_mat = tf.while_loop(condition, get_precision, [i, conf_mat])\n",
        "\n",
        "    i = tf.constant(3)\n",
        "    c = lambda i: tf.less(i, 3)\n",
        "    b = tf_count(i)\n",
        "    tf.while_loop(c, b, [i])\n",
        "\n",
        "    weights = tf.math.divide(class_counts, size)\n",
        "    numerators = tf.math.multiply(tf.math.multiply(precision, recall), tf.constant(2))\n",
        "    denominators = tf.math.add(precision, recall)\n",
        "    f1s = tf.math.divide(numerators, denominators)\n",
        "    weighted_f1 = tf.reduce_sum(f.math.multiply(f1s, weights))\n",
        "    return weighted_f1\n",
        "\n",
        "def f1_metric(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    this calculates precision & recall\n",
        "    \"\"\"\n",
        "\n",
        "    def recall(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))  # mistake: y_pred of 0.3 is also considered 1\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    # y_true_class = tf.math.argmax(y_true, axis=1, output_type=tf.dtypes.int32)\n",
        "    # y_pred_class = tf.math.argmax(y_pred, axis=1, output_type=tf.dtypes.int32)\n",
        "    # conf_mat = tf.math.confusion_matrix(y_true_class, y_pred_class)\n",
        "    # tf.Print(conf_mat, [conf_mat], \"confusion_matrix\")\n",
        "\n",
        "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
        "\n",
        "get_custom_objects().update({\"f1_metric\": f1_metric, \"f1_weighted\": f1_weighted})"
      ],
      "metadata": {
        "id": "7ioEK5kM63cV"
      },
      "id": "7ioEK5kM63cV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_weights = get_sample_weights(y_train)\n",
        "print(\"Test sample_weights\")\n",
        "rand_idx = np.random.randint(0, 656, 30)\n",
        "print(y_train[rand_idx])\n",
        "print(sample_weights[rand_idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbAIscDA66Rk",
        "outputId": "0afa5a01-b4af-4723-e0ac-111caea5d979"
      },
      "id": "vbAIscDA66Rk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "real class weights are [1.02821317 0.97329377] [0 1]\n",
            "value_counts (array([0, 1]), array([319, 337]))\n",
            "Test sample_weights\n",
            "[0 1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0]\n",
            "[1.02821317 0.97329377 0.97329377 0.97329377 1.02821317 0.97329377\n",
            " 0.97329377 1.02821317 1.02821317 1.02821317 0.97329377 0.97329377\n",
            " 0.97329377 1.02821317 0.97329377 1.02821317 0.97329377 0.97329377\n",
            " 1.02821317 1.02821317 0.97329377 0.97329377 0.97329377 0.97329377\n",
            " 0.97329377 0.97329377 1.02821317 0.97329377 0.97329377 1.02821317]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_enc = OneHotEncoder(sparse_output=False, categories='auto')  # , categories='auto'\n",
        "y_train = one_hot_enc.fit_transform(y_train.reshape(-1, 1))\n",
        "print(\"y_train\",y_train.shape)\n",
        "y_cv = one_hot_enc.transform(y_cv.reshape(-1, 1))\n",
        "y_test = one_hot_enc.transform(y_test.reshape(-1, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI5yAeX-69mN",
        "outputId": "04af950f-74ee-49f3-f816-0f968348f121"
      },
      "id": "NI5yAeX-69mN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train (656, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim = int(np.sqrt(num_features))\n",
        "x_train = reshape_as_image(x_train, dim, dim)\n",
        "x_cv = reshape_as_image(x_cv, dim, dim)\n",
        "x_test = reshape_as_image(x_test, dim, dim)\n",
        "# adding a 1-dim for channels (3)\n",
        "x_train = np.stack((x_train,) * 3, axis=-1)\n",
        "x_test = np.stack((x_test,) * 3, axis=-1)\n",
        "x_cv = np.stack((x_cv,) * 3, axis=-1)\n",
        "print(\"final shape of x, y train/test {} {} {} {}\".format(x_train.shape, y_train.shape, x_test.shape, y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGk_l03M6_33",
        "outputId": "dc261165-3226-41ef-f90b-b2cd1d0fea5a"
      },
      "id": "nGk_l03M6_33",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final shape of x, y train/test (656, 3, 3, 3) (656, 2) (205, 3, 3, 3) (205, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "columns = rows = 4\n",
        "for i in range(1, columns*rows +1):\n",
        "    index = np.random.randint(len(x_train))\n",
        "    img = x_train[index]\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title('image_'+str(index)+'_class_'+str(np.argmax(y_train[index])), fontsize=10)\n",
        "    plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
        "    plt.imshow(img)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "jSXdWwEK7Bz2",
        "outputId": "65f0a424-9f48-4f3a-c1fc-4ff5675f323e"
      },
      "id": "jSXdWwEK7Bz2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, LeakyReLU\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, Callback\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
        "from tensorflow.keras.initializers import RandomUniform, RandomNormal\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "params = {'batch_size': 80, 'conv2d_layers': {'conv2d_do_1': 0.22, 'conv2d_filters_1': 20, 'conv2d_kernel_size_1': 2, 'conv2d_mp_1': 2,\n",
        "                                              'conv2d_strides_1': 1, 'kernel_regularizer_1': 0.0, 'conv2d_do_2': 0.05,\n",
        "                                              'conv2d_filters_2': 40, 'conv2d_kernel_size_2': 2, 'conv2d_mp_2': 2, 'conv2d_strides_2': 2,\n",
        "                                              'kernel_regularizer_2': 0.0, 'layers': 'two'},\n",
        "          'dense_layers': {'dense_do_1': 0.22, 'dense_nodes_1': 100, 'kernel_regularizer_1': 0.0, 'layers': 'one'},\n",
        "          'epochs': 300, 'lr': 0.001, 'optimizer': 'adam'}"
      ],
      "metadata": {
        "id": "CN7_YK7i7FTW"
      },
      "id": "CN7_YK7i7FTW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import *\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.metrics import AUC\n",
        "\n",
        "def f1_custom(y_true, y_pred):\n",
        "    y_t = np.argmax(y_true, axis=1)\n",
        "    y_p = np.argmax(y_pred, axis=1)\n",
        "    f1_score(y_t, y_p, labels=None, average='weighted', sample_weight=None, zero_division='warn')\n",
        "\n",
        "def create_model_cnn(params):\n",
        "    model = Sequential()\n",
        "\n",
        "    print(\"Training with params {}\".format(params))\n",
        "    # (batch_size, timesteps, data_dim)\n",
        "    # x_train, y_train = get_data_cnn(df, df.head(1).iloc[0][\"timestamp\"])[0:2]\n",
        "    conv2d_layer1 = Conv2D(params[\"conv2d_layers\"][\"conv2d_filters_1\"],\n",
        "                           params[\"conv2d_layers\"][\"conv2d_kernel_size_1\"],\n",
        "                           strides=params[\"conv2d_layers\"][\"conv2d_strides_1\"],\n",
        "                           kernel_regularizer=regularizers.l2(params[\"conv2d_layers\"][\"kernel_regularizer_1\"]),\n",
        "                           padding='valid',activation=\"relu\", use_bias=True,\n",
        "                           kernel_initializer='glorot_uniform',\n",
        "                           input_shape=(x_train[0].shape[0],\n",
        "                                        x_train[0].shape[1], x_train[0].shape[2]))\n",
        "    model.add(conv2d_layer1)\n",
        "    if params[\"conv2d_layers\"]['conv2d_mp_1'] == 1:\n",
        "        model.add(MaxPool2D(pool_size=2))\n",
        "    model.add(Dropout(params['conv2d_layers']['conv2d_do_1']))\n",
        "    if params[\"conv2d_layers\"]['layers'] == 'two':\n",
        "        conv2d_layer2 = Conv2D(params[\"conv2d_layers\"][\"conv2d_filters_2\"],\n",
        "                               params[\"conv2d_layers\"][\"conv2d_kernel_size_2\"],\n",
        "                               strides=params[\"conv2d_layers\"][\"conv2d_strides_2\"],\n",
        "                               kernel_regularizer=regularizers.l2(params[\"conv2d_layers\"][\"kernel_regularizer_2\"]),\n",
        "                               padding='valid',activation=\"relu\", use_bias=True,\n",
        "                               kernel_initializer='glorot_uniform')\n",
        "        model.add(conv2d_layer2)\n",
        "        if params[\"conv2d_layers\"]['conv2d_mp_2'] == 1:\n",
        "            model.add(MaxPool2D(pool_size=2))\n",
        "        model.add(Dropout(params['conv2d_layers']['conv2d_do_2']))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(params['dense_layers'][\"dense_nodes_1\"], activation='relu'))\n",
        "    model.add(Dropout(params['dense_layers']['dense_do_1']))\n",
        "\n",
        "    if params['dense_layers'][\"layers\"] == 'two':\n",
        "        model.add(Dense(params['dense_layers'][\"dense_nodes_2\"], activation='relu',\n",
        "                        kernel_regularizer=params['dense_layers'][\"kernel_regularizer_1\"]))\n",
        "        model.add(Dropout(params['dense_layers']['dense_do_2']))\n",
        "\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    if params[\"optimizer\"] == 'rmsprop':\n",
        "        optimizer = optimizers.RMSprop(lr=params[\"lr\"])\n",
        "    elif params[\"optimizer\"] == 'sgd':\n",
        "        optimizer = optimizers.SGD(lr=params[\"lr\"], decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    elif params[\"optimizer\"] == 'adam':\n",
        "        optimizer = optimizers.Adam(learning_rate=params[\"lr\"], beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', f1_metric])\n",
        "    # from keras.utils.vis_utils import plot_model use this too for diagram with plot\n",
        "    # model.summary(print_fn=lambda x: print(x + '\\n'))\n",
        "    return model\n",
        "\n",
        "def check_baseline(pred, y_test):\n",
        "    print(\"size of test set\", len(y_test))\n",
        "    e = np.equal(pred, y_test)\n",
        "    print(\"TP class counts\", np.unique(y_test[e], return_counts=True))\n",
        "    print(\"True class counts\", np.unique(y_test, return_counts=True))\n",
        "    print(\"Pred class counts\", np.unique(pred, return_counts=True))\n",
        "    holds = np.unique(y_test, return_counts=True)[1][2]  # number 'hold' predictions\n",
        "    print(\"baseline acc:\", (holds/len(y_test)*100))"
      ],
      "metadata": {
        "id": "rEDIfYm07I7M"
      },
      "id": "rEDIfYm07I7M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG\n",
        "from tensorflow.keras.utils import model_to_dot, plot_model\n",
        "\n",
        "model = create_model_cnn(params)\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False)\n",
        "\n",
        "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "myORv3H97PKo",
        "outputId": "d44ab6de-503e-4a5b-bd4c-8d64e8165ce4"
      },
      "id": "myORv3H97PKo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with params {'batch_size': 80, 'conv2d_layers': {'conv2d_do_1': 0.22, 'conv2d_filters_1': 20, 'conv2d_kernel_size_1': 2, 'conv2d_mp_1': 2, 'conv2d_strides_1': 1, 'kernel_regularizer_1': 0.0, 'conv2d_do_2': 0.05, 'conv2d_filters_2': 40, 'conv2d_kernel_size_2': 2, 'conv2d_mp_2': 2, 'conv2d_strides_2': 2, 'kernel_regularizer_2': 0.0, 'layers': 'two'}, 'dense_layers': {'dense_do_1': 0.22, 'dense_nodes_1': 100, 'kernel_regularizer_1': 0.0, 'layers': 'one'}, 'epochs': 300, 'lr': 0.001, 'optimizer': 'adam'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "best_model_path = os.path.join('.', 'best_model_keras')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n",
        "                   patience=100, min_delta=0.0001)\n",
        "# csv_logger = CSVLogger(os.path.join(OUTPUT_PATH, 'log_training_batch.log'), append=True)\n",
        "rlp = ReduceLROnPlateau(monitor='val_loss', factor=0.02, patience=20, verbose=1, mode='min',\n",
        "                        min_delta=0.001, cooldown=1, min_lr=0.0001)\n",
        "mcp = ModelCheckpoint(best_model_path, monitor='val_f1_metric', verbose=1,\n",
        "                      save_best_only=True, save_weights_only=False, mode='max', period=1)  # val_f1_metric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqaq17f47RHv",
        "outputId": "9f906aa8-c9dd-4520-c913-75a44d716fe9"
      },
      "id": "qqaq17f47RHv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = model.fit(x_train, y_train, epochs=params['epochs'], verbose=1,\n",
        "                            batch_size=64, shuffle=True,\n",
        "                            # validation_split=0.3,\n",
        "                            validation_data=(x_cv, y_cv),\n",
        "                            callbacks=[mcp, rlp, es]\n",
        "                            , sample_weight=sample_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH1alg-E7UxM",
        "outputId": "0c897d5c-8a5a-406b-9ce4-ac110c7a2fe8"
      },
      "id": "WH1alg-E7UxM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            " 1/11 [=>............................] - ETA: 13s - loss: 0.6879 - accuracy: 0.6094 - f1_metric: 0.6094\n",
            "Epoch 1: val_f1_metric improved from -inf to 0.78241, saving model to ./best_model_keras\n",
            "11/11 [==============================] - 3s 154ms/step - loss: 0.6588 - accuracy: 0.6585 - f1_metric: 0.6520 - val_loss: 0.6040 - val_accuracy: 0.7927 - val_f1_metric: 0.7824 - lr: 0.0010\n",
            "Epoch 2/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.6443 - accuracy: 0.6406 - f1_metric: 0.6406\n",
            "Epoch 2: val_f1_metric did not improve from 0.78241\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6142 - accuracy: 0.7165 - f1_metric: 0.7145 - val_loss: 0.5420 - val_accuracy: 0.7866 - val_f1_metric: 0.7731 - lr: 0.0010\n",
            "Epoch 3/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.6598 - accuracy: 0.5781 - f1_metric: 0.5781\n",
            "Epoch 3: val_f1_metric improved from 0.78241 to 0.79282, saving model to ./best_model_keras\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.5653 - accuracy: 0.7256 - f1_metric: 0.7230 - val_loss: 0.4890 - val_accuracy: 0.8049 - val_f1_metric: 0.7928 - lr: 0.0010\n",
            "Epoch 4/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4978 - accuracy: 0.7500 - f1_metric: 0.7500\n",
            "Epoch 4: val_f1_metric improved from 0.79282 to 0.80729, saving model to ./best_model_keras\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.5288 - accuracy: 0.7546 - f1_metric: 0.7628 - val_loss: 0.4579 - val_accuracy: 0.8171 - val_f1_metric: 0.8073 - lr: 0.0010\n",
            "Epoch 5/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.5767 - accuracy: 0.7188 - f1_metric: 0.7187\n",
            "Epoch 5: val_f1_metric improved from 0.80729 to 0.81655, saving model to ./best_model_keras\n",
            "11/11 [==============================] - 2s 169ms/step - loss: 0.5076 - accuracy: 0.7607 - f1_metric: 0.7685 - val_loss: 0.4405 - val_accuracy: 0.8232 - val_f1_metric: 0.8166 - lr: 0.0010\n",
            "Epoch 6/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.4896 - accuracy: 0.7734 - f1_metric: 0.7734\n",
            "Epoch 6: val_f1_metric improved from 0.81655 to 0.83102, saving model to ./best_model_keras\n",
            "11/11 [==============================] - 2s 195ms/step - loss: 0.4930 - accuracy: 0.7698 - f1_metric: 0.7599 - val_loss: 0.4163 - val_accuracy: 0.8354 - val_f1_metric: 0.8310 - lr: 0.0010\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4702 - accuracy: 0.7896 - f1_metric: 0.7955\n",
            "Epoch 7: val_f1_metric did not improve from 0.83102\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.4702 - accuracy: 0.7896 - f1_metric: 0.7955 - val_loss: 0.4035 - val_accuracy: 0.8293 - val_f1_metric: 0.8299 - lr: 0.0010\n",
            "Epoch 8/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4040 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 8: val_f1_metric did not improve from 0.83102\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4693 - accuracy: 0.7866 - f1_metric: 0.7841 - val_loss: 0.3949 - val_accuracy: 0.7988 - val_f1_metric: 0.7957 - lr: 0.0010\n",
            "Epoch 9/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4673 - accuracy: 0.7969 - f1_metric: 0.7969\n",
            "Epoch 9: val_f1_metric did not improve from 0.83102\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.7942 - f1_metric: 0.7912 - val_loss: 0.3830 - val_accuracy: 0.8110 - val_f1_metric: 0.8102 - lr: 0.0010\n",
            "Epoch 10/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.5404 - accuracy: 0.7344 - f1_metric: 0.7344\n",
            "Epoch 10: val_f1_metric did not improve from 0.83102\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4773 - accuracy: 0.7835 - f1_metric: 0.7812 - val_loss: 0.3857 - val_accuracy: 0.8049 - val_f1_metric: 0.8009 - lr: 0.0010\n",
            "Epoch 11/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4142 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 11: val_f1_metric improved from 0.83102 to 0.83623, saving model to ./best_model_keras\n",
            "11/11 [==============================] - 1s 114ms/step - loss: 0.4614 - accuracy: 0.8003 - f1_metric: 0.8011 - val_loss: 0.3710 - val_accuracy: 0.8415 - val_f1_metric: 0.8362 - lr: 0.0010\n",
            "Epoch 12/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.5039 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 12: val_f1_metric improved from 0.83623 to 0.84549, saving model to ./best_model_keras\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.4603 - accuracy: 0.8003 - f1_metric: 0.8097 - val_loss: 0.3715 - val_accuracy: 0.8476 - val_f1_metric: 0.8455 - lr: 0.0010\n",
            "Epoch 13/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3791 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 13: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4451 - accuracy: 0.8095 - f1_metric: 0.8097 - val_loss: 0.3746 - val_accuracy: 0.8232 - val_f1_metric: 0.8206 - lr: 0.0010\n",
            "Epoch 14/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.5126 - accuracy: 0.7812 - f1_metric: 0.7812\n",
            "Epoch 14: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4499 - accuracy: 0.8003 - f1_metric: 0.8054 - val_loss: 0.3660 - val_accuracy: 0.8476 - val_f1_metric: 0.8414 - lr: 0.0010\n",
            "Epoch 15/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3999 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 15: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4318 - accuracy: 0.8064 - f1_metric: 0.8153 - val_loss: 0.3611 - val_accuracy: 0.8476 - val_f1_metric: 0.8414 - lr: 0.0010\n",
            "Epoch 16/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4537 - accuracy: 0.7812 - f1_metric: 0.7812\n",
            "Epoch 16: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4356 - accuracy: 0.8155 - f1_metric: 0.8196 - val_loss: 0.3672 - val_accuracy: 0.8476 - val_f1_metric: 0.8414 - lr: 0.0010\n",
            "Epoch 17/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3610 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 17: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4206 - accuracy: 0.8110 - f1_metric: 0.8196 - val_loss: 0.3584 - val_accuracy: 0.8293 - val_f1_metric: 0.8218 - lr: 0.0010\n",
            "Epoch 18/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3922 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 18: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4296 - accuracy: 0.8110 - f1_metric: 0.8196 - val_loss: 0.3595 - val_accuracy: 0.8171 - val_f1_metric: 0.8073 - lr: 0.0010\n",
            "Epoch 19/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4005 - accuracy: 0.7812 - f1_metric: 0.7812\n",
            "Epoch 19: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8018 - f1_metric: 0.7940 - val_loss: 0.3641 - val_accuracy: 0.8354 - val_f1_metric: 0.8270 - lr: 0.0010\n",
            "Epoch 20/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.5016 - accuracy: 0.7656 - f1_metric: 0.7656\n",
            "Epoch 20: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4389 - accuracy: 0.7942 - f1_metric: 0.7827 - val_loss: 0.3591 - val_accuracy: 0.8293 - val_f1_metric: 0.8177 - lr: 0.0010\n",
            "Epoch 21/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3847 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 21: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4253 - accuracy: 0.8003 - f1_metric: 0.8054 - val_loss: 0.3549 - val_accuracy: 0.8537 - val_f1_metric: 0.8426 - lr: 0.0010\n",
            "Epoch 22/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3310 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 22: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4052 - accuracy: 0.8338 - f1_metric: 0.8196 - val_loss: 0.3427 - val_accuracy: 0.8537 - val_f1_metric: 0.8426 - lr: 0.0010\n",
            "Epoch 23/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3244 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 23: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4206 - accuracy: 0.8064 - f1_metric: 0.8068 - val_loss: 0.3546 - val_accuracy: 0.8293 - val_f1_metric: 0.8177 - lr: 0.0010\n",
            "Epoch 24/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4568 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 24: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8095 - f1_metric: 0.8011 - val_loss: 0.3486 - val_accuracy: 0.8354 - val_f1_metric: 0.8270 - lr: 0.0010\n",
            "Epoch 25/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4869 - accuracy: 0.7656 - f1_metric: 0.7656\n",
            "Epoch 25: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4229 - accuracy: 0.8049 - f1_metric: 0.8139 - val_loss: 0.3515 - val_accuracy: 0.8110 - val_f1_metric: 0.7980 - lr: 0.0010\n",
            "Epoch 26/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4597 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 26: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3956 - accuracy: 0.8155 - f1_metric: 0.8111 - val_loss: 0.3450 - val_accuracy: 0.8171 - val_f1_metric: 0.8032 - lr: 0.0010\n",
            "Epoch 27/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.5748 - accuracy: 0.7031 - f1_metric: 0.7031\n",
            "Epoch 27: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4030 - accuracy: 0.8079 - f1_metric: 0.8082 - val_loss: 0.3412 - val_accuracy: 0.7988 - val_f1_metric: 0.7836 - lr: 0.0010\n",
            "Epoch 28/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3581 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 28: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4021 - accuracy: 0.8186 - f1_metric: 0.8097 - val_loss: 0.3350 - val_accuracy: 0.8110 - val_f1_metric: 0.7940 - lr: 0.0010\n",
            "Epoch 29/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3294 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 29: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4160 - accuracy: 0.8155 - f1_metric: 0.8111 - val_loss: 0.3362 - val_accuracy: 0.8232 - val_f1_metric: 0.8044 - lr: 0.0010\n",
            "Epoch 30/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3669 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 30: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8247 - f1_metric: 0.8239 - val_loss: 0.3422 - val_accuracy: 0.8293 - val_f1_metric: 0.8096 - lr: 0.0010\n",
            "Epoch 31/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4359 - accuracy: 0.7812 - f1_metric: 0.7812\n",
            "Epoch 31: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4069 - accuracy: 0.8140 - f1_metric: 0.8097 - val_loss: 0.3411 - val_accuracy: 0.8293 - val_f1_metric: 0.8137 - lr: 0.0010\n",
            "Epoch 32/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.5370 - accuracy: 0.7344 - f1_metric: 0.7344\n",
            "Epoch 32: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4009 - accuracy: 0.8384 - f1_metric: 0.8281 - val_loss: 0.3469 - val_accuracy: 0.8110 - val_f1_metric: 0.7940 - lr: 0.0010\n",
            "Epoch 33/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4401 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 33: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4132 - accuracy: 0.8125 - f1_metric: 0.8210 - val_loss: 0.3479 - val_accuracy: 0.8049 - val_f1_metric: 0.7888 - lr: 0.0010\n",
            "Epoch 34/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4650 - accuracy: 0.7969 - f1_metric: 0.7969\n",
            "Epoch 34: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8171 - f1_metric: 0.8210 - val_loss: 0.3479 - val_accuracy: 0.8110 - val_f1_metric: 0.7940 - lr: 0.0010\n",
            "Epoch 35/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3437 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 35: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3888 - accuracy: 0.8186 - f1_metric: 0.8139 - val_loss: 0.3333 - val_accuracy: 0.8232 - val_f1_metric: 0.8044 - lr: 0.0010\n",
            "Epoch 36/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3656 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 36: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3741 - accuracy: 0.8354 - f1_metric: 0.8381 - val_loss: 0.3253 - val_accuracy: 0.8293 - val_f1_metric: 0.8137 - lr: 0.0010\n",
            "Epoch 37/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3494 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 37: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3894 - accuracy: 0.8338 - f1_metric: 0.8281 - val_loss: 0.3194 - val_accuracy: 0.8415 - val_f1_metric: 0.8241 - lr: 0.0010\n",
            "Epoch 38/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3441 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 38: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4066 - accuracy: 0.8232 - f1_metric: 0.8310 - val_loss: 0.3316 - val_accuracy: 0.8293 - val_f1_metric: 0.8137 - lr: 0.0010\n",
            "Epoch 39/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3541 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 39: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3719 - accuracy: 0.8232 - f1_metric: 0.8224 - val_loss: 0.3174 - val_accuracy: 0.8232 - val_f1_metric: 0.8084 - lr: 0.0010\n",
            "Epoch 40/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4356 - accuracy: 0.7656 - f1_metric: 0.7656\n",
            "Epoch 40: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3679 - accuracy: 0.8354 - f1_metric: 0.8338 - val_loss: 0.3104 - val_accuracy: 0.8476 - val_f1_metric: 0.8333 - lr: 0.0010\n",
            "Epoch 41/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4012 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 41: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3749 - accuracy: 0.8293 - f1_metric: 0.8324 - val_loss: 0.3174 - val_accuracy: 0.8293 - val_f1_metric: 0.8137 - lr: 0.0010\n",
            "Epoch 42/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2444 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 42: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3609 - accuracy: 0.8430 - f1_metric: 0.8494 - val_loss: 0.3113 - val_accuracy: 0.8293 - val_f1_metric: 0.8177 - lr: 0.0010\n",
            "Epoch 43/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3565 - accuracy: 0.7969 - f1_metric: 0.7969\n",
            "Epoch 43: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3773 - accuracy: 0.8323 - f1_metric: 0.8224 - val_loss: 0.3154 - val_accuracy: 0.8293 - val_f1_metric: 0.8137 - lr: 0.0010\n",
            "Epoch 44/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4597 - accuracy: 0.7969 - f1_metric: 0.7969\n",
            "Epoch 44: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3804 - accuracy: 0.8247 - f1_metric: 0.8153 - val_loss: 0.3240 - val_accuracy: 0.8415 - val_f1_metric: 0.8241 - lr: 0.0010\n",
            "Epoch 45/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3538 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 45: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3908 - accuracy: 0.8171 - f1_metric: 0.8210 - val_loss: 0.3162 - val_accuracy: 0.8476 - val_f1_metric: 0.8333 - lr: 0.0010\n",
            "Epoch 46/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3054 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 46: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3743 - accuracy: 0.8247 - f1_metric: 0.8281 - val_loss: 0.3284 - val_accuracy: 0.8293 - val_f1_metric: 0.8137 - lr: 0.0010\n",
            "Epoch 47/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3941 - accuracy: 0.7969 - f1_metric: 0.7969\n",
            "Epoch 47: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3839 - accuracy: 0.8277 - f1_metric: 0.8310 - val_loss: 0.3216 - val_accuracy: 0.8415 - val_f1_metric: 0.8241 - lr: 0.0010\n",
            "Epoch 48/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3038 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 48: val_f1_metric did not improve from 0.84549\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3626 - accuracy: 0.8399 - f1_metric: 0.8338 - val_loss: 0.3154 - val_accuracy: 0.8354 - val_f1_metric: 0.8189 - lr: 0.0010\n",
            "Epoch 49/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.5927 - accuracy: 0.6875 - f1_metric: 0.6875\n",
            "Epoch 49: val_f1_metric improved from 0.84549 to 0.85417, saving model to ./best_model_keras\n",
            "11/11 [==============================] - 2s 210ms/step - loss: 0.3633 - accuracy: 0.8384 - f1_metric: 0.8452 - val_loss: 0.3101 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 0.0010\n",
            "Epoch 50/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3097 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 50: val_f1_metric did not improve from 0.85417\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3557 - accuracy: 0.8445 - f1_metric: 0.8466 - val_loss: 0.3143 - val_accuracy: 0.8293 - val_f1_metric: 0.8137 - lr: 0.0010\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3550 - accuracy: 0.8415 - f1_metric: 0.8395\n",
            "Epoch 51: val_f1_metric did not improve from 0.85417\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3550 - accuracy: 0.8415 - f1_metric: 0.8395 - val_loss: 0.3065 - val_accuracy: 0.8415 - val_f1_metric: 0.8241 - lr: 0.0010\n",
            "Epoch 52/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4263 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 52: val_f1_metric did not improve from 0.85417\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3504 - accuracy: 0.8598 - f1_metric: 0.8651 - val_loss: 0.3021 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 0.0010\n",
            "Epoch 53/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3607 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 53: val_f1_metric did not improve from 0.85417\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3511 - accuracy: 0.8460 - f1_metric: 0.8437 - val_loss: 0.3013 - val_accuracy: 0.8659 - val_f1_metric: 0.8530 - lr: 0.0010\n",
            "Epoch 54/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4032 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 54: val_f1_metric did not improve from 0.85417\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3660 - accuracy: 0.8354 - f1_metric: 0.8381 - val_loss: 0.3058 - val_accuracy: 0.8598 - val_f1_metric: 0.8478 - lr: 0.0010\n",
            "Epoch 55/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2674 - accuracy: 0.9219 - f1_metric: 0.9219\n",
            "Epoch 55: val_f1_metric improved from 0.85417 to 0.86343, saving model to ./best_model_keras\n",
            "11/11 [==============================] - 1s 139ms/step - loss: 0.3626 - accuracy: 0.8415 - f1_metric: 0.8395 - val_loss: 0.3026 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 0.0010\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3442 - accuracy: 0.8399 - f1_metric: 0.8423\n",
            "Epoch 56: val_f1_metric did not improve from 0.86343\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.3442 - accuracy: 0.8399 - f1_metric: 0.8423 - val_loss: 0.3025 - val_accuracy: 0.8659 - val_f1_metric: 0.8530 - lr: 0.0010\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3572 - accuracy: 0.8430 - f1_metric: 0.8537\n",
            "Epoch 57: val_f1_metric improved from 0.86343 to 0.86748, saving model to ./best_model_keras\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 0.3572 - accuracy: 0.8430 - f1_metric: 0.8537 - val_loss: 0.2960 - val_accuracy: 0.8780 - val_f1_metric: 0.8675 - lr: 0.0010\n",
            "Epoch 58/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3632 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 58: val_f1_metric did not improve from 0.86748\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3430 - accuracy: 0.8552 - f1_metric: 0.8523 - val_loss: 0.2864 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 0.0010\n",
            "Epoch 59/300\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.3646 - accuracy: 0.8576 - f1_metric: 0.8576\n",
            "Epoch 59: val_f1_metric did not improve from 0.86748\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.3533 - accuracy: 0.8628 - f1_metric: 0.8679 - val_loss: 0.2878 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 0.0010\n",
            "Epoch 60/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.3419 - accuracy: 0.8469 - f1_metric: 0.8469\n",
            "Epoch 60: val_f1_metric did not improve from 0.86748\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.3423 - accuracy: 0.8460 - f1_metric: 0.8437 - val_loss: 0.2895 - val_accuracy: 0.8659 - val_f1_metric: 0.8530 - lr: 0.0010\n",
            "Epoch 61/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2369 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 61: val_f1_metric did not improve from 0.86748\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3535 - accuracy: 0.8293 - f1_metric: 0.8366 - val_loss: 0.2954 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 0.0010\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3473 - accuracy: 0.8338 - f1_metric: 0.8281\n",
            "Epoch 62: val_f1_metric did not improve from 0.86748\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.3473 - accuracy: 0.8338 - f1_metric: 0.8281 - val_loss: 0.2932 - val_accuracy: 0.8720 - val_f1_metric: 0.8623 - lr: 0.0010\n",
            "Epoch 63/300\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.3787 - accuracy: 0.8247 - f1_metric: 0.8247\n",
            "Epoch 63: val_f1_metric did not improve from 0.86748\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.3682 - accuracy: 0.8293 - f1_metric: 0.8324 - val_loss: 0.2935 - val_accuracy: 0.8659 - val_f1_metric: 0.8530 - lr: 0.0010\n",
            "Epoch 64/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.3675 - accuracy: 0.8266 - f1_metric: 0.8266\n",
            "Epoch 64: val_f1_metric improved from 0.86748 to 0.87269, saving model to ./best_model_keras\n",
            "11/11 [==============================] - 2s 181ms/step - loss: 0.3682 - accuracy: 0.8262 - f1_metric: 0.8253 - val_loss: 0.2942 - val_accuracy: 0.8841 - val_f1_metric: 0.8727 - lr: 0.0010\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3465 - accuracy: 0.8613 - f1_metric: 0.8580\n",
            "Epoch 65: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.3465 - accuracy: 0.8613 - f1_metric: 0.8580 - val_loss: 0.2930 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 0.0010\n",
            "Epoch 66/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.3445 - accuracy: 0.8359 - f1_metric: 0.8359\n",
            "Epoch 66: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.3486 - accuracy: 0.8308 - f1_metric: 0.8168 - val_loss: 0.2964 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 0.0010\n",
            "Epoch 67/300\n",
            " 8/11 [====================>.........] - ETA: 0s - loss: 0.3362 - accuracy: 0.8574 - f1_metric: 0.8574\n",
            "Epoch 67: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.3336 - accuracy: 0.8537 - f1_metric: 0.8466 - val_loss: 0.3017 - val_accuracy: 0.8720 - val_f1_metric: 0.8623 - lr: 0.0010\n",
            "Epoch 68/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3212 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 68: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3364 - accuracy: 0.8430 - f1_metric: 0.8409 - val_loss: 0.2973 - val_accuracy: 0.8720 - val_f1_metric: 0.8623 - lr: 0.0010\n",
            "Epoch 69/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2787 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 69: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3605 - accuracy: 0.8308 - f1_metric: 0.8381 - val_loss: 0.2954 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 0.0010\n",
            "Epoch 70/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3429 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 70: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3408 - accuracy: 0.8491 - f1_metric: 0.8509 - val_loss: 0.2897 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 0.0010\n",
            "Epoch 71/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2565 - accuracy: 0.9219 - f1_metric: 0.9219\n",
            "Epoch 71: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3329 - accuracy: 0.8643 - f1_metric: 0.8565 - val_loss: 0.2992 - val_accuracy: 0.8659 - val_f1_metric: 0.8530 - lr: 0.0010\n",
            "Epoch 72/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3406 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 72: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3351 - accuracy: 0.8384 - f1_metric: 0.8366 - val_loss: 0.3087 - val_accuracy: 0.8720 - val_f1_metric: 0.8623 - lr: 0.0010\n",
            "Epoch 73/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2982 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 73: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3518 - accuracy: 0.8323 - f1_metric: 0.8395 - val_loss: 0.2906 - val_accuracy: 0.8720 - val_f1_metric: 0.8623 - lr: 0.0010\n",
            "Epoch 74/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3727 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 74: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3520 - accuracy: 0.8476 - f1_metric: 0.8537 - val_loss: 0.2864 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 0.0010\n",
            "Epoch 75/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2532 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 75: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3319 - accuracy: 0.8430 - f1_metric: 0.8409 - val_loss: 0.2882 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 0.0010\n",
            "Epoch 76/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4107 - accuracy: 0.7656 - f1_metric: 0.7656\n",
            "Epoch 76: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3323 - accuracy: 0.8537 - f1_metric: 0.8551 - val_loss: 0.2898 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 0.0010\n",
            "Epoch 77/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2950 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 77: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3365 - accuracy: 0.8521 - f1_metric: 0.8537 - val_loss: 0.3036 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 0.0010\n",
            "Epoch 78/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2839 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 78: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3295 - accuracy: 0.8476 - f1_metric: 0.8494 - val_loss: 0.2841 - val_accuracy: 0.8780 - val_f1_metric: 0.8675 - lr: 0.0010\n",
            "Epoch 79/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2877 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 79: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3222 - accuracy: 0.8582 - f1_metric: 0.8551 - val_loss: 0.2824 - val_accuracy: 0.8659 - val_f1_metric: 0.8530 - lr: 0.0010\n",
            "Epoch 80/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3751 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 80: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3476 - accuracy: 0.8293 - f1_metric: 0.8239 - val_loss: 0.2861 - val_accuracy: 0.8780 - val_f1_metric: 0.8675 - lr: 0.0010\n",
            "Epoch 81/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3198 - accuracy: 0.9219 - f1_metric: 0.9219\n",
            "Epoch 81: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3276 - accuracy: 0.8613 - f1_metric: 0.8665 - val_loss: 0.2947 - val_accuracy: 0.8659 - val_f1_metric: 0.8530 - lr: 0.0010\n",
            "Epoch 82/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2683 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 82: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3297 - accuracy: 0.8674 - f1_metric: 0.8722 - val_loss: 0.2942 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 0.0010\n",
            "Epoch 83/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3356 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 83: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3159 - accuracy: 0.8613 - f1_metric: 0.8580 - val_loss: 0.2851 - val_accuracy: 0.8659 - val_f1_metric: 0.8530 - lr: 0.0010\n",
            "Epoch 84/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3297 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 84: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3317 - accuracy: 0.8613 - f1_metric: 0.8622 - val_loss: 0.2959 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 0.0010\n",
            "Epoch 85/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3410 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 85: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3202 - accuracy: 0.8613 - f1_metric: 0.8537 - val_loss: 0.2911 - val_accuracy: 0.8598 - val_f1_metric: 0.8478 - lr: 0.0010\n",
            "Epoch 86/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2573 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 86: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3233 - accuracy: 0.8537 - f1_metric: 0.8466 - val_loss: 0.2888 - val_accuracy: 0.8720 - val_f1_metric: 0.8623 - lr: 0.0010\n",
            "Epoch 87/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4366 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 87: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3376 - accuracy: 0.8445 - f1_metric: 0.8466 - val_loss: 0.2940 - val_accuracy: 0.8659 - val_f1_metric: 0.8530 - lr: 0.0010\n",
            "Epoch 88/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.1727 - accuracy: 0.9688 - f1_metric: 0.9687\n",
            "Epoch 88: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3226 - accuracy: 0.8598 - f1_metric: 0.8565 - val_loss: 0.2945 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 0.0010\n",
            "Epoch 89/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2141 - accuracy: 0.9219 - f1_metric: 0.9219\n",
            "Epoch 89: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3205 - accuracy: 0.8613 - f1_metric: 0.8494 - val_loss: 0.2996 - val_accuracy: 0.8537 - val_f1_metric: 0.8385 - lr: 0.0010\n",
            "Epoch 90/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2620 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 90: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3113 - accuracy: 0.8582 - f1_metric: 0.8636 - val_loss: 0.2943 - val_accuracy: 0.8659 - val_f1_metric: 0.8530 - lr: 0.0010\n",
            "Epoch 91/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3042 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 91: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3244 - accuracy: 0.8582 - f1_metric: 0.8594 - val_loss: 0.2917 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 0.0010\n",
            "Epoch 92/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3892 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 92: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3247 - accuracy: 0.8506 - f1_metric: 0.8480 - val_loss: 0.3019 - val_accuracy: 0.8598 - val_f1_metric: 0.8478 - lr: 0.0010\n",
            "Epoch 93/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.1667 - accuracy: 0.9531 - f1_metric: 0.9531\n",
            "Epoch 93: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3295 - accuracy: 0.8582 - f1_metric: 0.8551 - val_loss: 0.2996 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 0.0010\n",
            "Epoch 94/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4048 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 94: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3259 - accuracy: 0.8521 - f1_metric: 0.8622 - val_loss: 0.2834 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 0.0010\n",
            "Epoch 95/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3256 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 95: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2995 - accuracy: 0.8735 - f1_metric: 0.8778 - val_loss: 0.2895 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 0.0010\n",
            "Epoch 96/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2702 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 96: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3050 - accuracy: 0.8582 - f1_metric: 0.8679 - val_loss: 0.2816 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 0.0010\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3099 - accuracy: 0.8674 - f1_metric: 0.8636\n",
            "Epoch 97: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3099 - accuracy: 0.8674 - f1_metric: 0.8636 - val_loss: 0.2961 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 0.0010\n",
            "Epoch 98/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3290 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 98: val_f1_metric did not improve from 0.87269\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3164 - accuracy: 0.8521 - f1_metric: 0.8494 - val_loss: 0.2836 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 0.0010\n",
            "Epoch 99/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3170 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 99: val_f1_metric improved from 0.87269 to 0.87789, saving model to ./best_model_keras\n",
            "\n",
            "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "11/11 [==============================] - 1s 114ms/step - loss: 0.3137 - accuracy: 0.8628 - f1_metric: 0.8679 - val_loss: 0.2844 - val_accuracy: 0.8902 - val_f1_metric: 0.8779 - lr: 0.0010\n",
            "Epoch 100/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2012 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 100: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3260 - accuracy: 0.8537 - f1_metric: 0.8551 - val_loss: 0.2843 - val_accuracy: 0.8902 - val_f1_metric: 0.8779 - lr: 1.0000e-04\n",
            "Epoch 101/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3265 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 101: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3113 - accuracy: 0.8628 - f1_metric: 0.8594 - val_loss: 0.2839 - val_accuracy: 0.8902 - val_f1_metric: 0.8779 - lr: 1.0000e-04\n",
            "Epoch 102/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2141 - accuracy: 0.9531 - f1_metric: 0.9531\n",
            "Epoch 102: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3086 - accuracy: 0.8598 - f1_metric: 0.8651 - val_loss: 0.2843 - val_accuracy: 0.8902 - val_f1_metric: 0.8779 - lr: 1.0000e-04\n",
            "Epoch 103/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3143 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 103: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3099 - accuracy: 0.8628 - f1_metric: 0.8636 - val_loss: 0.2846 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 104/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3965 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 104: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3077 - accuracy: 0.8643 - f1_metric: 0.8608 - val_loss: 0.2853 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 105/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2597 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 105: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3207 - accuracy: 0.8506 - f1_metric: 0.8437 - val_loss: 0.2828 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 106/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2805 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 106: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3063 - accuracy: 0.8582 - f1_metric: 0.8594 - val_loss: 0.2823 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 107/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3636 - accuracy: 0.7812 - f1_metric: 0.7812\n",
            "Epoch 107: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2990 - accuracy: 0.8598 - f1_metric: 0.8608 - val_loss: 0.2830 - val_accuracy: 0.8902 - val_f1_metric: 0.8738 - lr: 1.0000e-04\n",
            "Epoch 108/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4550 - accuracy: 0.7969 - f1_metric: 0.7969\n",
            "Epoch 108: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2982 - accuracy: 0.8780 - f1_metric: 0.8864 - val_loss: 0.2834 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 109/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2686 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 109: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2932 - accuracy: 0.8735 - f1_metric: 0.8693 - val_loss: 0.2825 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 110/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3039 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 110: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3066 - accuracy: 0.8628 - f1_metric: 0.8679 - val_loss: 0.2830 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 111/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2803 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 111: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3046 - accuracy: 0.8628 - f1_metric: 0.8636 - val_loss: 0.2820 - val_accuracy: 0.8902 - val_f1_metric: 0.8738 - lr: 1.0000e-04\n",
            "Epoch 112/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2394 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 112: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2901 - accuracy: 0.8659 - f1_metric: 0.8580 - val_loss: 0.2823 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 113/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2016 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 113: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3063 - accuracy: 0.8689 - f1_metric: 0.8736 - val_loss: 0.2847 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 114/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3099 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 114: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3108 - accuracy: 0.8582 - f1_metric: 0.8509 - val_loss: 0.2844 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 115/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.1614 - accuracy: 0.9844 - f1_metric: 0.9844\n",
            "Epoch 115: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3040 - accuracy: 0.8689 - f1_metric: 0.8651 - val_loss: 0.2829 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 116/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2752 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 116: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2988 - accuracy: 0.8720 - f1_metric: 0.8764 - val_loss: 0.2831 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 117/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2438 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 117: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2992 - accuracy: 0.8582 - f1_metric: 0.8594 - val_loss: 0.2836 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 118/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2711 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 118: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3075 - accuracy: 0.8720 - f1_metric: 0.8722 - val_loss: 0.2815 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 119/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4402 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 119: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3069 - accuracy: 0.8704 - f1_metric: 0.8793 - val_loss: 0.2817 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 120/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4463 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 120: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3069 - accuracy: 0.8582 - f1_metric: 0.8636 - val_loss: 0.2824 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 121/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3300 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 121: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3021 - accuracy: 0.8780 - f1_metric: 0.8736 - val_loss: 0.2846 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 122/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2972 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 122: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3130 - accuracy: 0.8552 - f1_metric: 0.8608 - val_loss: 0.2864 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 1.0000e-04\n",
            "Epoch 123/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3941 - accuracy: 0.7500 - f1_metric: 0.7500\n",
            "Epoch 123: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2964 - accuracy: 0.8735 - f1_metric: 0.8693 - val_loss: 0.2864 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 1.0000e-04\n",
            "Epoch 124/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2131 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 124: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2867 - accuracy: 0.8765 - f1_metric: 0.8722 - val_loss: 0.2862 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 125/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3264 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 125: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3048 - accuracy: 0.8643 - f1_metric: 0.8651 - val_loss: 0.2860 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 126/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2517 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 126: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2928 - accuracy: 0.8659 - f1_metric: 0.8707 - val_loss: 0.2870 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 1.0000e-04\n",
            "Epoch 127/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2801 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 127: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3069 - accuracy: 0.8674 - f1_metric: 0.8722 - val_loss: 0.2860 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 1.0000e-04\n",
            "Epoch 128/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.3064 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 128: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3100 - accuracy: 0.8567 - f1_metric: 0.8494 - val_loss: 0.2854 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 1.0000e-04\n",
            "Epoch 129/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3339 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 129: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3035 - accuracy: 0.8506 - f1_metric: 0.8480 - val_loss: 0.2847 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 130/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2292 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 130: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3017 - accuracy: 0.8750 - f1_metric: 0.8750 - val_loss: 0.2844 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 131/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3581 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 131: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3034 - accuracy: 0.8674 - f1_metric: 0.8636 - val_loss: 0.2840 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 132/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2852 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 132: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3045 - accuracy: 0.8720 - f1_metric: 0.8807 - val_loss: 0.2852 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 133/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2948 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 133: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3186 - accuracy: 0.8689 - f1_metric: 0.8693 - val_loss: 0.2856 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 134/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3877 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 134: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3025 - accuracy: 0.8643 - f1_metric: 0.8651 - val_loss: 0.2866 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 135/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2812 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 135: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2949 - accuracy: 0.8659 - f1_metric: 0.8665 - val_loss: 0.2873 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 136/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2628 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 136: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3162 - accuracy: 0.8628 - f1_metric: 0.8636 - val_loss: 0.2860 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 137/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2566 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 137: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2866 - accuracy: 0.8750 - f1_metric: 0.8707 - val_loss: 0.2855 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 138/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3082 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 138: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2984 - accuracy: 0.8750 - f1_metric: 0.8793 - val_loss: 0.2872 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 139/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3534 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 139: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2975 - accuracy: 0.8704 - f1_metric: 0.8750 - val_loss: 0.2866 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 140/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3173 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 140: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2911 - accuracy: 0.8796 - f1_metric: 0.8835 - val_loss: 0.2858 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 141/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3399 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 141: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3048 - accuracy: 0.8750 - f1_metric: 0.8707 - val_loss: 0.2875 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 1.0000e-04\n",
            "Epoch 142/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3972 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 142: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8674 - f1_metric: 0.8764 - val_loss: 0.2864 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 1.0000e-04\n",
            "Epoch 143/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2238 - accuracy: 0.9219 - f1_metric: 0.9219\n",
            "Epoch 143: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2968 - accuracy: 0.8704 - f1_metric: 0.8622 - val_loss: 0.2852 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 144/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2994 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 144: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2890 - accuracy: 0.8857 - f1_metric: 0.8849 - val_loss: 0.2855 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 145/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3527 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 145: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3035 - accuracy: 0.8689 - f1_metric: 0.8693 - val_loss: 0.2844 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 146/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2688 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 146: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3219 - accuracy: 0.8476 - f1_metric: 0.8409 - val_loss: 0.2851 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 147/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2312 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 147: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3012 - accuracy: 0.8628 - f1_metric: 0.8636 - val_loss: 0.2875 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 148/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3110 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 148: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2982 - accuracy: 0.8720 - f1_metric: 0.8636 - val_loss: 0.2886 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 1.0000e-04\n",
            "Epoch 149/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4062 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 149: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3125 - accuracy: 0.8582 - f1_metric: 0.8551 - val_loss: 0.2876 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 150/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2557 - accuracy: 0.9219 - f1_metric: 0.9219\n",
            "Epoch 150: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2963 - accuracy: 0.8674 - f1_metric: 0.8636 - val_loss: 0.2862 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 151/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3868 - accuracy: 0.7969 - f1_metric: 0.7969\n",
            "Epoch 151: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2981 - accuracy: 0.8674 - f1_metric: 0.8636 - val_loss: 0.2856 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 152/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2391 - accuracy: 0.9219 - f1_metric: 0.9219\n",
            "Epoch 152: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2965 - accuracy: 0.8735 - f1_metric: 0.8736 - val_loss: 0.2836 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 153/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3292 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 153: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3097 - accuracy: 0.8582 - f1_metric: 0.8636 - val_loss: 0.2833 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 154/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2335 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 154: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2909 - accuracy: 0.8613 - f1_metric: 0.8580 - val_loss: 0.2837 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 155/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2456 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 155: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2886 - accuracy: 0.8720 - f1_metric: 0.8722 - val_loss: 0.2839 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 156/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2041 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 156: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3047 - accuracy: 0.8628 - f1_metric: 0.8636 - val_loss: 0.2831 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3050 - accuracy: 0.8659 - f1_metric: 0.8622\n",
            "Epoch 157: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.3050 - accuracy: 0.8659 - f1_metric: 0.8622 - val_loss: 0.2840 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 158/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3166 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 158: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3030 - accuracy: 0.8750 - f1_metric: 0.8793 - val_loss: 0.2839 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 159/300\n",
            " 8/11 [====================>.........] - ETA: 0s - loss: 0.3244 - accuracy: 0.8652 - f1_metric: 0.8652\n",
            "Epoch 159: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.3108 - accuracy: 0.8659 - f1_metric: 0.8707 - val_loss: 0.2848 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 160/300\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.3234 - accuracy: 0.8611 - f1_metric: 0.8611\n",
            "Epoch 160: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.3164 - accuracy: 0.8643 - f1_metric: 0.8651 - val_loss: 0.2847 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 161/300\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.2966 - accuracy: 0.8628 - f1_metric: 0.8628\n",
            "Epoch 161: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2960 - accuracy: 0.8643 - f1_metric: 0.8608 - val_loss: 0.2836 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2969 - accuracy: 0.8796 - f1_metric: 0.8793\n",
            "Epoch 162: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.2969 - accuracy: 0.8796 - f1_metric: 0.8793 - val_loss: 0.2833 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2938 - accuracy: 0.8598 - f1_metric: 0.8651\n",
            "Epoch 163: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.2938 - accuracy: 0.8598 - f1_metric: 0.8651 - val_loss: 0.2848 - val_accuracy: 0.8537 - val_f1_metric: 0.8385 - lr: 1.0000e-04\n",
            "Epoch 164/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2967 - accuracy: 0.8641 - f1_metric: 0.8641\n",
            "Epoch 164: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.2975 - accuracy: 0.8628 - f1_metric: 0.8594 - val_loss: 0.2874 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 1.0000e-04\n",
            "Epoch 165/300\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.3044 - accuracy: 0.8542 - f1_metric: 0.8542\n",
            "Epoch 165: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.3067 - accuracy: 0.8537 - f1_metric: 0.8551 - val_loss: 0.2853 - val_accuracy: 0.8537 - val_f1_metric: 0.8385 - lr: 1.0000e-04\n",
            "Epoch 166/300\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.2805 - accuracy: 0.8802 - f1_metric: 0.8802\n",
            "Epoch 166: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2868 - accuracy: 0.8750 - f1_metric: 0.8707 - val_loss: 0.2841 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 167/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2011 - accuracy: 0.9219 - f1_metric: 0.9219\n",
            "Epoch 167: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3114 - accuracy: 0.8689 - f1_metric: 0.8693 - val_loss: 0.2848 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 1.0000e-04\n",
            "Epoch 168/300\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.3022 - accuracy: 0.8785 - f1_metric: 0.8785\n",
            "Epoch 168: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.3072 - accuracy: 0.8720 - f1_metric: 0.8807 - val_loss: 0.2853 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3081 - accuracy: 0.8613 - f1_metric: 0.8580\n",
            "Epoch 169: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.3081 - accuracy: 0.8613 - f1_metric: 0.8580 - val_loss: 0.2856 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 170/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.3047 - accuracy: 0.8687 - f1_metric: 0.8687\n",
            "Epoch 170: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.3033 - accuracy: 0.8704 - f1_metric: 0.8750 - val_loss: 0.2841 - val_accuracy: 0.8537 - val_f1_metric: 0.8385 - lr: 1.0000e-04\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2908 - accuracy: 0.8582 - f1_metric: 0.8636\n",
            "Epoch 171: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.2908 - accuracy: 0.8582 - f1_metric: 0.8636 - val_loss: 0.2824 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.8552 - f1_metric: 0.8523\n",
            "Epoch 172: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.3117 - accuracy: 0.8552 - f1_metric: 0.8523 - val_loss: 0.2836 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 173/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2008 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 173: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2896 - accuracy: 0.8567 - f1_metric: 0.8580 - val_loss: 0.2831 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 174/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.3046 - accuracy: 0.8531 - f1_metric: 0.8531\n",
            "Epoch 174: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.3092 - accuracy: 0.8521 - f1_metric: 0.8494 - val_loss: 0.2847 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 1.0000e-04\n",
            "Epoch 175/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3174 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 175: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2839 - accuracy: 0.8765 - f1_metric: 0.8679 - val_loss: 0.2839 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 176/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2789 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 176: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.2986 - accuracy: 0.8613 - f1_metric: 0.8622 - val_loss: 0.2819 - val_accuracy: 0.8902 - val_f1_metric: 0.8738 - lr: 1.0000e-04\n",
            "Epoch 177/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3095 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 177: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.3175 - accuracy: 0.8598 - f1_metric: 0.8565 - val_loss: 0.2820 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 178/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2364 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 178: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3022 - accuracy: 0.8552 - f1_metric: 0.8608 - val_loss: 0.2824 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2998 - accuracy: 0.8720 - f1_metric: 0.8679\n",
            "Epoch 179: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2998 - accuracy: 0.8720 - f1_metric: 0.8679 - val_loss: 0.2828 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 1.0000e-04\n",
            "Epoch 180/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2847 - accuracy: 0.8625 - f1_metric: 0.8625\n",
            "Epoch 180: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.2844 - accuracy: 0.8613 - f1_metric: 0.8580 - val_loss: 0.2792 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 181/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3592 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 181: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2949 - accuracy: 0.8765 - f1_metric: 0.8764 - val_loss: 0.2788 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 182/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2586 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 182: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.2991 - accuracy: 0.8659 - f1_metric: 0.8580 - val_loss: 0.2805 - val_accuracy: 0.8537 - val_f1_metric: 0.8385 - lr: 1.0000e-04\n",
            "Epoch 183/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2933 - accuracy: 0.8641 - f1_metric: 0.8641\n",
            "Epoch 183: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2902 - accuracy: 0.8674 - f1_metric: 0.8764 - val_loss: 0.2807 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3006 - accuracy: 0.8674 - f1_metric: 0.8636\n",
            "Epoch 184: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.3006 - accuracy: 0.8674 - f1_metric: 0.8636 - val_loss: 0.2797 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2956 - accuracy: 0.8796 - f1_metric: 0.8835\n",
            "Epoch 185: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2956 - accuracy: 0.8796 - f1_metric: 0.8835 - val_loss: 0.2782 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 186/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.3131 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 186: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.3090 - accuracy: 0.8613 - f1_metric: 0.8665 - val_loss: 0.2779 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3054 - accuracy: 0.8659 - f1_metric: 0.8750\n",
            "Epoch 187: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.3054 - accuracy: 0.8659 - f1_metric: 0.8750 - val_loss: 0.2789 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 188/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.3051 - accuracy: 0.8719 - f1_metric: 0.8719\n",
            "Epoch 188: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.3045 - accuracy: 0.8720 - f1_metric: 0.8722 - val_loss: 0.2802 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 189/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2691 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 189: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2887 - accuracy: 0.8704 - f1_metric: 0.8707 - val_loss: 0.2803 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 190/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4373 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 190: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.3005 - accuracy: 0.8689 - f1_metric: 0.8736 - val_loss: 0.2814 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 191/300\n",
            " 8/11 [====================>.........] - ETA: 0s - loss: 0.2901 - accuracy: 0.8691 - f1_metric: 0.8691\n",
            "Epoch 191: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2978 - accuracy: 0.8613 - f1_metric: 0.8537 - val_loss: 0.2819 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3054 - accuracy: 0.8567 - f1_metric: 0.8537\n",
            "Epoch 192: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.3054 - accuracy: 0.8567 - f1_metric: 0.8537 - val_loss: 0.2810 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 193/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3013 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 193: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.3021 - accuracy: 0.8704 - f1_metric: 0.8707 - val_loss: 0.2837 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3091 - accuracy: 0.8628 - f1_metric: 0.8679\n",
            "Epoch 194: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.3091 - accuracy: 0.8628 - f1_metric: 0.8679 - val_loss: 0.2858 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 1.0000e-04\n",
            "Epoch 195/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2242 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 195: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2940 - accuracy: 0.8552 - f1_metric: 0.8523 - val_loss: 0.2873 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 1.0000e-04\n",
            "Epoch 196/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3118 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 196: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3070 - accuracy: 0.8582 - f1_metric: 0.8594 - val_loss: 0.2852 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 1.0000e-04\n",
            "Epoch 197/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.3054 - accuracy: 0.8687 - f1_metric: 0.8687\n",
            "Epoch 197: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.3053 - accuracy: 0.8674 - f1_metric: 0.8636 - val_loss: 0.2833 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3019 - accuracy: 0.8735 - f1_metric: 0.8736\n",
            "Epoch 198: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.3019 - accuracy: 0.8735 - f1_metric: 0.8736 - val_loss: 0.2831 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 199/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4117 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 199: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.3040 - accuracy: 0.8643 - f1_metric: 0.8608 - val_loss: 0.2823 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 200/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2924 - accuracy: 0.8656 - f1_metric: 0.8656\n",
            "Epoch 200: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2975 - accuracy: 0.8628 - f1_metric: 0.8551 - val_loss: 0.2822 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 201/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2651 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 201: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2919 - accuracy: 0.8643 - f1_metric: 0.8651 - val_loss: 0.2817 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 202/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2403 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 202: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3025 - accuracy: 0.8506 - f1_metric: 0.8352 - val_loss: 0.2802 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 203/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3611 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 203: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2783 - accuracy: 0.8857 - f1_metric: 0.8849 - val_loss: 0.2812 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 204/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3081 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 204: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2918 - accuracy: 0.8689 - f1_metric: 0.8651 - val_loss: 0.2809 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 205/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3829 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 205: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3152 - accuracy: 0.8537 - f1_metric: 0.8594 - val_loss: 0.2824 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 206/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3324 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 206: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2990 - accuracy: 0.8643 - f1_metric: 0.8651 - val_loss: 0.2827 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 207/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3214 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 207: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2854 - accuracy: 0.8704 - f1_metric: 0.8750 - val_loss: 0.2822 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 208/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3293 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 208: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2877 - accuracy: 0.8720 - f1_metric: 0.8764 - val_loss: 0.2811 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 209/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3233 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 209: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8704 - f1_metric: 0.8665 - val_loss: 0.2823 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 210/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2899 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 210: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2978 - accuracy: 0.8689 - f1_metric: 0.8565 - val_loss: 0.2834 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 211/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3055 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 211: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2960 - accuracy: 0.8689 - f1_metric: 0.8736 - val_loss: 0.2837 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2954 - accuracy: 0.8750 - f1_metric: 0.8622\n",
            "Epoch 212: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2954 - accuracy: 0.8750 - f1_metric: 0.8622 - val_loss: 0.2838 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 213/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3383 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 213: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2911 - accuracy: 0.8811 - f1_metric: 0.8849 - val_loss: 0.2826 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 214/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4102 - accuracy: 0.7969 - f1_metric: 0.7969\n",
            "Epoch 214: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2835 - accuracy: 0.8628 - f1_metric: 0.8679 - val_loss: 0.2808 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 215/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3519 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 215: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2771 - accuracy: 0.8841 - f1_metric: 0.8835 - val_loss: 0.2813 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3136 - accuracy: 0.8506 - f1_metric: 0.8608\n",
            "Epoch 216: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3136 - accuracy: 0.8506 - f1_metric: 0.8608 - val_loss: 0.2826 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 217/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4796 - accuracy: 0.7656 - f1_metric: 0.7656\n",
            "Epoch 217: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2962 - accuracy: 0.8720 - f1_metric: 0.8679 - val_loss: 0.2820 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 218/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2607 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 218: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3114 - accuracy: 0.8674 - f1_metric: 0.8679 - val_loss: 0.2833 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 219/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2849 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 219: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2908 - accuracy: 0.8674 - f1_metric: 0.8594 - val_loss: 0.2827 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 220/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2835 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 220: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3085 - accuracy: 0.8582 - f1_metric: 0.8636 - val_loss: 0.2828 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 221/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2973 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 221: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3008 - accuracy: 0.8720 - f1_metric: 0.8679 - val_loss: 0.2845 - val_accuracy: 0.8720 - val_f1_metric: 0.8582 - lr: 1.0000e-04\n",
            "Epoch 222/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2516 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 222: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3011 - accuracy: 0.8780 - f1_metric: 0.8778 - val_loss: 0.2845 - val_accuracy: 0.8780 - val_f1_metric: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 223/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4311 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 223: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2983 - accuracy: 0.8735 - f1_metric: 0.8736 - val_loss: 0.2846 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 224/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2356 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 224: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3021 - accuracy: 0.8704 - f1_metric: 0.8707 - val_loss: 0.2833 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 225/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2877 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 225: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3038 - accuracy: 0.8613 - f1_metric: 0.8622 - val_loss: 0.2829 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 226/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2428 - accuracy: 0.9531 - f1_metric: 0.9531\n",
            "Epoch 226: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2977 - accuracy: 0.8750 - f1_metric: 0.8750 - val_loss: 0.2828 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 227/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3041 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 227: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2852 - accuracy: 0.8689 - f1_metric: 0.8693 - val_loss: 0.2822 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 228/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3445 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 228: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3088 - accuracy: 0.8506 - f1_metric: 0.8480 - val_loss: 0.2812 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 229/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3886 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 229: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2969 - accuracy: 0.8659 - f1_metric: 0.8707 - val_loss: 0.2803 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 230/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2804 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 230: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2944 - accuracy: 0.8735 - f1_metric: 0.8608 - val_loss: 0.2815 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 231/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3473 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 231: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2980 - accuracy: 0.8689 - f1_metric: 0.8736 - val_loss: 0.2813 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 232/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3731 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 232: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2955 - accuracy: 0.8796 - f1_metric: 0.8878 - val_loss: 0.2804 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 233/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2531 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 233: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2976 - accuracy: 0.8659 - f1_metric: 0.8622 - val_loss: 0.2797 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 234/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2692 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 234: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2883 - accuracy: 0.8720 - f1_metric: 0.8764 - val_loss: 0.2793 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 235/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2988 - accuracy: 0.8781 - f1_metric: 0.8781\n",
            "Epoch 235: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3009 - accuracy: 0.8765 - f1_metric: 0.8722 - val_loss: 0.2785 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 236/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3158 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 236: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2920 - accuracy: 0.8689 - f1_metric: 0.8736 - val_loss: 0.2778 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 237/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3863 - accuracy: 0.8125 - f1_metric: 0.8125\n",
            "Epoch 237: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2935 - accuracy: 0.8796 - f1_metric: 0.8835 - val_loss: 0.2782 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 238/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3573 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 238: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2930 - accuracy: 0.8659 - f1_metric: 0.8622 - val_loss: 0.2772 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 239/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3922 - accuracy: 0.7969 - f1_metric: 0.7969\n",
            "Epoch 239: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3051 - accuracy: 0.8552 - f1_metric: 0.8565 - val_loss: 0.2788 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 240/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.5428 - accuracy: 0.7344 - f1_metric: 0.7344\n",
            "Epoch 240: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3145 - accuracy: 0.8506 - f1_metric: 0.8523 - val_loss: 0.2788 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 241/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2271 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 241: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2971 - accuracy: 0.8643 - f1_metric: 0.8651 - val_loss: 0.2782 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 242/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2934 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 242: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2962 - accuracy: 0.8552 - f1_metric: 0.8608 - val_loss: 0.2800 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3097 - accuracy: 0.8567 - f1_metric: 0.8580\n",
            "Epoch 243: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3097 - accuracy: 0.8567 - f1_metric: 0.8580 - val_loss: 0.2806 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 244/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2479 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 244: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2830 - accuracy: 0.8811 - f1_metric: 0.8807 - val_loss: 0.2809 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 245/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2906 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 245: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.2879 - accuracy: 0.8613 - f1_metric: 0.8665 - val_loss: 0.2796 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 246/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2704 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 246: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2883 - accuracy: 0.8643 - f1_metric: 0.8693 - val_loss: 0.2779 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 247/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3112 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 247: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2903 - accuracy: 0.8643 - f1_metric: 0.8608 - val_loss: 0.2767 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 248/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2119 - accuracy: 0.9219 - f1_metric: 0.9219\n",
            "Epoch 248: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3053 - accuracy: 0.8460 - f1_metric: 0.8310 - val_loss: 0.2756 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 249/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3997 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 249: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2995 - accuracy: 0.8765 - f1_metric: 0.8679 - val_loss: 0.2771 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 250/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.1965 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 250: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2912 - accuracy: 0.8704 - f1_metric: 0.8750 - val_loss: 0.2773 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 251/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2377 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 251: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2887 - accuracy: 0.8704 - f1_metric: 0.8750 - val_loss: 0.2785 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 252/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2221 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 252: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2790 - accuracy: 0.8659 - f1_metric: 0.8665 - val_loss: 0.2787 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 253/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2620 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 253: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2843 - accuracy: 0.8720 - f1_metric: 0.8679 - val_loss: 0.2813 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 254/300\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.2895 - accuracy: 0.8698 - f1_metric: 0.8698\n",
            "Epoch 254: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2949 - accuracy: 0.8674 - f1_metric: 0.8594 - val_loss: 0.2824 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 255/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2640 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 255: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2962 - accuracy: 0.8765 - f1_metric: 0.8764 - val_loss: 0.2831 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 256/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2850 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 256: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3067 - accuracy: 0.8613 - f1_metric: 0.8707 - val_loss: 0.2809 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 257/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4118 - accuracy: 0.7969 - f1_metric: 0.7969\n",
            "Epoch 257: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3102 - accuracy: 0.8735 - f1_metric: 0.8651 - val_loss: 0.2801 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 258/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2961 - accuracy: 0.8734 - f1_metric: 0.8734\n",
            "Epoch 258: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.2937 - accuracy: 0.8750 - f1_metric: 0.8793 - val_loss: 0.2788 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2821 - accuracy: 0.8765 - f1_metric: 0.8764\n",
            "Epoch 259: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2821 - accuracy: 0.8765 - f1_metric: 0.8764 - val_loss: 0.2783 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 260/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3438 - accuracy: 0.7969 - f1_metric: 0.7969\n",
            "Epoch 260: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2781 - accuracy: 0.8689 - f1_metric: 0.8693 - val_loss: 0.2781 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 261/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3070 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 261: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2899 - accuracy: 0.8735 - f1_metric: 0.8736 - val_loss: 0.2777 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 262/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3708 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 262: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3075 - accuracy: 0.8659 - f1_metric: 0.8622 - val_loss: 0.2765 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 263/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2667 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 263: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2980 - accuracy: 0.8689 - f1_metric: 0.8651 - val_loss: 0.2775 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 264/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2567 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 264: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2944 - accuracy: 0.8643 - f1_metric: 0.8693 - val_loss: 0.2776 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 265/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3448 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 265: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2985 - accuracy: 0.8582 - f1_metric: 0.8636 - val_loss: 0.2789 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 266/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2816 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 266: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2922 - accuracy: 0.8582 - f1_metric: 0.8551 - val_loss: 0.2782 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 267/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3064 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 267: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2836 - accuracy: 0.8704 - f1_metric: 0.8793 - val_loss: 0.2786 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 268/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.4815 - accuracy: 0.7500 - f1_metric: 0.7500\n",
            "Epoch 268: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2852 - accuracy: 0.8796 - f1_metric: 0.8750 - val_loss: 0.2792 - val_accuracy: 0.8841 - val_f1_metric: 0.8686 - lr: 1.0000e-04\n",
            "Epoch 269/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.3108 - accuracy: 0.8656 - f1_metric: 0.8656\n",
            "Epoch 269: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3127 - accuracy: 0.8659 - f1_metric: 0.8665 - val_loss: 0.2788 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 270/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2398 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 270: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3038 - accuracy: 0.8582 - f1_metric: 0.8551 - val_loss: 0.2787 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2888 - accuracy: 0.8750 - f1_metric: 0.8835\n",
            "Epoch 271: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2888 - accuracy: 0.8750 - f1_metric: 0.8835 - val_loss: 0.2770 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 272/300\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.2864 - accuracy: 0.8663 - f1_metric: 0.8663\n",
            "Epoch 272: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2875 - accuracy: 0.8689 - f1_metric: 0.8736 - val_loss: 0.2771 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 273/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2356 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 273: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3018 - accuracy: 0.8613 - f1_metric: 0.8622 - val_loss: 0.2787 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 274/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2189 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 274: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2955 - accuracy: 0.8689 - f1_metric: 0.8693 - val_loss: 0.2799 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 275/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2866 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 275: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3012 - accuracy: 0.8765 - f1_metric: 0.8764 - val_loss: 0.2786 - val_accuracy: 0.8598 - val_f1_metric: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 276/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3274 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 276: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2922 - accuracy: 0.8567 - f1_metric: 0.8537 - val_loss: 0.2770 - val_accuracy: 0.8659 - val_f1_metric: 0.8490 - lr: 1.0000e-04\n",
            "Epoch 277/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2625 - accuracy: 0.8281 - f1_metric: 0.8281\n",
            "Epoch 277: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8521 - f1_metric: 0.8537 - val_loss: 0.2776 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 278/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3391 - accuracy: 0.8750 - f1_metric: 0.8750\n",
            "Epoch 278: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2859 - accuracy: 0.8643 - f1_metric: 0.8523 - val_loss: 0.2770 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 279/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.1931 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 279: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2961 - accuracy: 0.8674 - f1_metric: 0.8636 - val_loss: 0.2775 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 280/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3215 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 280: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2942 - accuracy: 0.8521 - f1_metric: 0.8494 - val_loss: 0.2792 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2919 - accuracy: 0.8674 - f1_metric: 0.8679\n",
            "Epoch 281: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2919 - accuracy: 0.8674 - f1_metric: 0.8679 - val_loss: 0.2800 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 282/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2987 - accuracy: 0.8594 - f1_metric: 0.8594\n",
            "Epoch 282: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2960 - accuracy: 0.8628 - f1_metric: 0.8679 - val_loss: 0.2796 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 283/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2773 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 283: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2882 - accuracy: 0.8689 - f1_metric: 0.8523 - val_loss: 0.2801 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2934 - accuracy: 0.8704 - f1_metric: 0.8622\n",
            "Epoch 284: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2934 - accuracy: 0.8704 - f1_metric: 0.8622 - val_loss: 0.2802 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 285/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2248 - accuracy: 0.9531 - f1_metric: 0.9531\n",
            "Epoch 285: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2961 - accuracy: 0.8704 - f1_metric: 0.8707 - val_loss: 0.2812 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 286/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2302 - accuracy: 0.9062 - f1_metric: 0.9062\n",
            "Epoch 286: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3017 - accuracy: 0.8841 - f1_metric: 0.8793 - val_loss: 0.2807 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 287/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2900 - accuracy: 0.8719 - f1_metric: 0.8719\n",
            "Epoch 287: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.2879 - accuracy: 0.8720 - f1_metric: 0.8722 - val_loss: 0.2792 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 288/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2234 - accuracy: 0.9375 - f1_metric: 0.9375\n",
            "Epoch 288: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2851 - accuracy: 0.8857 - f1_metric: 0.8764 - val_loss: 0.2787 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 289/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.2973 - accuracy: 0.8438 - f1_metric: 0.8437\n",
            "Epoch 289: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2947 - accuracy: 0.8780 - f1_metric: 0.8821 - val_loss: 0.2786 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 290/300\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 0.3174 - accuracy: 0.8906 - f1_metric: 0.8906\n",
            "Epoch 290: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2760 - accuracy: 0.8628 - f1_metric: 0.8594 - val_loss: 0.2780 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 291/300\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.2834 - accuracy: 0.8715 - f1_metric: 0.8715\n",
            "Epoch 291: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2953 - accuracy: 0.8628 - f1_metric: 0.8594 - val_loss: 0.2775 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2927 - accuracy: 0.8674 - f1_metric: 0.8764\n",
            "Epoch 292: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2927 - accuracy: 0.8674 - f1_metric: 0.8764 - val_loss: 0.2778 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 293/300\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.3117 - accuracy: 0.8524 - f1_metric: 0.8524\n",
            "Epoch 293: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.3064 - accuracy: 0.8552 - f1_metric: 0.8565 - val_loss: 0.2780 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2987 - accuracy: 0.8689 - f1_metric: 0.8651\n",
            "Epoch 294: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2987 - accuracy: 0.8689 - f1_metric: 0.8651 - val_loss: 0.2774 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2900 - accuracy: 0.8689 - f1_metric: 0.8736\n",
            "Epoch 295: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2900 - accuracy: 0.8689 - f1_metric: 0.8736 - val_loss: 0.2783 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 296/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2998 - accuracy: 0.8656 - f1_metric: 0.8656\n",
            "Epoch 296: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.3005 - accuracy: 0.8659 - f1_metric: 0.8665 - val_loss: 0.2784 - val_accuracy: 0.8720 - val_f1_metric: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 297/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2949 - accuracy: 0.8766 - f1_metric: 0.8766\n",
            "Epoch 297: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2969 - accuracy: 0.8750 - f1_metric: 0.8707 - val_loss: 0.2773 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 298/300\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.3058 - accuracy: 0.8687 - f1_metric: 0.8687\n",
            "Epoch 298: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.3080 - accuracy: 0.8674 - f1_metric: 0.8636 - val_loss: 0.2784 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 299/300\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 0.2747 - accuracy: 0.8819 - f1_metric: 0.8819\n",
            "Epoch 299: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2703 - accuracy: 0.8857 - f1_metric: 0.8892 - val_loss: 0.2768 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2930 - accuracy: 0.8689 - f1_metric: 0.8693\n",
            "Epoch 300: val_f1_metric did not improve from 0.87789\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2930 - accuracy: 0.8689 - f1_metric: 0.8693 - val_loss: 0.2776 - val_accuracy: 0.8780 - val_f1_metric: 0.8594 - lr: 1.0000e-04\n",
            "CPU times: user 49.6 s, sys: 1.36 s, total: 51 s\n",
            "Wall time: 52.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"last\"\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['f1_metric'])\n",
        "plt.plot(history.history['val_f1_metric'])\n",
        "\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train_loss', 'val_loss', 'f1', 'val_f1'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "fSSaoE3p7vjq",
        "outputId": "8c2d65d4-59e6-48fc-cb30-d7b389b52e21"
      },
      "id": "fSSaoE3p7vjq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score, cohen_kappa_score\n",
        "import seaborn as sns\n",
        "\n",
        "model = load_model(best_model_path)\n",
        "test_res = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"keras evaluate=\", test_res)\n",
        "pred = model.predict(x_test)\n",
        "pred_classes = np.argmax(pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "conf_mat = confusion_matrix(y_test_classes, pred_classes)\n",
        "print(conf_mat)\n",
        "labels = [0,1]\n",
        "# ax = sns.heatmap(conf_mat, xticklabels=labels, yticklabels=labels, annot=True)\n",
        "# ax.xaxis.set_ticks_position('top')\n",
        "f1_weighted = f1_score(y_test_classes, pred_classes, labels=None,\n",
        "         average='weighted', sample_weight=None)\n",
        "print(\"F1 score (weighted)\", f1_weighted)\n",
        "print(\"F1 score (macro)\", f1_score(y_test_classes, pred_classes, labels=None,\n",
        "         average='macro', sample_weight=None))\n",
        "print(\"F1 score (micro)\", f1_score(y_test_classes, pred_classes, labels=None,\n",
        "         average='micro', sample_weight=None))  # weighted and micro preferred in case of imbalance\n",
        "# https://scikit-learn.org/stable/modules/model_evaluation.html#cohen-s-kappa --> supports multiclass; ref: https://stats.stackexchange.com/questions/82162/cohens-kappa-in-plain-english\n",
        "print(\"cohen's Kappa\", cohen_kappa_score(y_test_classes, pred_classes))\n",
        "\n",
        "prec = []\n",
        "for i, row in enumerate(conf_mat):\n",
        "    prec.append(np.round(row[i]/np.sum(row), 2))\n",
        "    print(\"precision of class {} = {}\".format(i, prec[i]))\n",
        "print(\"precision avg\", sum(prec)/len(prec))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCPM-TOz7z2f",
        "outputId": "fb9b37ba-155e-4e19-9517-3e480a6cfe4f"
      },
      "id": "MCPM-TOz7z2f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keras evaluate= [0.3038841187953949, 0.8634146451950073, 0.8619504570960999]\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "[[88 12]\n",
            " [16 89]]\n",
            "F1 score (weighted) 0.8634276348474508\n",
            "F1 score (macro) 0.8634113839710642\n",
            "F1 score (micro) 0.8634146341463415\n",
            "cohen's Kappa 0.7269267364414843\n",
            "precision of class 0 = 0.88\n",
            "precision of class 1 = 0.85\n",
            "precision avg 0.865\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}